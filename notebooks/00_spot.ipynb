{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"00_Spot\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from numpy import power\n",
    "from math import inf\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.hyperparameters.values import (modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds, get_default_values, get_var_name, get_var_type, get_bound_values,\n",
    "    get_dict_with_levels_and_types)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "from spotRiver.utils.selectors import select_leaf_prediction, select_leaf_model\n",
    "from spotRiver import data\n",
    "from spotRiver.data.bike_sharing import get_bike_sharing_data\n",
    "from spotRiver.data.river_hyper_dict import HyperDict\n",
    "from spotRiver.utils.assignments import assign_values, iterate_dict_values, convert_keys\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder , MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import river.stream as river_stream\n",
    "from river.tree.splitter import EBSTSplitter, QOSplitter, TEBSTSplitter, GaussianSplitter, HistogramSplitter\n",
    "from river.linear_model import LinearRegression, PARegressor, Perceptron\n",
    "from river.tree import HoeffdingAdaptiveTreeRegressor\n",
    "from river.preprocessing import StandardScaler\n",
    "from river.compose import Pipeline\n",
    "from river import compose\n",
    "from river import datasets, time_series, utils, compose, linear_model, optim, preprocessing, evaluate, metrics, tree \n",
    "from river.datasets import synth\n",
    "from river import feature_extraction\n",
    "from river import stats, compose, preprocessing, tree\n",
    "from river import metrics\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train, test = get_bike_sharing_data()\n",
    "target_column=\"count\"\n",
    "n_samples = df.shape[0]\n",
    "X = copy.deepcopy(train)\n",
    "y = X.pop(\"count\")\n",
    "data = river_stream.iter_pandas(X, y)\n",
    "dataset = list(data)\n",
    "#\n",
    "categorical_columns = [\n",
    "    \"weather\",\n",
    "    \"season\",\n",
    "    \"holiday\",\n",
    "    \"workingday\",\n",
    "]\n",
    "categories = [\n",
    "    [\"clear\", \"misty\", \"rain\"],\n",
    "    [\"spring\", \"summer\", \"fall\", \"winter\"],\n",
    "    [\"False\", \"True\"],\n",
    "    [\"False\", \"True\"],\n",
    "]\n",
    "\n",
    "m = test.shape[0]\n",
    "a = int(m/2)-100\n",
    "b = int(m/2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load default `hyper_dict` for all algorithms, hyperparameters and levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# river_hyper_dict = HyperDict().load()\n",
    "# Load local hyper_dict:\n",
    "with open(\"river_hyper_dict.json\", \"r\") as f:\n",
    "         river_hyper_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}\n",
    "core_model  = HoeffdingAdaptiveTreeRegressor\n",
    "fun_control.update({\"core_model\": core_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control.update({\"core_model_hyper_dict\": river_hyper_dict[core_model.__name__]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_prediction\", [\"mean\"])\n",
    "fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify hyperparameter of type numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 11])\n",
    "# fun_control"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing model `prep_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_model = StandardScaler()\n",
    "prep_model = compose.Select(\"weekday\", \"month\", \"temp\", \"feel_temp\", \"humidity\", \"windspeed\")\n",
    "prep_model += (\n",
    "    feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())\n",
    ")\n",
    "prep_model |= preprocessing.StandardScaler()\n",
    "prep_model\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_default_values(fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fun_control.update({\"var_name\": list(fun_control[\"core_model_hyper_dict\"].keys()),\n",
    "#            \"var_type\": list(fun_control[\"core_model_hyper_dict\"][key][\"type\"] for key in fun_control[\"core_model_hyper_dict\"].keys())})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Type and Variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['int',\n",
       " 'int',\n",
       " 'float',\n",
       " 'float',\n",
       " 'factor',\n",
       " 'factor',\n",
       " 'float',\n",
       " 'factor',\n",
       " 'int',\n",
       " 'factor',\n",
       " 'int',\n",
       " 'float',\n",
       " 'factor',\n",
       " 'float',\n",
       " 'int',\n",
       " 'factor',\n",
       " 'factor',\n",
       " 'factor']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "var_type\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lower and upper bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile fun_control for spot\n",
    "\n",
    "* To be updated: Check if fun_control is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "fun = HyperRiver(seed=123, log_level=50).fun_oml_horizon\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"target_column\": target_column,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"weights\": np.array([1, 1/1000, 1/1000])*10_000.0,\n",
    "               \"step\": 100,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": 1.0,\n",
    "               \"metric\": metrics.MAE(),\n",
    "               \"metric_sklearn\": mean_absolute_error,\n",
    "               \"var_name\": var_name,\n",
    "               \"var_type\": var_type,\n",
    "               \"prep_model\": prep_model\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'core_model': river.tree.hoeffding_adaptive_tree_regressor.HoeffdingAdaptiveTreeRegressor,\n",
       " 'core_model_hyper_dict': {'grace_period': {'type': 'int',\n",
       "   'default': 200,\n",
       "   'transform': 'None',\n",
       "   'lower': 10,\n",
       "   'upper': 1000},\n",
       "  'max_depth': {'type': 'int',\n",
       "   'default': 20,\n",
       "   'transform': 'transform_power_2',\n",
       "   'lower': 2,\n",
       "   'upper': 20},\n",
       "  'delta': {'type': 'float',\n",
       "   'default': 1e-07,\n",
       "   'transform': 'None',\n",
       "   'lower': 1e-08,\n",
       "   'upper': 1e-06},\n",
       "  'tau': {'type': 'float',\n",
       "   'default': 0.05,\n",
       "   'transform': 'None',\n",
       "   'lower': 0.01,\n",
       "   'upper': 0.1},\n",
       "  'leaf_prediction': {'levels': ['mean'],\n",
       "   'type': 'factor',\n",
       "   'default': 'mean',\n",
       "   'transform': 'None',\n",
       "   'core_model_parameter_type': 'str',\n",
       "   'lower': 0,\n",
       "   'upper': 0},\n",
       "  'leaf_model': {'levels': ['LinearRegression'],\n",
       "   'type': 'factor',\n",
       "   'default': 'LinearRegression',\n",
       "   'transform': 'None',\n",
       "   'class_name': 'river.linear_model',\n",
       "   'core_model_parameter_type': 'instance',\n",
       "   'lower': 0,\n",
       "   'upper': 0},\n",
       "  'model_selector_decay': {'type': 'float',\n",
       "   'default': 0.95,\n",
       "   'transform': 'None',\n",
       "   'lower': 0.9,\n",
       "   'upper': 0.99},\n",
       "  'splitter': {'levels': ['EBSTSplitter', 'TEBSTSplitter', 'QOSplitter'],\n",
       "   'type': 'factor',\n",
       "   'default': 'EBSTSplitter',\n",
       "   'transform': 'None',\n",
       "   'class_name': 'river.tree.splitter',\n",
       "   'core_model_parameter_type': 'instance()',\n",
       "   'lower': 0,\n",
       "   'upper': 2},\n",
       "  'min_samples_split': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'None',\n",
       "   'lower': 3,\n",
       "   'upper': 11},\n",
       "  'bootstrap_sampling': {'levels': [0, 1],\n",
       "   'type': 'factor',\n",
       "   'default': 0,\n",
       "   'transform': 'None',\n",
       "   'core_model_parameter_type': 'bool',\n",
       "   'lower': 0,\n",
       "   'upper': 1},\n",
       "  'drift_window_threshold': {'type': 'int',\n",
       "   'default': 300,\n",
       "   'transform': 'None',\n",
       "   'lower': 100,\n",
       "   'upper': 500},\n",
       "  'switch_significance': {'type': 'float',\n",
       "   'default': 0.05,\n",
       "   'transform': 'None',\n",
       "   'lower': 0.01,\n",
       "   'upper': 0.1},\n",
       "  'binary_split': {'levels': [0, 1],\n",
       "   'type': 'factor',\n",
       "   'default': 0,\n",
       "   'transform': 'None',\n",
       "   'core_model_parameter_type': 'bool',\n",
       "   'lower': 0,\n",
       "   'upper': 1},\n",
       "  'max_size': {'type': 'float',\n",
       "   'default': 500.0,\n",
       "   'transform': 'None',\n",
       "   'lower': 100.0,\n",
       "   'upper': 1000.0},\n",
       "  'memory_estimate_period': {'type': 'int',\n",
       "   'default': 1000000,\n",
       "   'transform': 'None',\n",
       "   'lower': 100000,\n",
       "   'upper': 1000000},\n",
       "  'stop_mem_management': {'levels': [0, 1],\n",
       "   'type': 'factor',\n",
       "   'default': 0,\n",
       "   'transform': 'None',\n",
       "   'core_model_parameter_type': 'bool',\n",
       "   'lower': 0,\n",
       "   'upper': 1},\n",
       "  'remove_poor_attrs': {'levels': [0, 1],\n",
       "   'type': 'factor',\n",
       "   'default': 0,\n",
       "   'transform': 'None',\n",
       "   'core_model_parameter_type': 'bool',\n",
       "   'lower': 0,\n",
       "   'upper': 1},\n",
       "  'merit_preprune': {'levels': [0, 1],\n",
       "   'type': 'factor',\n",
       "   'default': 0,\n",
       "   'transform': 'None',\n",
       "   'core_model_parameter_type': 'bool',\n",
       "   'lower': 0,\n",
       "   'upper': 1}},\n",
       " 'prep_model': Pipeline (\n",
       "   TransformerUnion (\n",
       "     Select (\n",
       "       feel_temp\n",
       "       humidity\n",
       "       month\n",
       "       temp\n",
       "       weekday\n",
       "       windspeed\n",
       "     ),\n",
       "     TargetAgg (\n",
       "       by=['hour']\n",
       "       how=Mean ()\n",
       "       target_name=\"y\"\n",
       "     )\n",
       "   ),\n",
       "   StandardScaler (\n",
       "     with_std=True\n",
       "   )\n",
       " ),\n",
       " 'data': None,\n",
       " 'train':        season  year  month  hour holiday  weekday workingday weather   temp  \\\n",
       " 0      spring     0      1     0   False        6      False   clear   9.84   \n",
       " 1      spring     0      1     1   False        6      False   clear   9.02   \n",
       " 2      spring     0      1     2   False        6      False   clear   9.02   \n",
       " 3      spring     0      1     3   False        6      False   clear   9.84   \n",
       " 4      spring     0      1     4   False        6      False   clear   9.84   \n",
       " ...       ...   ...    ...   ...     ...      ...        ...     ...    ...   \n",
       " 10422  spring     1      3     9   False        4       True   clear  19.68   \n",
       " 10423  spring     1      3    10   False        4       True   clear  21.32   \n",
       " 10424  spring     1      3    11   False        4       True   clear  22.96   \n",
       " 10425  spring     1      3    12   False        4       True   misty  25.42   \n",
       " 10426  spring     1      3    13   False        4       True   misty  27.06   \n",
       " \n",
       "        feel_temp  humidity  windspeed     count  \n",
       " 0         14.395      0.81     0.0000  0.016377  \n",
       " 1         13.635      0.80     0.0000  0.040942  \n",
       " 2         13.635      0.80     0.0000  0.032753  \n",
       " 3         14.395      0.75     0.0000  0.013306  \n",
       " 4         14.395      0.75     0.0000  0.001024  \n",
       " ...          ...       ...        ...       ...  \n",
       " 10422     23.485      0.77     6.0032  0.322416  \n",
       " 10423     25.000      0.68     7.0015  0.167861  \n",
       " 10424     26.515      0.60     8.9981  0.215967  \n",
       " 10425     31.060      0.50     8.9981  0.271238  \n",
       " 10426     31.060      0.41     6.0032  0.279427  \n",
       " \n",
       " [10427 rows x 13 columns],\n",
       " 'test':        season  year  month  hour holiday  weekday workingday weather   temp  \\\n",
       " 10427  spring     1      3    14   False        4       True   misty  29.52   \n",
       " 10428  spring     1      3    15   False        4       True   clear  29.52   \n",
       " 10429  spring     1      3    16   False        4       True   clear  29.52   \n",
       " 10430  spring     1      3    17   False        4       True   clear  28.70   \n",
       " 10431  spring     1      3    18   False        4       True   clear  27.06   \n",
       " ...       ...   ...    ...   ...     ...      ...        ...     ...    ...   \n",
       " 17374  spring     1     12    19   False        1       True   misty  10.66   \n",
       " 17375  spring     1     12    20   False        1       True   misty  10.66   \n",
       " 17376  spring     1     12    21   False        1       True   clear  10.66   \n",
       " 17377  spring     1     12    22   False        1       True   clear  10.66   \n",
       " 17378  spring     1     12    23   False        1       True   clear  10.66   \n",
       " \n",
       "        feel_temp  humidity  windspeed     count  \n",
       " 10427     32.575      0.30     7.0015  0.264074  \n",
       " 10428     32.575      0.32    15.0013  0.293756  \n",
       " 10429     32.575      0.37    26.0027  0.436029  \n",
       " 10430     31.820      0.39    16.9979  0.729785  \n",
       " 10431     31.060      0.44    19.0012  0.763562  \n",
       " ...          ...       ...        ...       ...  \n",
       " 17374     12.880      0.60    11.0014  0.121801  \n",
       " 17375     12.880      0.60    11.0014  0.091095  \n",
       " 17376     12.880      0.60    11.0014  0.092119  \n",
       " 17377     13.635      0.56     8.9981  0.062436  \n",
       " 17378     13.635      0.65     8.9981  0.050154  \n",
       " \n",
       " [6952 rows x 13 columns],\n",
       " 'target_column': 'count',\n",
       " 'horizon': 168,\n",
       " 'oml_grace_period': 2,\n",
       " 'n_samples': 17379,\n",
       " 'weights': array([10000.,    10.,    10.]),\n",
       " 'step': 100,\n",
       " 'log_level': 50,\n",
       " 'weight_coeff': 1.0,\n",
       " 'metric': MAE: 0.,\n",
       " 'metric_sklearn': <function sklearn.metrics._regression.mean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')>,\n",
       " 'var_name': ['grace_period',\n",
       "  'max_depth',\n",
       "  'delta',\n",
       "  'tau',\n",
       "  'leaf_prediction',\n",
       "  'leaf_model',\n",
       "  'model_selector_decay',\n",
       "  'splitter',\n",
       "  'min_samples_split',\n",
       "  'bootstrap_sampling',\n",
       "  'drift_window_threshold',\n",
       "  'switch_significance',\n",
       "  'binary_split',\n",
       "  'max_size',\n",
       "  'memory_estimate_period',\n",
       "  'stop_mem_management',\n",
       "  'remove_poor_attrs',\n",
       "  'merit_preprune'],\n",
       " 'var_type': ['int',\n",
       "  'int',\n",
       "  'float',\n",
       "  'float',\n",
       "  'factor',\n",
       "  'factor',\n",
       "  'float',\n",
       "  'factor',\n",
       "  'int',\n",
       "  'factor',\n",
       "  'int',\n",
       "  'float',\n",
       "  'factor',\n",
       "  'float',\n",
       "  'int',\n",
       "  'factor',\n",
       "  'factor',\n",
       "  'factor']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let f_c = {\"core_model_hyper_dict\":{ \"leaf_prediction\": { \"levels\": [\"mean\", \"model\", \"adaptive\"], \"type\": \"factor\", \"default\": \"mean\", \"core_model_parameter_type\": \"str\"},  \"max_depth\": { \"type\": \"int\", \"default\": 20, \"transform\": \"transform_power_2\", \"lower\": 2, \"upper\": 20}}} and v = {'max_depth': 20,'leaf_prediction': 'mean'} and def transform_power_2(x): return 2**x. Write a function that takes f_c and v as input and returns a dictionary with the same structure as v. The function should also transform the values of the hyperparameters according to the transform function specified in f_c if the hyperparameter is of type \"int\", or \"float\" or \"num\".  For example, transform_hyper_parameter_values(f_c, v) should return {'max_depth': 1048576, 'leaf_prediction': 'mean'}.\n",
    "\n",
    "def transform_power_2(x):\n",
    "    return 2**x\n",
    "\n",
    "def transform_hyper_parameter_values(fun_control, hyper_parameter_values):\n",
    "    \"\"\"\n",
    "    Transform the values of the hyperparameters according to the transform function specified in f_c if the hyperparameter is of type \"int\", or \"float\" or \"num\".\n",
    "    \"\"\"\n",
    "    hyper_parameter_values = copy.deepcopy(hyper_parameter_values)\n",
    "    for key, value in hyper_parameter_values.items():\n",
    "        if fun_control[\"core_model_hyper_dict\"][key][\"type\"] in [\"int\", \"float\", \"num\"] and fun_control[\"core_model_hyper_dict\"][key][\"transform\"] != \"None\":\n",
    "            hyper_parameter_values[key] = eval(fun_control[\"core_model_hyper_dict\"][key][\"transform\"])(value)\n",
    "    return hyper_parameter_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if fun_control is correct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fun_hyperriver: fun_oml_horizon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate  (simulated) X hyperparameter config from spot():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0e+02, 2.0e+01, 1.0e-07, 5.0e-02, 0.0e+00, 0.0e+00, 9.5e-01,\n",
       "       0.0e+00, 5.0e+00, 0.0e+00, 3.0e+02, 5.0e-02, 0.0e+00, 5.0e+02,\n",
       "       1.0e+06, 0.0e+00, 0.0e+00, 0.0e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_default_values(fun_control)\n",
    "# get values from dict as np.array. If string, return zero\n",
    "X = np.array([float(X[key]) if isinstance(X[key], numbers.Number) else 0 for key in X.keys()])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grace_period': array([200.]),\n",
       " 'max_depth': array([20.]),\n",
       " 'delta': array([1.e-07]),\n",
       " 'tau': array([0.05]),\n",
       " 'leaf_prediction': array([0.]),\n",
       " 'leaf_model': array([0.]),\n",
       " 'model_selector_decay': array([0.95]),\n",
       " 'splitter': array([0.]),\n",
       " 'min_samples_split': array([5.]),\n",
       " 'bootstrap_sampling': array([0.]),\n",
       " 'drift_window_threshold': array([300.]),\n",
       " 'switch_significance': array([0.05]),\n",
       " 'binary_split': array([0.]),\n",
       " 'max_size': array([500.]),\n",
       " 'memory_estimate_period': array([1000000.]),\n",
       " 'stop_mem_management': array([0.]),\n",
       " 'remove_poor_attrs': array([0.]),\n",
       " 'merit_preprune': array([0.])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([X])\n",
    "X.shape[1]\n",
    "var_dict = assign_values(X, fun_control[\"var_name\"])\n",
    "var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['int',\n",
       " 'int',\n",
       " 'float',\n",
       " 'float',\n",
       " 'factor',\n",
       " 'factor',\n",
       " 'float',\n",
       " 'factor',\n",
       " 'int',\n",
       " 'factor',\n",
       " 'int',\n",
       " 'float',\n",
       " 'factor',\n",
       " 'float',\n",
       " 'int',\n",
       " 'factor',\n",
       " 'factor',\n",
       " 'factor']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control[\"var_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grace_period': 200, 'max_depth': 20, 'delta': 1e-07, 'tau': 0.05, 'leaf_prediction': 0, 'leaf_model': 0, 'model_selector_decay': 0.95, 'splitter': 0, 'min_samples_split': 5, 'bootstrap_sampling': 0, 'drift_window_threshold': 300, 'switch_significance': 0.05, 'binary_split': 0, 'max_size': 500.0, 'memory_estimate_period': 1000000, 'stop_mem_management': 0, 'remove_poor_attrs': 0, 'merit_preprune': 0}\n",
      "{'grace_period': 200, 'max_depth': 1048576, 'delta': 1e-07, 'tau': 0.05, 'leaf_prediction': 'mean', 'leaf_model': <class 'river.linear_model.lin_reg.LinearRegression'>, 'model_selector_decay': 0.95, 'splitter': EBSTSplitter (), 'min_samples_split': 5, 'bootstrap_sampling': 0, 'drift_window_threshold': 300, 'switch_significance': 0.05, 'binary_split': 0, 'max_size': 500.0, 'memory_estimate_period': 1000000, 'stop_mem_management': 0, 'remove_poor_attrs': 0, 'merit_preprune': 0}\n"
     ]
    }
   ],
   "source": [
    "for values in iterate_dict_values(var_dict):\n",
    "            values = convert_keys(values, fun_control[\"var_type\"])\n",
    "            print(values)\n",
    "            values = get_dict_with_levels_and_types(fun_control=fun_control, v=values)\n",
    "            values = transform_hyper_parameter_values(fun_control=fun_control, hyper_parameter_values=values)\n",
    "            print(values)\n",
    "            model = compose.Pipeline(fun_control[\"prep_model\"], fun_control[\"core_model\"](**values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grace_period': 200,\n",
       " 'max_depth': 1048576,\n",
       " 'delta': 1e-07,\n",
       " 'tau': 0.05,\n",
       " 'leaf_prediction': 'mean',\n",
       " 'leaf_model': river.linear_model.lin_reg.LinearRegression,\n",
       " 'model_selector_decay': 0.95,\n",
       " 'splitter': EBSTSplitter (),\n",
       " 'min_samples_split': 5,\n",
       " 'bootstrap_sampling': 0,\n",
       " 'drift_window_threshold': 300,\n",
       " 'switch_significance': 0.05,\n",
       " 'binary_split': 0,\n",
       " 'max_size': 500.0,\n",
       " 'memory_estimate_period': 1000000,\n",
       " 'stop_mem_management': 0,\n",
       " 'remove_poor_attrs': 0,\n",
       " 'merit_preprune': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Metric  Memory (MB)  CompTime (s)\n",
       " 0        NaN     0.060090      0.002192\n",
       " 1   0.181150     0.629938      0.057549\n",
       " 2   0.171039     0.745264      0.293957\n",
       " 3   0.126652     0.504434      0.245068\n",
       " 4   0.111308     0.711018      0.110999\n",
       " 5   0.113703     0.703635      0.264412\n",
       " 6   0.123865     0.563879      0.269861\n",
       " 7   0.090645     0.705828      0.094838\n",
       " 8   0.099753     0.660360      0.333064\n",
       " 9   0.104110     0.722749      0.099826\n",
       " 10  0.106796     0.741075      0.365424\n",
       " 11  0.099175     0.604262      0.335597\n",
       " 12  0.116016     0.680594      0.229675\n",
       " 13  0.109834     0.669992      0.347839\n",
       " 14  0.109915     0.746533      0.318938\n",
       " 15  0.097033     0.856433      0.301372\n",
       " 16  0.087399     0.740820      0.076370\n",
       " 17  0.087669     0.754246      0.232332\n",
       " 18  0.099367     0.748721      0.090063\n",
       " 19  0.104198     0.732435      0.098398\n",
       " 20  0.098435     0.758745      0.413247\n",
       " 21  0.096890     0.718737      0.348988\n",
       " 22  0.094855     0.742102      0.096450\n",
       " 23  0.093655     0.657602      0.257312\n",
       " 24  0.089197     0.709552      0.254166\n",
       " 25  0.100461     0.695107      0.234597\n",
       " 26  0.107997     0.733565      0.352480\n",
       " 27  0.107359     0.917000      0.490944\n",
       " 28  0.104786     0.757430      0.435072\n",
       " 29  0.110526     0.708880      0.234506\n",
       " 30  0.102743     0.743673      0.084270\n",
       " 31  0.095306     0.749112      0.104765\n",
       " 32  0.100425     0.748311      0.103596\n",
       " 33  0.115387     0.748533      0.101380\n",
       " 34  0.098178     0.734800      0.088715\n",
       " 35  0.090692     0.634679      1.238839\n",
       " 36  0.111285     0.710829      0.085678\n",
       " 37  0.113521     0.699739      0.248319\n",
       " 38  0.077949     0.711278      0.081786\n",
       " 39  0.068972     0.727391      0.089772\n",
       " 40  0.079298     0.786069      0.122358\n",
       " 41  0.178939     0.812833      0.097643\n",
       " 42  0.187684     0.406461      0.571492,\n",
       "          count  Prediction  Difference\n",
       " 0     0.264074    0.275333   -0.011259\n",
       " 1     0.293756    0.271580    0.022177\n",
       " 2     0.436029    0.277124    0.158905\n",
       " 3     0.729785    0.308905    0.420880\n",
       " 4     0.763562    0.379052    0.384510\n",
       " ...        ...         ...         ...\n",
       " 6947  0.121801    0.280579   -0.158778\n",
       " 6948  0.091095    0.270143   -0.179048\n",
       " 6949  0.092119    0.269663   -0.177545\n",
       " 6950  0.062436    0.113815   -0.051379\n",
       " 6951  0.050154    0.113773   -0.063619\n",
       " \n",
       " [6952 rows x 3 columns])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotRiver.evaluation.eval_bml import eval_oml_horizon\n",
    "eval_oml_horizon(\n",
    "                    model=model,\n",
    "                    train=fun_control[\"train\"],\n",
    "                    test=fun_control[\"test\"],\n",
    "                    target_column=fun_control[\"target_column\"],\n",
    "                    horizon=fun_control[\"horizon\"],\n",
    "                    oml_grace_period=fun_control[\"oml_grace_period\"],\n",
    "                    metric=fun_control[\"metric_sklearn\"],\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in fun_oml_horizon(). Call to eval_oml_horizon failed. err=RecursionError('maximum recursion depth exceeded while calling a Python object'), type(err)=<class 'RecursionError'>\n",
      "Error in fun_oml_horizon(). Call to eval_oml_horizon failed. err=RecursionError('maximum recursion depth exceeded while calling a Python object'), type(err)=<class 'RecursionError'>\n",
      "Error in fun_oml_horizon(). Call to eval_oml_horizon failed. err=RecursionError('maximum recursion depth exceeded while calling a Python object'), type(err)=<class 'RecursionError'>\n",
      "Error in fun_oml_horizon(). Call to eval_oml_horizon failed. err=RecursionError('maximum recursion depth exceeded while calling a Python object'), type(err)=<class 'RecursionError'>\n"
     ]
    }
   ],
   "source": [
    "spot_htr = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = 1,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type=var_type,\n",
    "                   var_name=var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 10,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": 20,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_htr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.print_importance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
