{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"River Hyperparameter Tuning with SPOT\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Parameter Optimization\n",
    "## `river` Hyperparameter Tuning: Nowcasting\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Nowcasting Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from math import inf\n",
    "from scipy.optimize import shgo\n",
    "from scipy.optimize import direct\n",
    "from scipy.optimize import differential_evolution\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import preprocessing\n",
    "from river import linear_model\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import time_series\n",
    "from river import utils\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "from spotPython.spot import spot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Nowcasting Example from River (Airline Passengers)\n",
    "\n",
    "* This is the Nowcasting example taken from [https://riverml.xyz/0.15.0/examples/building-a-simple-nowcasting-model/](https://riverml.xyz/0.15.0/examples/building-a-simple-nowcasting-model/)\n",
    "* It is used to check whether the implementation can be executed.\n",
    "* Finally, the objective function is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing, datasets, utils, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from spotRiver.utils.features import get_ordinal_date\n",
    "from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n",
    "\n",
    "dataset = datasets.AirlinePassengers()\n",
    "for x, y in datasets.AirlinePassengers():\n",
    "    print(x, y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('lin_reg', linear_model.LinearRegression())\n",
    ")\n",
    "\n",
    "dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset)\n",
    "plot_nowcast_model(dates, metric, y_trues, y_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nowcasting: The Improved Model for Airline Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing, datasets, utils, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from spotRiver.utils.features import get_month_distances\n",
    "from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n",
    "from river import optim\n",
    "\n",
    "dataset = datasets.AirlinePassengers()\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    ('features', compose.TransformerUnion(\n",
    "        ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n",
    "        ('month_distances', compose.FuncTransformer(get_month_distances)),\n",
    "    )),\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('lin_reg', linear_model.LinearRegression(\n",
    "        intercept_lr=0,\n",
    "        optimizer=optim.SGD(0.03)\n",
    "    ))\n",
    ")\n",
    "\n",
    "dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset)\n",
    "\n",
    "plot_nowcast_model(dates, metric, y_trues, y_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Nowcasting: The Improved Model for GW Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.resources as pkg_resources\n",
    "import spotRiver.data as data\n",
    "inp_file = pkg_resources.files(data)\n",
    "csv_path = str(inp_file.resolve())\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217\n"
     ]
    }
   ],
   "source": [
    "from spotRiver.data.generic import GenericData\n",
    "import importlib.resources as pkg_resources\n",
    "import spotRiver.data as data\n",
    "inp_file = pkg_resources.files(data)\n",
    "csv_path = str(inp_file.resolve())\n",
    "\n",
    "\n",
    "dataset = GenericData(filename=\"UnivariateData.csv\",\n",
    "                      directory=csv_path,\n",
    "                      target=\"Consumption\",\n",
    "                      n_features=1,\n",
    "                      n_samples=51_706,\n",
    "                      converters={\"Consumption\": float},\n",
    "                      parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n",
    "for x, y in dataset:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing, datasets, utils, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from spotRiver.utils.features import get_month_distances, get_weekday_distances, get_ordinal_date, get_hour_distances\n",
    "from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n",
    "from river import optim\n",
    "from spotRiver.data.generic import GenericData\n",
    "import importlib.resources as pkg_resources\n",
    "import spotRiver.data as data\n",
    "inp_file = pkg_resources.files(data)\n",
    "csv_path = str(inp_file.resolve())\n",
    "\n",
    "\n",
    "dataset = GenericData(filename=\"UnivariateData.csv\",\n",
    "                      directory=csv_path,\n",
    "                      target=\"Consumption\",\n",
    "                      n_features=1,\n",
    "                      n_samples=51_706,\n",
    "                      converters={\"Consumption\": float},\n",
    "                      parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n",
    "for x, y in dataset:\n",
    "    print(x, y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compose.Pipeline(\n",
    "    ('features', compose.TransformerUnion(\n",
    "        ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n",
    "        ('month_distances', compose.FuncTransformer(get_month_distances)),\n",
    "        ('weekday_distances', compose.FuncTransformer(get_weekday_distances)),\n",
    "        ('hour_distances', compose.FuncTransformer(get_hour_distances)),\n",
    "    )),\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('lin_reg', linear_model.LinearRegression(\n",
    "        intercept_lr=0,\n",
    "        optimizer=optim.SGD(0.001)\n",
    "    ))\n",
    ")\n",
    "# model = preprocessing.TargetStandardScaler(regressor=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset, time_interval=\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nowcast_model(dates, metric, y_trues, y_preds, range=[51_600, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['lin_reg'].weights\n",
    "# model.regressor['lin_reg'].weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 SPOT Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing, datasets, utils, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from spotRiver.utils.features import get_month_distances, get_weekday_distances, get_ordinal_date, get_hour_distances\n",
    "from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n",
    "from river import optim\n",
    "from scipy.optimize import differential_evolution\n",
    "from spotRiver.data.generic import GenericData\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "from spotPython.spot import spot\n",
    "\n",
    "\n",
    "dataset = GenericData(filename=\"UnivariateData.csv\",\n",
    "                      directory=\"/Users/bartz/data/\",\n",
    "                      target=\"Consumption\",\n",
    "                      n_features=1,\n",
    "                      n_samples=51_706,\n",
    "                      converters={\"Consumption\": float},\n",
    "                      parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n",
    "\n",
    "fun = HyperRiver(123).fun_nowcasting\n",
    "var_name = [\"lr\", \"intercept_lr\", \"hour\", \"weekday\", \"month\"]\n",
    "var_type = [\"num\", \"num\"] + [\"factor\"] * 3\n",
    "lower = np.array([0.00225, 0.01,        0,      0,   0])\n",
    "upper = np.array([0.003,  0.09,       1,      1,   1])\n",
    "fun_control = {\"data\": dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_now = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = 360,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type=var_type,\n",
    "                   var_name=var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": 20,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": 5,\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 1000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_now.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_now.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_now.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_now.print_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_now.to_all_dim(spot_now.min_X.reshape(1,-1))\n",
    "print(X)\n",
    "lr = X[:, 0]\n",
    "intercept_lr = X[:, 1]\n",
    "hour = X[:, 2]\n",
    "weekday = X[:, 3]\n",
    "month = X[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i = int(hour)\n",
    "w_i = int(weekday)\n",
    "m_i = int(month)\n",
    "# baseline:\n",
    "extract_features = compose.TransformerUnion(get_ordinal_date)\n",
    "if h_i:\n",
    "    extract_features = compose.TransformerUnion(get_ordinal_date, get_hour_distances)\n",
    "if w_i:\n",
    "    extract_features = compose.TransformerUnion(extract_features, get_weekday_distances)\n",
    "if m_i:\n",
    "    extract_features = compose.TransformerUnion(extract_features, get_month_distances)\n",
    "model_spot = compose.Pipeline(\n",
    "    (\"features\", extract_features),\n",
    "    (\"scale\", preprocessing.StandardScaler()),\n",
    "    (\n",
    "        \"lin_reg\",\n",
    "        linear_model.LinearRegression(\n",
    "            intercept_init=0, optimizer=optim.SGD(float(lr)), intercept_lr=float(intercept_lr)\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "# eval:\n",
    "dates, metric, y_trues, y_preds = eval_nowcast_model(\n",
    "    model_spot, dataset=dataset, time_interval=\"Time\"\n",
    ")\n",
    "z = metric.get()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nowcast_model(dates, metric, y_trues, y_preds, range=[51_606, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spot['lin_reg'].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_z = None\n",
    "max_z = None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_now.y)` and\n",
    "  * `max_z = max(spot_now.y)`\n",
    "* These settings are not so colorful, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(spot_now.y), max(spot_now.y)\n",
    "n = spot_now.k\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1, n):\n",
    "        spot_now.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "812997cf104508e2f173b2c90792eaf8cff67f1a4f9ecbbbe259fea2cc1f68f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
