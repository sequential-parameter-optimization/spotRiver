{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"River Hyperparameter Tuning with SPOT HTR\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Parameter Optimization\n",
    "## `river` Hyperparameter Tuning: HTR with User Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspotstream        0.2.0\n",
      "spotPython          0.0.10\n",
      "spotRiver           0.0.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall http://www.gm.fh-koeln.de/~bartz/site/spotPython.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: HTR Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "from spotPython.spot import spot\n",
    "from spotRiver import data\n",
    "from scipy.optimize import shgo\n",
    "from scipy.optimize import direct\n",
    "from scipy.optimize import differential_evolution\n",
    "import matplotlib.pyplot as plt\n",
    "from spotRiver.utils.selectors import select_leaf_prediction\n",
    "from spotRiver.utils.selectors import select_leaf_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 The Objective Function \n",
    "\n",
    "* Here we will use the river `HATR` function.\n",
    "* First, the function will be tested independently from `Spot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['int',\n",
       " 'int',\n",
       " 'num',\n",
       " 'num',\n",
       " 'factor',\n",
       " 'factor',\n",
       " 'float',\n",
       " 'int',\n",
       " 'int',\n",
       " 'factor',\n",
       " 'float']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "from river import datasets\n",
    "from river import time_series\n",
    "from river import utils\n",
    "import calendar\n",
    "import math\n",
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "from river import metrics\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "\n",
    "fun = HyperRiver(123).fun_HTR_iter_progressive\n",
    "var_type = [\"int\"] * 2 + [\"num\"] * 2 + [\"factor\"] * 2 + [\"float\"] + [\"int\"] * 2 + [\"factor\"] + [\"float\"]\n",
    "var_type\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Instead of using the Airline Passenger data as in notebook 01, we demonstrate the usage of user specified data which is *not* part of the `spotRiver` package!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River's Synth Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from river import datasets\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river import preprocessing  # we are going to use that later\n",
    "from river.datasets import synth  # we are going to use some synthetic datasets too\n",
    "from river import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.datasets import synth\n",
    "n_samples = 10_000\n",
    "data = synth.Friedman(seed=42).take(n_samples)\n",
    "# dataset = synth.Friedman(seed=42)\n",
    "dataset  = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotRiver.data.generic import GenericData\n",
    "# fraction = 1.0\n",
    "# data = GenericData(filename=\"opm_num.zip\",\n",
    "#                       directory=\".\",\n",
    "#                       target=\"Sale Amount\",\n",
    "#                       n_features=7,\n",
    "#                       n_samples=985_862,\n",
    "#                       fraction = fraction,\n",
    "#                       converters={'List Year': int,\n",
    "#                                   'Assessed Value': float,\n",
    "#                                   'Sale Amount': float,\n",
    "#                                   'Sales Ratio': float,\n",
    "#                                   'lon': float,\n",
    "#                                   'lat': float,\n",
    "#                                   'timestamp_rec': float},\n",
    "#                       parse_dates=None\n",
    "#                       # parse_dates={\"Date Recorded\": \"%Y-%m-%d\"}\n",
    "#                       )\n",
    "# n_samples = int(data.n_samples * fraction)\n",
    "# dataset = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6394267984578837, 1: 0.025010755222666936, 2: 0.27502931836911926, 3: 0.22321073814882275, 4: 0.7364712141640124, 5: 0.6766994874229113, 6: 0.8921795677048454, 7: 0.08693883262941615, 8: 0.4219218196852704, 9: 0.029797219438070344} 7.6612066799391085\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[2.00e+02 1.00e+01 1.00e-06 7.50e-02 2.00e+00 1.00e+00 0.00e+00 7.00e+00 0.00e+00 3.12e+02]]\n",
    "# lower = np.array([100, 1,  1e-8, 0.025, 0, 0, 0.8,  0,  5, 0, 250.0])\n",
    "# upper = np.array([200, 10, 1e-6, 0.075, 1, 1, 0.975, 1, 10, 1, 750.0])\n",
    "\n",
    "lower = np.array([100, 100,  1e-8, 0.025, 0, 0, 0.8,  1,  5, 0, 250.0])\n",
    "upper = np.array([200, 10_000, 1e-6, 0.075, 0, 1, 0.975, 1, 10, 1, 750.0])\n",
    "fun_control = {\"data\": dataset,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"weights\": np.array([1, 1/10, 1/10]*10_000),\n",
    "               \"step\": 100,\n",
    "               \"verbosity\": 0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Run the `Spot` Optimizer\n",
    "\n",
    "* Since the data is larger than the airline passengers data, the max. time is increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name=[\"gracePeriod\", \"maxDepth\", \"delta\", \"tau\", \"leafPrediction\",\n",
    "          \"leafModel\", \"modelSelDecay\", \"splitter\",\n",
    "          \"minSamplesSplit\", \"binarySplit\", \"maxSize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = 300,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type=var_type,\n",
    "                   var_name=var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 10,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": 100,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": False,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": 11,\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 1000,\n",
    "                                      })\n",
    "spot_htr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results \n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.print_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(spot_htr.y), max(spot_htr.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = spot_htr.k\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1, n):\n",
    "        spot_htr.plot_contour(i=i, j=j, min_z=min(spot_htr.y), max_z = max(spot_htr.y) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Evaluate HTR Model with Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_htr.to_all_dim(spot_htr.min_X.reshape(1,-1))\n",
    "print(X)\n",
    "grace_period = X[:, 0]\n",
    "max_depth = X[:, 1]\n",
    "delta = X[:, 2]\n",
    "tau = X[:, 3]\n",
    "leaf_prediction = X[:, 4]\n",
    "leaf_model = X[:, 5]\n",
    "model_selector_decay = X[:, 6]\n",
    "splitter = X[:, 7]\n",
    "min_samples_split = X[:, 8]\n",
    "binary_split = X[:, 9]\n",
    "max_size = X[:, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "from river import tree\n",
    "from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive\n",
    "from spotRiver.evaluation.eval_oml import eval_oml_iter_progressive\n",
    "from spotRiver.utils.selectors import select_splitter\n",
    "from spotRiver.utils.selectors import select_max_depth\n",
    "num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler()\n",
    "cat = compose.SelectType(str) | preprocessing.FeatureHasher(n_features=1000, seed=1)\n",
    "res = eval_oml_iter_progressive(\n",
    "    dataset=fun_control[\"data\"],\n",
    "    step=fun_control[\"step\"],\n",
    "    verbose=True,\n",
    "    metric=metrics.MAE(),\n",
    "    models={\n",
    "         \"Default: HTR + QO\": (\n",
    "             (num + cat) | tree.HoeffdingTreeRegressor(\n",
    "                splitter=tree.splitter.QOSplitter()\n",
    "            )\n",
    "        ),\n",
    "        \"SPOT: HTR + QO\": (\n",
    "            (num + cat) | tree.HoeffdingTreeRegressor(\n",
    "                grace_period=int(grace_period),\n",
    "                max_depth=select_max_depth(int(max_depth)),\n",
    "                delta=float(delta),\n",
    "                tau=float(tau),\n",
    "                leaf_prediction=select_leaf_prediction(int(leaf_prediction)),\n",
    "                leaf_model=select_leaf_model(int(leaf_model)),\n",
    "                splitter=select_splitter(int(splitter)),\n",
    "                min_samples_split=int(min_samples_split),\n",
    "                binary_split=int(binary_split),\n",
    "                max_size=float(max_size)\n",
    "            )\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "y = fun_eval_oml_iter_progressive(res, metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive\n",
    "plot_oml_iter_progressive(res, log_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# model[\"ts\"].regressor[\"lm\"].weights\n",
    "# forecast = model.forecast(horizon=fun_control[\"horizon\"])\n",
    "# forecast\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "812997cf104508e2f173b2c90792eaf8cff67f1a4f9ecbbbe259fea2cc1f68f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
