{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to spotRiver \u00b6 For official information see SPOTSeven","title":"Home"},{"location":"#welcome-to-spotriver","text":"For official information see SPOTSeven","title":"Welcome to spotRiver"},{"location":"about/","text":"Contact/Privacy Policy \u00b6 Address \u00b6 Prof. Dr. Thomas Bartz-Beielstein TH K\u00f6ln Raum 1.519 Steinm\u00fcllerallee 6 51643 Gummersbach +49 (0)2261 8196 6391 thomas.bartz-beielstein [at] th-koeln.de www.spotseven.de Privacy Policy \u00b6 We are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. The use of the Internet pages of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject. The processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled. As the controller, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone. Definitions The data protection declaration of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used. In this data protection declaration, we use, inter alia, the following terms: a) Personal data Personal data means any information relating to an identified or identifiable natural person (\u201cdata subject\u201d). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person. b) Data subject Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing. c) Processing Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction. d) Restriction of processing Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future. e) Profiling Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements. f) Pseudonymisation Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person. g) Controller or controller responsible for the processing Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law. h) Processor Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller. i) Recipient Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing. j) Third party Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data. k) Consent Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her. Name and Address of the controller Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is: TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab Steinm\u00fcllerallee 1 51643 Gummersbach Deutschland Phone: +49 2261 81966391 Email: thomas.bartz-beielstein@th-koeln.de Website: www.spotseven.de Collection of general data and information The website of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems. When using these general data and information, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject. Comments function in the blog on the website The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties. If a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user\u2019s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller. Routine erasure and blocking of personal data The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to. If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements. Rights of the data subject a) Right of confirmation Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. b) Right of access Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information: the purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer. If a data subject wishes to avail himself of this right of access, he or she may at any time contact our Data Protection Officer or another employee of the controller. c) Right to rectification Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement. If a data subject wishes to exercise this right to rectification, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. d) Right to erasure (Right to be forgotten) Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary: The personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee shall promptly ensure that the erasure request is complied with immediately. Where the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the necessary measures in individual cases. e) Right of restriction of processing Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies: The accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the restriction of the processing. f) Right to data portability Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. Furthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others. In order to assert the right to data portability, the data subject may at any time contact the Data Protection Officer designated by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. g) Right to object Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions. The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims. If the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab to the processing for direct marketing purposes, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab will no longer process the personal data for these purposes. In addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest. In order to exercise the right to object, the data subject may directly contact the Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications. h) Automated individual decision-making, including profiling Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, or (3) is not based on the data subject\u2019s explicit consent. If the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject\u2019s explicit consent, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall implement suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision. If the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. i) Right to withdraw data protection consent Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time. f the data subject wishes to exercise the right to withdraw the consent, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. Data protection provisions about the application and use of Facebook On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network. A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests. The operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland. With each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject. If the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the \u201cLike\u201d button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data. Facebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made. The data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook, e.g. the Facebook blocker of the provider Webgraph, which may be obtained under http://webgraph.com/resources/facebookblocker/. These applications may be used by the data subject to eliminate a data transmission to Facebook. Data protection provisions about the application and use of Google+ On this website, the controller has integrated the Google+ button as a component. Google+ is a so-called social network. A social network is a social meeting place on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Google+ allows users of the social network to include the creation of private profiles, upload photos and network through friend requests. The operating company of Google+ is Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this website, which is operated by the controller and on which a Google+ button has been integrated, the Internet browser on the information technology system of the data subject automatically downloads a display of the corresponding Google+ button of Google through the respective Google+ button component. During the course of this technical procedure, Google is made aware of what specific sub-page of our website was visited by the data subject. More detailed information about Google+ is available under https://developers.google.com/+/. If the data subject is logged in at the same time to Google+, Google recognizes with each call-up to our website by the data subject and for the entire duration of his or her stay on our Internet site, which specific sub-pages of our Internet page were visited by the data subject. This information is collected through the Google+ button and Google matches this with the respective Google+ account associated with the data subject. If the data subject clicks on the Google+ button integrated on our website and thus gives a Google+ 1 recommendation, then Google assigns this information to the personal Google+ user account of the data subject and stores the personal data. Google stores the Google+ 1 recommendation of the data subject, making it publicly available in accordance with the terms and conditions accepted by the data subject in this regard. Subsequently, a Google+ 1 recommendation given by the data subject on this website together with other personal data, such as the Google+ account name used by the data subject and the stored photo, is stored and processed on other Google services, such as search-engine results of the Google search engine, the Google account of the data subject or in other places, e.g. on Internet pages, or in relation to advertisements. Google is also able to link the visit to this website with other personal data stored on Google. Google further records this personal information with the purpose of improving or optimizing the various Google services. Through the Google+ button, Google receives information that the data subject visited our website, if the data subject at the time of the call-up to our website is logged in to Google+. This occurs regardless of whether the data subject clicks or doesn\u2019t click on the Google+ button. If the data subject does not wish to transmit personal data to Google, he or she may prevent such transmission by logging out of his Google+ account before calling up our website. Further information and the data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/. More references from Google about the Google+ 1 button may be obtained under https://developers.google.com/+/web/buttons-policy. Data protection provisions about the application and use of Jetpack for WordPress On this website, the controller has integrated Jetpack. Jetpack is a WordPress plug-in, which provides additional features to the operator of a website based on WordPress. Jetpack allows the Internet site operator, inter alia, an overview of the visitors of the site. By displaying related posts and publications, or the ability to share content on the page, it is also possible to increase visitor numbers. In addition, security features are integrated into Jetpack, so a Jetpack-using site is better protected against brute-force attacks. Jetpack also optimizes and accelerates the loading of images on the website. The operating company of Jetpack Plug-Ins for WordPress is the Automattic Inc., 132 Hawthorne Street, San Francisco, CA 94107, UNITED STATES. The operating enterprise uses the tracking technology created by Quantcast Inc., 201 Third Street, San Francisco, CA 94103, UNITED STATES. Jetpack sets a cookie on the information technology system used by the data subject. The definition of cookies is explained above. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Jetpack component was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to submit data through the Jetpack component for analysis purposes to Automattic. During the course of this technical procedure Automattic receives data that is used to create an overview of website visits. The data obtained in this way serves the analysis of the behaviour of the data subject, which has access to the Internet page of the controller and is analyzed with the aim to optimize the website. The data collected through the Jetpack component is not used to identify the data subject without a prior obtaining of a separate express consent of the data subject. The data comes also to the notice of Quantcast. Quantcast uses the data for the same purposes as Automattic. The data subject can, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Automattic/Quantcast from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Automattic/Quantcast may be deleted at any time via a web browser or other software programs. In addition, the data subject has the possibility of objecting to a collection of data relating to a use of this Internet site that are generated by the Jetpack cookie as well as the processing of these data by Automattic/Quantcast and the chance to preclude any such. For this purpose, the data subject must press the \u2018opt-out\u2019 button under the link https://www.quantcast.com/opt-out/ which sets an opt-out cookie. The opt-out cookie set with this purpose is placed on the information technology system used by the data subject. If the cookies are deleted on the system of the data subject, then the data subject must call up the link again and set a new opt-out cookie. With the setting of the opt-out cookie, however, the possibility exists that the websites of the controller are not fully usable anymore by the data subject. The applicable data protection provisions of Automattic may be accessed under https://automattic.com/privacy/. The applicable data protection provisions of Quantcast can be accessed under https://www.quantcast.com/privacy/. Data protection provisions about the application and use of LinkedIn The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world. The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data. LinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made. LinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy. Data protection provisions about the application and use of Twitter On this website, the controller has integrated components of Twitter. Twitter is a multilingual, publicly-accessible microblogging service on which users may publish and spread so-called \u2018tweets,\u2019 e.g. short messages, which are limited to 140 characters. These short messages are available for everyone, including those who are not logged on to Twitter. The tweets are also displayed to so-called followers of the respective user. Followers are other Twitter users who follow a user\u2019s tweets. Furthermore, Twitter allows you to address a wide audience via hashtags, links or retweets. The operating company of Twitter is Twitter, Inc., 1355 Market Street, Suite 900, San Francisco, CA 94103, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Twitter component (Twitter button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding Twitter component of Twitter. Further information about the Twitter buttons is available under https://about.twitter.com/de/resources/buttons. During the course of this technical procedure, Twitter gains knowledge of what specific sub-page of our website was visited by the data subject. The purpose of the integration of the Twitter component is a retransmission of the contents of this website to allow our users to introduce this web page to the digital world and increase our visitor numbers. If the data subject is logged in at the same time on Twitter, Twitter detects with every call-up to our website by the data subject and for the entire duration of their stay on our Internet site which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Twitter component and associated with the respective Twitter account of the data subject. If the data subject clicks on one of the Twitter buttons integrated on our website, then Twitter assigns this information to the personal Twitter user account of the data subject and stores the personal data. Twitter receives information via the Twitter component that the data subject has visited our website, provided that the data subject is logged in on Twitter at the time of the call-up to our website. This occurs regardless of whether the person clicks on the Twitter component or not. If such a transmission of information to Twitter is not desirable for the data subject, then he or she may prevent this by logging off from their Twitter account before a call-up to our website is made. The applicable data protection provisions of Twitter may be accessed under https://twitter.com/privacy?lang=en. Data protection provisions about the application and use of YouTube On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal. The operating company of YouTube is YouTube, LLC, 901 Cherry Ave., San Bruno, CA 94066, UNITED STATES. The YouTube, LLC is a subsidiary of Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject. YouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made. YouTube\u2019s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google. Legal basis for the processing Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR). The legitimate interests pursued by the controller or by a third party Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders. Period for which the personal data will be stored The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract. Provision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact our Data Protection Officer. Our Data Protection Officer clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data. Existence of automated decision-making As a responsible company, we do not use automatic decision-making or profiling. This Privacy Policy has been generated by the Privacy Policy Generator of the External Data Protection Officers that was developed in cooperation with RC GmbH, which sells used notebooks and the Media Law Lawyers from WBS-LAW.","title":"About"},{"location":"about/#contactprivacy-policy","text":"","title":"Contact/Privacy Policy"},{"location":"about/#address","text":"Prof. Dr. Thomas Bartz-Beielstein TH K\u00f6ln Raum 1.519 Steinm\u00fcllerallee 6 51643 Gummersbach +49 (0)2261 8196 6391 thomas.bartz-beielstein [at] th-koeln.de www.spotseven.de","title":"Address"},{"location":"about/#privacy-policy","text":"We are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. The use of the Internet pages of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject. The processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled. As the controller, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone. Definitions The data protection declaration of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used. In this data protection declaration, we use, inter alia, the following terms: a) Personal data Personal data means any information relating to an identified or identifiable natural person (\u201cdata subject\u201d). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person. b) Data subject Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing. c) Processing Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction. d) Restriction of processing Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future. e) Profiling Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements. f) Pseudonymisation Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person. g) Controller or controller responsible for the processing Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law. h) Processor Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller. i) Recipient Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing. j) Third party Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data. k) Consent Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her. Name and Address of the controller Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is: TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab Steinm\u00fcllerallee 1 51643 Gummersbach Deutschland Phone: +49 2261 81966391 Email: thomas.bartz-beielstein@th-koeln.de Website: www.spotseven.de Collection of general data and information The website of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems. When using these general data and information, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject. Comments function in the blog on the website The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties. If a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user\u2019s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller. Routine erasure and blocking of personal data The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to. If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements. Rights of the data subject a) Right of confirmation Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. b) Right of access Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information: the purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer. If a data subject wishes to avail himself of this right of access, he or she may at any time contact our Data Protection Officer or another employee of the controller. c) Right to rectification Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement. If a data subject wishes to exercise this right to rectification, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. d) Right to erasure (Right to be forgotten) Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary: The personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee shall promptly ensure that the erasure request is complied with immediately. Where the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the necessary measures in individual cases. e) Right of restriction of processing Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies: The accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the restriction of the processing. f) Right to data portability Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. Furthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others. In order to assert the right to data portability, the data subject may at any time contact the Data Protection Officer designated by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. g) Right to object Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions. The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims. If the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab to the processing for direct marketing purposes, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab will no longer process the personal data for these purposes. In addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest. In order to exercise the right to object, the data subject may directly contact the Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications. h) Automated individual decision-making, including profiling Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, or (3) is not based on the data subject\u2019s explicit consent. If the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject\u2019s explicit consent, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall implement suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision. If the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. i) Right to withdraw data protection consent Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time. f the data subject wishes to exercise the right to withdraw the consent, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. Data protection provisions about the application and use of Facebook On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network. A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests. The operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland. With each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject. If the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the \u201cLike\u201d button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data. Facebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made. The data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook, e.g. the Facebook blocker of the provider Webgraph, which may be obtained under http://webgraph.com/resources/facebookblocker/. These applications may be used by the data subject to eliminate a data transmission to Facebook. Data protection provisions about the application and use of Google+ On this website, the controller has integrated the Google+ button as a component. Google+ is a so-called social network. A social network is a social meeting place on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Google+ allows users of the social network to include the creation of private profiles, upload photos and network through friend requests. The operating company of Google+ is Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this website, which is operated by the controller and on which a Google+ button has been integrated, the Internet browser on the information technology system of the data subject automatically downloads a display of the corresponding Google+ button of Google through the respective Google+ button component. During the course of this technical procedure, Google is made aware of what specific sub-page of our website was visited by the data subject. More detailed information about Google+ is available under https://developers.google.com/+/. If the data subject is logged in at the same time to Google+, Google recognizes with each call-up to our website by the data subject and for the entire duration of his or her stay on our Internet site, which specific sub-pages of our Internet page were visited by the data subject. This information is collected through the Google+ button and Google matches this with the respective Google+ account associated with the data subject. If the data subject clicks on the Google+ button integrated on our website and thus gives a Google+ 1 recommendation, then Google assigns this information to the personal Google+ user account of the data subject and stores the personal data. Google stores the Google+ 1 recommendation of the data subject, making it publicly available in accordance with the terms and conditions accepted by the data subject in this regard. Subsequently, a Google+ 1 recommendation given by the data subject on this website together with other personal data, such as the Google+ account name used by the data subject and the stored photo, is stored and processed on other Google services, such as search-engine results of the Google search engine, the Google account of the data subject or in other places, e.g. on Internet pages, or in relation to advertisements. Google is also able to link the visit to this website with other personal data stored on Google. Google further records this personal information with the purpose of improving or optimizing the various Google services. Through the Google+ button, Google receives information that the data subject visited our website, if the data subject at the time of the call-up to our website is logged in to Google+. This occurs regardless of whether the data subject clicks or doesn\u2019t click on the Google+ button. If the data subject does not wish to transmit personal data to Google, he or she may prevent such transmission by logging out of his Google+ account before calling up our website. Further information and the data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/. More references from Google about the Google+ 1 button may be obtained under https://developers.google.com/+/web/buttons-policy. Data protection provisions about the application and use of Jetpack for WordPress On this website, the controller has integrated Jetpack. Jetpack is a WordPress plug-in, which provides additional features to the operator of a website based on WordPress. Jetpack allows the Internet site operator, inter alia, an overview of the visitors of the site. By displaying related posts and publications, or the ability to share content on the page, it is also possible to increase visitor numbers. In addition, security features are integrated into Jetpack, so a Jetpack-using site is better protected against brute-force attacks. Jetpack also optimizes and accelerates the loading of images on the website. The operating company of Jetpack Plug-Ins for WordPress is the Automattic Inc., 132 Hawthorne Street, San Francisco, CA 94107, UNITED STATES. The operating enterprise uses the tracking technology created by Quantcast Inc., 201 Third Street, San Francisco, CA 94103, UNITED STATES. Jetpack sets a cookie on the information technology system used by the data subject. The definition of cookies is explained above. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Jetpack component was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to submit data through the Jetpack component for analysis purposes to Automattic. During the course of this technical procedure Automattic receives data that is used to create an overview of website visits. The data obtained in this way serves the analysis of the behaviour of the data subject, which has access to the Internet page of the controller and is analyzed with the aim to optimize the website. The data collected through the Jetpack component is not used to identify the data subject without a prior obtaining of a separate express consent of the data subject. The data comes also to the notice of Quantcast. Quantcast uses the data for the same purposes as Automattic. The data subject can, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Automattic/Quantcast from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Automattic/Quantcast may be deleted at any time via a web browser or other software programs. In addition, the data subject has the possibility of objecting to a collection of data relating to a use of this Internet site that are generated by the Jetpack cookie as well as the processing of these data by Automattic/Quantcast and the chance to preclude any such. For this purpose, the data subject must press the \u2018opt-out\u2019 button under the link https://www.quantcast.com/opt-out/ which sets an opt-out cookie. The opt-out cookie set with this purpose is placed on the information technology system used by the data subject. If the cookies are deleted on the system of the data subject, then the data subject must call up the link again and set a new opt-out cookie. With the setting of the opt-out cookie, however, the possibility exists that the websites of the controller are not fully usable anymore by the data subject. The applicable data protection provisions of Automattic may be accessed under https://automattic.com/privacy/. The applicable data protection provisions of Quantcast can be accessed under https://www.quantcast.com/privacy/. Data protection provisions about the application and use of LinkedIn The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world. The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data. LinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made. LinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy. Data protection provisions about the application and use of Twitter On this website, the controller has integrated components of Twitter. Twitter is a multilingual, publicly-accessible microblogging service on which users may publish and spread so-called \u2018tweets,\u2019 e.g. short messages, which are limited to 140 characters. These short messages are available for everyone, including those who are not logged on to Twitter. The tweets are also displayed to so-called followers of the respective user. Followers are other Twitter users who follow a user\u2019s tweets. Furthermore, Twitter allows you to address a wide audience via hashtags, links or retweets. The operating company of Twitter is Twitter, Inc., 1355 Market Street, Suite 900, San Francisco, CA 94103, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Twitter component (Twitter button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding Twitter component of Twitter. Further information about the Twitter buttons is available under https://about.twitter.com/de/resources/buttons. During the course of this technical procedure, Twitter gains knowledge of what specific sub-page of our website was visited by the data subject. The purpose of the integration of the Twitter component is a retransmission of the contents of this website to allow our users to introduce this web page to the digital world and increase our visitor numbers. If the data subject is logged in at the same time on Twitter, Twitter detects with every call-up to our website by the data subject and for the entire duration of their stay on our Internet site which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Twitter component and associated with the respective Twitter account of the data subject. If the data subject clicks on one of the Twitter buttons integrated on our website, then Twitter assigns this information to the personal Twitter user account of the data subject and stores the personal data. Twitter receives information via the Twitter component that the data subject has visited our website, provided that the data subject is logged in on Twitter at the time of the call-up to our website. This occurs regardless of whether the person clicks on the Twitter component or not. If such a transmission of information to Twitter is not desirable for the data subject, then he or she may prevent this by logging off from their Twitter account before a call-up to our website is made. The applicable data protection provisions of Twitter may be accessed under https://twitter.com/privacy?lang=en. Data protection provisions about the application and use of YouTube On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal. The operating company of YouTube is YouTube, LLC, 901 Cherry Ave., San Bruno, CA 94066, UNITED STATES. The YouTube, LLC is a subsidiary of Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject. YouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made. YouTube\u2019s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google. Legal basis for the processing Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR). The legitimate interests pursued by the controller or by a third party Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders. Period for which the personal data will be stored The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract. Provision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact our Data Protection Officer. Our Data Protection Officer clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data. Existence of automated decision-making As a responsible company, we do not use automatic decision-making or profiling. This Privacy Policy has been generated by the Privacy Policy Generator of the External Data Protection Officers that was developed in cooperation with RC GmbH, which sells used notebooks and the Media Law Lawyers from WBS-LAW.","title":"Privacy Policy"},{"location":"download/","text":"Install spotRiver \u00b6 pip install spotRiver","title":"Download"},{"location":"download/#install-spotriver","text":"pip install spotRiver","title":"Install spotRiver"},{"location":"examples/","text":"spotRiver Examples \u00b6 Friedman Drift \u00b6 import numpy as np import pandas as pd from spotRiver.evaluation.eval_oml import eval_oml_iter_progressive, plot_oml_iter_progressive from spotRiver.evaluation.eval_bml import eval_bml_horizon, eval_bml_landmark, eval_bml_window, eval_oml_horizon, plot_bml_oml_horizon_predictions, plot_bml_oml_horizon_metrics from spotRiver.utils.data_conversion import convert_to_df from river import metrics as river_metrics, compose, feature_extraction, linear_model, preprocessing, stats from river import stream as river_stream from river import preprocessing as river_preprocessing from river.datasets import synth from river.tree import HoeffdingTreeRegressor, HoeffdingAdaptiveTreeRegressor from sklearn.tree import DecisionTreeRegressor from sklearn.linear_model import LinearRegression from sklearn.datasets import make_regression from sklearn import preprocessing as preprocessing_sklearn from sklearn import tree as sklearn_tree from sklearn.pipeline import Pipeline from sklearn.preprocessing import MinMaxScaler from sklearn.pipeline import make_pipeline from sklearn.metrics import mean_absolute_error import os if not os.path.exists('./figures'): os.makedirs('./figures') Consider Global Recurring Abrupt Drift: def _global_recurring_abrupt_gen(self, x, index: int): if index < self._change_point1 or index >= self._change_point2: # The initial concept is recurring return ( 10 * math.sin(math.pi * x[0] * x[1]) + 20 * (x[2] - 0.5) ** 2 + 10 * x[3] + 5 * x[4] ) else: # Drift: the positions of the features are swapped return ( 10 * math.sin(math.pi * x[3] * x[5]) + 20 * (x[1] - 0.5) ** 2 + 10 * x[0] + 5 * x[2] ) Metric and Horizon \u00b6 metric = mean_absolute_error horizon = 7*24 k = 10 n_total = int(k*100_000) p_1 = int(k*25_000) p_2 = int(k*50_000) position=(p_1, p_2) n_train = 1_000 a = n_train + p_1 - 12 b = a + 12 Data: Friedman-Drift \u00b6 dataset = synth.FriedmanDrift( drift_type='gra', position=position, seed=123 ) data_dict = {key: [] for key in list(dataset.take(1))[0][0].keys()} data_dict[\"y\"] = [] for x, y in dataset.take(n_total): for key, value in x.items(): data_dict[key].append(value) data_dict[\"y\"].append(y) df = pd.DataFrame(data_dict) # Add column names x1 until x10 to the first 10 columns of the dataframe and the column name y to the last column df.columns = [f\"x{i}\" for i in range(1, 11)] + [\"y\"] train = df[:n_train] test = df[n_train:] target_column = \"y\" BML: Linear Regression \u00b6 bml_lm = LinearRegression() # Add a MinMaxScaler to the pipeline bml_lm = make_pipeline(MinMaxScaler(), bml_lm) df_eval_bml_lm, df_true_bml_lm = eval_bml_horizon(model = bml_lm, train = train, test = test, target_column=target_column, horizon=horizon, include_remainder=True, metric=metric) BML: Decision Tree Regressor \u00b6 bml_tree = DecisionTreeRegressor(random_state=0) # Add a MinMaxScaler to the pipeline bml_tree = make_pipeline(MinMaxScaler(), bml_tree) df_eval_bml_tree, df_true_bml_tree = eval_bml_horizon(model = bml_tree, train = train, test = test, target_column=target_column, horizon=horizon, include_remainder=True, metric=metric) OML: Linear Regression \u00b6 oml_lm = preprocessing.StandardScaler() oml_lm |= linear_model.LinearRegression() df_eval_oml_lm, df_true_oml_lm = eval_oml_horizon(model=oml_lm, train=train, test=test, target_column=\"y\", horizon=horizon, metric=metric) OML: HTR \u00b6 htr_model = (preprocessing.StandardScaler() | HoeffdingTreeRegressor()) df_eval_htr, df_true_htr = eval_oml_horizon(model=htr_model, train=train, test=test, target_column=\"y\", horizon=horizon, oml_grace_period=100, metric=metric) OML: HATR \u00b6 hatr_model = (preprocessing.StandardScaler() | HoeffdingAdaptiveTreeRegressor()) df_eval_hatr, df_true_hatr = eval_oml_horizon(model=hatr_model, train=train, test=test, target_column=\"y\", horizon=horizon, oml_grace_period=100,metric=metric) Plot \u00b6 df_labels=[\"bml_lm\", \"bml_tree\", \"oml_lm\", \"htr\", \"hatr\"] plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_lm, df_eval_bml_tree, df_eval_oml_lm, df_eval_htr, df_eval_hatr], log_y=False, log_x=False, df_labels=df_labels, cumulative=True, metric=metric, figsize=(10, 5), filename=\"./figures/ch09_friedman_1_000_000_metrics.pdf\") plot_bml_oml_horizon_predictions(df_true = [df_true_bml_lm[a:b], df_true_bml_tree[a:b], df_true_oml_lm[a:b], df_true_htr[a:b], df_true_hatr[a:b]], target_column=\"y\", df_labels=df_labels, filename=\"./figures/ch09_friedman_1_000_000_predictions.pdf\") Further Examples \u00b6 Examples can be found in the Hyperparameter Tuning Cookbook, e.g., Documentation of the Sequential Parameter Optimization .","title":"Examples"},{"location":"examples/#spotriver-examples","text":"","title":"spotRiver Examples"},{"location":"examples/#friedman-drift","text":"import numpy as np import pandas as pd from spotRiver.evaluation.eval_oml import eval_oml_iter_progressive, plot_oml_iter_progressive from spotRiver.evaluation.eval_bml import eval_bml_horizon, eval_bml_landmark, eval_bml_window, eval_oml_horizon, plot_bml_oml_horizon_predictions, plot_bml_oml_horizon_metrics from spotRiver.utils.data_conversion import convert_to_df from river import metrics as river_metrics, compose, feature_extraction, linear_model, preprocessing, stats from river import stream as river_stream from river import preprocessing as river_preprocessing from river.datasets import synth from river.tree import HoeffdingTreeRegressor, HoeffdingAdaptiveTreeRegressor from sklearn.tree import DecisionTreeRegressor from sklearn.linear_model import LinearRegression from sklearn.datasets import make_regression from sklearn import preprocessing as preprocessing_sklearn from sklearn import tree as sklearn_tree from sklearn.pipeline import Pipeline from sklearn.preprocessing import MinMaxScaler from sklearn.pipeline import make_pipeline from sklearn.metrics import mean_absolute_error import os if not os.path.exists('./figures'): os.makedirs('./figures') Consider Global Recurring Abrupt Drift: def _global_recurring_abrupt_gen(self, x, index: int): if index < self._change_point1 or index >= self._change_point2: # The initial concept is recurring return ( 10 * math.sin(math.pi * x[0] * x[1]) + 20 * (x[2] - 0.5) ** 2 + 10 * x[3] + 5 * x[4] ) else: # Drift: the positions of the features are swapped return ( 10 * math.sin(math.pi * x[3] * x[5]) + 20 * (x[1] - 0.5) ** 2 + 10 * x[0] + 5 * x[2] )","title":"Friedman Drift"},{"location":"examples/#metric-and-horizon","text":"metric = mean_absolute_error horizon = 7*24 k = 10 n_total = int(k*100_000) p_1 = int(k*25_000) p_2 = int(k*50_000) position=(p_1, p_2) n_train = 1_000 a = n_train + p_1 - 12 b = a + 12","title":"Metric and Horizon"},{"location":"examples/#data-friedman-drift","text":"dataset = synth.FriedmanDrift( drift_type='gra', position=position, seed=123 ) data_dict = {key: [] for key in list(dataset.take(1))[0][0].keys()} data_dict[\"y\"] = [] for x, y in dataset.take(n_total): for key, value in x.items(): data_dict[key].append(value) data_dict[\"y\"].append(y) df = pd.DataFrame(data_dict) # Add column names x1 until x10 to the first 10 columns of the dataframe and the column name y to the last column df.columns = [f\"x{i}\" for i in range(1, 11)] + [\"y\"] train = df[:n_train] test = df[n_train:] target_column = \"y\"","title":"Data: Friedman-Drift"},{"location":"examples/#bml-linear-regression","text":"bml_lm = LinearRegression() # Add a MinMaxScaler to the pipeline bml_lm = make_pipeline(MinMaxScaler(), bml_lm) df_eval_bml_lm, df_true_bml_lm = eval_bml_horizon(model = bml_lm, train = train, test = test, target_column=target_column, horizon=horizon, include_remainder=True, metric=metric)","title":"BML: Linear Regression"},{"location":"examples/#bml-decision-tree-regressor","text":"bml_tree = DecisionTreeRegressor(random_state=0) # Add a MinMaxScaler to the pipeline bml_tree = make_pipeline(MinMaxScaler(), bml_tree) df_eval_bml_tree, df_true_bml_tree = eval_bml_horizon(model = bml_tree, train = train, test = test, target_column=target_column, horizon=horizon, include_remainder=True, metric=metric)","title":"BML: Decision Tree Regressor"},{"location":"examples/#oml-linear-regression","text":"oml_lm = preprocessing.StandardScaler() oml_lm |= linear_model.LinearRegression() df_eval_oml_lm, df_true_oml_lm = eval_oml_horizon(model=oml_lm, train=train, test=test, target_column=\"y\", horizon=horizon, metric=metric)","title":"OML: Linear Regression"},{"location":"examples/#oml-htr","text":"htr_model = (preprocessing.StandardScaler() | HoeffdingTreeRegressor()) df_eval_htr, df_true_htr = eval_oml_horizon(model=htr_model, train=train, test=test, target_column=\"y\", horizon=horizon, oml_grace_period=100, metric=metric)","title":"OML: HTR"},{"location":"examples/#oml-hatr","text":"hatr_model = (preprocessing.StandardScaler() | HoeffdingAdaptiveTreeRegressor()) df_eval_hatr, df_true_hatr = eval_oml_horizon(model=hatr_model, train=train, test=test, target_column=\"y\", horizon=horizon, oml_grace_period=100,metric=metric)","title":"OML: HATR"},{"location":"examples/#plot","text":"df_labels=[\"bml_lm\", \"bml_tree\", \"oml_lm\", \"htr\", \"hatr\"] plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_lm, df_eval_bml_tree, df_eval_oml_lm, df_eval_htr, df_eval_hatr], log_y=False, log_x=False, df_labels=df_labels, cumulative=True, metric=metric, figsize=(10, 5), filename=\"./figures/ch09_friedman_1_000_000_metrics.pdf\") plot_bml_oml_horizon_predictions(df_true = [df_true_bml_lm[a:b], df_true_bml_tree[a:b], df_true_oml_lm[a:b], df_true_htr[a:b], df_true_hatr[a:b]], target_column=\"y\", df_labels=df_labels, filename=\"./figures/ch09_friedman_1_000_000_predictions.pdf\")","title":"Plot"},{"location":"examples/#further-examples","text":"Examples can be found in the Hyperparameter Tuning Cookbook, e.g., Documentation of the Sequential Parameter Optimization .","title":"Further Examples"},{"location":"hyperparameter-tuning-cookbook/","text":"Hyperparameter Tuning Cookbook \u00b6 The following is a cookbook of hyperparameter tuning recipes. It is not meant to be exhaustive, but instead act as a place to capture a number of the common patterns used in hyperparameter tuning. Hyperparameter Tuning Cookbook","title":"Documentation"},{"location":"hyperparameter-tuning-cookbook/#hyperparameter-tuning-cookbook","text":"The following is a cookbook of hyperparameter tuning recipes. It is not meant to be exhaustive, but instead act as a place to capture a number of the common patterns used in hyperparameter tuning. Hyperparameter Tuning Cookbook","title":"Hyperparameter Tuning Cookbook"},{"location":"reference/SUMMARY/","text":"spotRiver data airline_passengers base bike_sharing generic opm river_hyper_dict synth sea drift drift_generator evaluation eval_bml eval_nowcast eval_oml fun hyperriver hyperriver_old plot stats preprocess impute utils data_conversion features","title":"SUMMARY"},{"location":"reference/spotRiver/data/","text":"Datasets. This module contains a collection of datasets for multiple tasks: classification, regression, etc. The data corresponds to popular datasets and are conveniently wrapped to easily iterate over the data in a stream fashion. All datasets have fixed size. AirlinePassengers \u00b6 Bases: base . FileDataset Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: Type Description Generator An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References [1]: International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60 Source code in spotRiver/data/airline_passengers.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class AirlinePassengers ( base . FileDataset ): \"\"\"Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: (Generator): An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References: [1]: [International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line) \"\"\" def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , ) def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, ) __init__ () \u00b6 Constructor method. Returns: Type Description NoneType None Source code in spotRiver/data/airline_passengers.py 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , ) __iter__ () \u00b6 Iterate over the data. Returns: Type Description Generator An iterator over the data in the file. Source code in spotRiver/data/airline_passengers.py 48 49 50 51 52 53 54 55 56 57 58 def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, )","title":"data"},{"location":"reference/spotRiver/data/#spotRiver.data.AirlinePassengers","text":"Bases: base . FileDataset Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: Type Description Generator An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References [1]: International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60 Source code in spotRiver/data/airline_passengers.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class AirlinePassengers ( base . FileDataset ): \"\"\"Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: (Generator): An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References: [1]: [International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line) \"\"\" def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , ) def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, )","title":"AirlinePassengers"},{"location":"reference/spotRiver/data/#spotRiver.data.airline_passengers.AirlinePassengers.__init__","text":"Constructor method. Returns: Type Description NoneType None Source code in spotRiver/data/airline_passengers.py 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , )","title":"__init__()"},{"location":"reference/spotRiver/data/#spotRiver.data.airline_passengers.AirlinePassengers.__iter__","text":"Iterate over the data. Returns: Type Description Generator An iterator over the data in the file. Source code in spotRiver/data/airline_passengers.py 48 49 50 51 52 53 54 55 56 57 58 def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, )","title":"__iter__()"},{"location":"reference/spotRiver/data/airline_passengers/","text":"AirlinePassengers \u00b6 Bases: base . FileDataset Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: Type Description Generator An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References [1]: International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60 Source code in spotRiver/data/airline_passengers.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class AirlinePassengers ( base . FileDataset ): \"\"\"Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: (Generator): An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References: [1]: [International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line) \"\"\" def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , ) def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, ) __init__ () \u00b6 Constructor method. Returns: Type Description NoneType None Source code in spotRiver/data/airline_passengers.py 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , ) __iter__ () \u00b6 Iterate over the data. Returns: Type Description Generator An iterator over the data in the file. Source code in spotRiver/data/airline_passengers.py 48 49 50 51 52 53 54 55 56 57 58 def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, )","title":"airline_passengers"},{"location":"reference/spotRiver/data/airline_passengers/#spotRiver.data.airline_passengers.AirlinePassengers","text":"Bases: base . FileDataset Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: Type Description Generator An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References [1]: International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60 Source code in spotRiver/data/airline_passengers.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class AirlinePassengers ( base . FileDataset ): \"\"\"Monthly number of international airline passengers [1]. The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data. Returns: (Generator): An iterator over the data in the file. Note: The code can be used as a template for creating new datasets based on CSV files. Examples: >>> from spotRiver.data.airline_passengers import AirlinePassengers dataset = AirlinePassengers() for x, y in dataset.take(5): print(x, y) {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112 {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118 {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132 {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129 {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121 References: [1]: [International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line) \"\"\" def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , ) def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, )","title":"AirlinePassengers"},{"location":"reference/spotRiver/data/airline_passengers/#spotRiver.data.airline_passengers.AirlinePassengers.__init__","text":"Constructor method. Returns: Type Description NoneType None Source code in spotRiver/data/airline_passengers.py 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self ): \"\"\"Constructor method. Returns: (NoneType): None \"\"\" super () . __init__ ( filename = \"airline-passengers.csv\" , task = base . REG , n_features = 1 , n_samples = 144 , )","title":"__init__()"},{"location":"reference/spotRiver/data/airline_passengers/#spotRiver.data.airline_passengers.AirlinePassengers.__iter__","text":"Iterate over the data. Returns: Type Description Generator An iterator over the data in the file. Source code in spotRiver/data/airline_passengers.py 48 49 50 51 52 53 54 55 56 57 58 def __iter__ ( self ): \"\"\"Iterate over the data. Returns: (Generator): An iterator over the data in the file. \"\"\" return stream . iter_csv ( self . path , target = \"passengers\" , converters = { \"passengers\" : int }, parse_dates = { \"month\" : \"%Y-%m\" }, )","title":"__iter__()"},{"location":"reference/spotRiver/data/base/","text":"Config \u00b6 Bases: abc . ABC Base class for all configurations. All configurations inherit from this class, be they stored in a file or generated on the fly. Source code in spotRiver/data/base.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class Config ( abc . ABC ): \"\"\"Base class for all configurations. All configurations inherit from this class, be they stored in a file or generated on the fly. \"\"\" def __init__ ( self , ): pass @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc ) @property def _repr_content ( self ): \"\"\"The items that are displayed in the __repr__ method. This property can be overridden in order to modify the output of the __repr__ method. \"\"\" content = {} content [ \"Name\" ] = self . __class__ . __name__ return content desc () property \u00b6 Return the description from the docstring. Source code in spotRiver/data/base.py 59 60 61 62 63 @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc ) Dataset \u00b6 Bases: abc . ABC Base class for all datasets. All datasets inherit from this class, be they stored in a file or generated on the fly. Note The code is based on code from the river package [1] to provide a similar interface. Parameters: Name Type Description Default task str Type of task the dataset is meant for. Should be one of: - \u201cRegression\u201d - \u201cBinary classification\u201d - \u201cMulti-class classification\u201d - \u201cMulti-output binary classification\u201d - \u201cMulti-output regression\u201d required n_features int Number of features in the dataset. None n_samples int Number of samples in the dataset. None n_classes int Number of classes in the dataset, only applies to classification datasets. None n_outputs int Number of outputs the target is made of, only applies to multi-output datasets. None sparse bool Whether the dataset is sparse or not. False References [1]: Base class for all datasets in River. Source code in spotRiver/data/base.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 class Dataset ( abc . ABC ): \"\"\"Base class for all datasets. All datasets inherit from this class, be they stored in a file or generated on the fly. Note: The code is based on code from the river package [1] to provide a similar interface. Args: task (str): Type of task the dataset is meant for. Should be one of: - \"Regression\" - \"Binary classification\" - \"Multi-class classification\" - \"Multi-output binary classification\" - \"Multi-output regression\" n_features (int): Number of features in the dataset. n_samples (int): Number of samples in the dataset. n_classes (int): Number of classes in the dataset, only applies to classification datasets. n_outputs (int): Number of outputs the target is made of, only applies to multi-output datasets. sparse (bool): Whether the dataset is sparse or not. References: [1]: [Base class for all datasets in River.](https://riverml.xyz/0.18.0/api/datasets/base/Dataset/) \"\"\" def __init__ ( self , task : str , n_features : int = None , n_samples = None , n_classes = None , n_outputs = None , sparse = False , ): self . task = task self . n_features = n_features self . n_samples = n_samples self . n_outputs = n_outputs self . n_classes = n_classes self . sparse = sparse @abc . abstractmethod def __iter__ ( self ): raise NotImplementedError def take ( self , k : int ): \"\"\"Iterate over the k samples.\"\"\" return itertools . islice ( self , k ) @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc ) @property def _repr_content ( self ): \"\"\"The items that are displayed in the __repr__ method. This property can be overridden in order to modify the output of the __repr__ method. \"\"\" content = {} content [ \"Name\" ] = self . __class__ . __name__ content [ \"Task\" ] = self . task if isinstance ( self , SyntheticDataset ) and self . n_samples is None : content [ \"Samples\" ] = \"\u221e\" elif self . n_samples : content [ \"Samples\" ] = f \" { self . n_samples : , } \" if self . n_features : content [ \"Features\" ] = f \" { self . n_features : , } \" if self . n_outputs : content [ \"Outputs\" ] = f \" { self . n_outputs : , } \" if self . n_classes : content [ \"Classes\" ] = f \" { self . n_classes : , } \" content [ \"Sparse\" ] = str ( self . sparse ) return content def __repr__ ( self ): l_len = max ( map ( len , self . _repr_content . keys ())) r_len = max ( map ( len , self . _repr_content . values ())) out = f \" { self . desc } \\n\\n \" + \" \\n \" . join ( k . rjust ( l_len ) + \" \" + v . ljust ( r_len ) for k , v in self . _repr_content . items () ) if \"Parameters \\n ----------\" in self . __doc__ : params = re . split ( r \"\\w+\\n\\s {4} \\-{3,}\" , re . split ( \"Parameters \\n ----------\" , self . __doc__ )[ 1 ], )[ 0 ] . rstrip () out += f \" \\n\\n Parameters \\n ---------- { params } \" return out desc () property \u00b6 Return the description from the docstring. Source code in spotRiver/data/base.py 134 135 136 137 138 @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc ) take ( k ) \u00b6 Iterate over the k samples. Source code in spotRiver/data/base.py 130 131 132 def take ( self , k : int ): \"\"\"Iterate over the k samples.\"\"\" return itertools . islice ( self , k ) FileConfig \u00b6 Bases: Config Base class for configurations that are stored in a local file. Parameters: Name Type Description Default filename str The file\u2019s name. required directory str The directory where the file is contained. Defaults to the location of the datasets module. None desc dict Extra config parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 class FileConfig ( Config ): \"\"\"Base class for configurations that are stored in a local file. Args: filename (str): The file's name. directory (str): The directory where the file is contained. Defaults to the location of the `datasets` module. desc (dict): Extra config parameters to pass as keyword arguments. \"\"\" def __init__ ( self , filename , directory = None , ** desc ): super () . __init__ ( ** desc ) self . filename = filename self . directory = directory @property def path ( self ): if self . directory : return pathlib . Path ( self . directory ) . joinpath ( self . filename ) return pathlib . Path ( __file__ ) . parent . joinpath ( self . filename ) @property def _repr_content ( self ): content = super () . _repr_content content [ \"Path\" ] = str ( self . path ) return content FileDataset \u00b6 Bases: Dataset Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Parameters: Name Type Description Default filename str The file\u2019s name. required directory str The directory where the file is contained. Defaults to the location of the datasets module. None desc dict Extra dataset parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 class FileDataset ( Dataset ): \"\"\"Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Args: filename (str): The file's name. directory (str): The directory where the file is contained. Defaults to the location of the `datasets` module. desc (dict): Extra dataset parameters to pass as keyword arguments. \"\"\" def __init__ ( self , filename , directory = None , ** desc ): super () . __init__ ( ** desc ) self . filename = filename self . directory = directory @property def path ( self ): if self . directory : return pathlib . Path ( self . directory ) . joinpath ( self . filename ) return pathlib . Path ( __file__ ) . parent . joinpath ( self . filename ) @property def _repr_content ( self ): content = super () . _repr_content content [ \"Path\" ] = str ( self . path ) return content GenericFileDataset \u00b6 Bases: Dataset Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Parameters: Name Type Description Default filename str The file\u2019s name. required directory str The directory where the file is contained. Defaults to the location of the datasets module. None desc dict Extra dataset parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 class GenericFileDataset ( Dataset ): \"\"\"Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Args: filename (str): The file's name. directory (str): The directory where the file is contained. Defaults to the location of the `datasets` module. desc (dict): Extra dataset parameters to pass as keyword arguments. \"\"\" def __init__ ( self , filename , target , converters , parse_dates , directory = None , ** desc ): super () . __init__ ( ** desc ) self . filename = filename self . directory = directory self . target = target self . converters = converters self . parse_dates = parse_dates @property def path ( self ): if self . directory : return pathlib . Path ( self . directory ) . joinpath ( self . filename ) return pathlib . Path ( __file__ ) . parent . joinpath ( self . filename ) @property def _repr_content ( self ): content = super () . _repr_content content [ \"Path\" ] = str ( self . path ) return content RemoteDataset \u00b6 Bases: FileDataset Base class for datasets that are stored in a remote file. Medium and large datasets that are not part of the river package inherit from this class. Note The filename doesn\u2019t have to be provided if unpack is False. Indeed in the latter case the filename will be inferred from the URL. Parameters: Name Type Description Default url str The URL the dataset is located at. required size int The expected download size. required unpack bool Whether to unpack the download or not. True filename str An optional name to given to the file if the file is unpacked. None desc dict Extra dataset parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 class RemoteDataset ( FileDataset ): \"\"\"Base class for datasets that are stored in a remote file. Medium and large datasets that are not part of the river package inherit from this class. Note: The filename doesn't have to be provided if unpack is False. Indeed in the latter case the filename will be inferred from the URL. Args: url (str): The URL the dataset is located at. size (int): The expected download size. unpack (bool): Whether to unpack the download or not. filename (str): An optional name to given to the file if the file is unpacked. desc (dict): Extra dataset parameters to pass as keyword arguments. \"\"\" def __init__ ( self , url , size , unpack = True , filename = None , ** desc ): if filename is None : filename = path . basename ( url ) super () . __init__ ( filename = filename , ** desc ) self . url = url self . size = size self . unpack = unpack @property def path ( self ): return pathlib . Path ( get_data_home (), self . __class__ . __name__ , self . filename ) def download ( self , force = False , verbose = True ): if not force and self . is_downloaded : return # Determine where to download the archive directory = self . path . parent directory . mkdir ( parents = True , exist_ok = True ) archive_path = directory . joinpath ( path . basename ( self . url )) with request . urlopen ( self . url ) as r : # Notify the user if verbose : meta = r . info () try : n_bytes = int ( meta [ \"Content-Length\" ]) msg = f \"Downloading { self . url } ( { utils . pretty . humanize_bytes ( n_bytes ) } )\" except KeyError : msg = f \"Downloading { self . url } \" print ( msg ) # Now dump the contents of the requests with open ( archive_path , \"wb\" ) as f : shutil . copyfileobj ( r , f ) if not self . unpack : return if verbose : print ( f \"Uncompressing into { directory } \" ) if archive_path . suffix . endswith ( \"zip\" ): with zipfile . ZipFile ( archive_path , \"r\" ) as zf : zf . extractall ( directory ) elif archive_path . suffix . endswith (( \"gz\" , \"tar\" )): mode = \"r:\" if archive_path . suffix . endswith ( \"tar\" ) else \"r:gz\" tar = tarfile . open ( archive_path , mode ) tar . extractall ( directory ) tar . close () else : raise RuntimeError ( f \"Unhandled extension type: { archive_path . suffix } \" ) # Delete the archive file now that it has been uncompressed archive_path . unlink () @abc . abstractmethod def _iter ( self ): pass @property def is_downloaded ( self ): \"\"\"Indicate whether or the data has been correctly downloaded.\"\"\" if self . path . exists (): if self . path . is_file (): return self . path . stat () . st_size == self . size return sum ( f . stat () . st_size for f in self . path . glob ( \"**/*\" ) if f . is_file ()) return False def __iter__ ( self ): if not self . is_downloaded : self . download ( verbose = True ) if not self . is_downloaded : raise RuntimeError ( \"Something went wrong during the download\" ) yield from self . _iter () @property def _repr_content ( self ): content = super () . _repr_content content [ \"URL\" ] = self . url content [ \"Size\" ] = utils . pretty . humanize_bytes ( self . size ) content [ \"Downloaded\" ] = str ( self . is_downloaded ) return content is_downloaded () property \u00b6 Indicate whether or the data has been correctly downloaded. Source code in spotRiver/data/base.py 363 364 365 366 367 368 369 370 371 @property def is_downloaded ( self ): \"\"\"Indicate whether or the data has been correctly downloaded.\"\"\" if self . path . exists (): if self . path . is_file (): return self . path . stat () . st_size == self . size return sum ( f . stat () . st_size for f in self . path . glob ( \"**/*\" ) if f . is_file ()) return False SyntheticDataset \u00b6 Bases: Dataset A synthetic dataset. All synthetic datasets inherit from this class. Source code in spotRiver/data/base.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 class SyntheticDataset ( Dataset ): \"\"\"A synthetic dataset. All synthetic datasets inherit from this class. \"\"\" def __repr__ ( self ): l_len_prop = max ( map ( len , self . _repr_content . keys ())) r_len_prop = max ( map ( len , self . _repr_content . values ())) params = self . _get_params () l_len_config = max ( map ( len , params . keys ())) r_len_config = max ( map ( len , map ( str , params . values ()))) out = ( \"Synthetic data generator \\n\\n \" + \" \\n \" . join ( k . rjust ( l_len_prop ) + \" \" + v . ljust ( r_len_prop ) for k , v in self . _repr_content . items ()) + \" \\n\\n Configuration \\n ------------- \\n \" + \" \\n \" . join ( k . rjust ( l_len_config ) + \" \" + str ( v ) . ljust ( r_len_config ) for k , v in params . items ()) ) return out def _get_params ( self ) -> typing . Dict [ str , typing . Any ]: \"\"\"Return the parameters that were used during initialization.\"\"\" return { name : getattr ( self , name ) for name , param in inspect . signature ( self . __init__ ) . parameters . items () # type: ignore if param . kind != param . VAR_KEYWORD } get_data_home ( data_home = None ) \u00b6 Return the location where remote datasets are to be stored. By default the data directory is set to a folder named \u2018spotriver_data\u2019 in the user home folder. Alternatively, it can be set by the \u2018SPOTRIVER_DATA\u2019 environment variable or programmatically by giving an explicit folder path. The \u2018~\u2019 symbol is expanded to the user home folder. If the folder does not already exist, it is automatically created. Parameters: Name Type Description Default data_home str The path to spotriver data directory. If None , the default path is ~/spotriver_data . None Returns: Name Type Description data_home str The path to the spotriver data directory. Source code in spotRiver/data/base.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def get_data_home ( data_home = None ) -> str : \"\"\"Return the location where remote datasets are to be stored. By default the data directory is set to a folder named 'spotriver_data' in the user home folder. Alternatively, it can be set by the 'SPOTRIVER_DATA' environment variable or programmatically by giving an explicit folder path. The '~' symbol is expanded to the user home folder. If the folder does not already exist, it is automatically created. Args: data_home (str): The path to spotriver data directory. If `None`, the default path is `~/spotriver_data`. Returns: data_home (str): The path to the spotriver data directory. \"\"\" if data_home is None : data_home = environ . get ( \"SPOTRIVER_DATA\" , Path . home () / \"spotriver_data\" ) # Ensure data_home is a Path() object pointing to an absolute path data_home = Path ( data_home ) . absolute () # Create data directory if it does not exists. data_home . mkdir ( parents = True , exist_ok = True ) return data_home","title":"base"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Config","text":"Bases: abc . ABC Base class for all configurations. All configurations inherit from this class, be they stored in a file or generated on the fly. Source code in spotRiver/data/base.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class Config ( abc . ABC ): \"\"\"Base class for all configurations. All configurations inherit from this class, be they stored in a file or generated on the fly. \"\"\" def __init__ ( self , ): pass @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc ) @property def _repr_content ( self ): \"\"\"The items that are displayed in the __repr__ method. This property can be overridden in order to modify the output of the __repr__ method. \"\"\" content = {} content [ \"Name\" ] = self . __class__ . __name__ return content","title":"Config"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Config.desc","text":"Return the description from the docstring. Source code in spotRiver/data/base.py 59 60 61 62 63 @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc )","title":"desc()"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Dataset","text":"Bases: abc . ABC Base class for all datasets. All datasets inherit from this class, be they stored in a file or generated on the fly. Note The code is based on code from the river package [1] to provide a similar interface. Parameters: Name Type Description Default task str Type of task the dataset is meant for. Should be one of: - \u201cRegression\u201d - \u201cBinary classification\u201d - \u201cMulti-class classification\u201d - \u201cMulti-output binary classification\u201d - \u201cMulti-output regression\u201d required n_features int Number of features in the dataset. None n_samples int Number of samples in the dataset. None n_classes int Number of classes in the dataset, only applies to classification datasets. None n_outputs int Number of outputs the target is made of, only applies to multi-output datasets. None sparse bool Whether the dataset is sparse or not. False References [1]: Base class for all datasets in River. Source code in spotRiver/data/base.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 class Dataset ( abc . ABC ): \"\"\"Base class for all datasets. All datasets inherit from this class, be they stored in a file or generated on the fly. Note: The code is based on code from the river package [1] to provide a similar interface. Args: task (str): Type of task the dataset is meant for. Should be one of: - \"Regression\" - \"Binary classification\" - \"Multi-class classification\" - \"Multi-output binary classification\" - \"Multi-output regression\" n_features (int): Number of features in the dataset. n_samples (int): Number of samples in the dataset. n_classes (int): Number of classes in the dataset, only applies to classification datasets. n_outputs (int): Number of outputs the target is made of, only applies to multi-output datasets. sparse (bool): Whether the dataset is sparse or not. References: [1]: [Base class for all datasets in River.](https://riverml.xyz/0.18.0/api/datasets/base/Dataset/) \"\"\" def __init__ ( self , task : str , n_features : int = None , n_samples = None , n_classes = None , n_outputs = None , sparse = False , ): self . task = task self . n_features = n_features self . n_samples = n_samples self . n_outputs = n_outputs self . n_classes = n_classes self . sparse = sparse @abc . abstractmethod def __iter__ ( self ): raise NotImplementedError def take ( self , k : int ): \"\"\"Iterate over the k samples.\"\"\" return itertools . islice ( self , k ) @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc ) @property def _repr_content ( self ): \"\"\"The items that are displayed in the __repr__ method. This property can be overridden in order to modify the output of the __repr__ method. \"\"\" content = {} content [ \"Name\" ] = self . __class__ . __name__ content [ \"Task\" ] = self . task if isinstance ( self , SyntheticDataset ) and self . n_samples is None : content [ \"Samples\" ] = \"\u221e\" elif self . n_samples : content [ \"Samples\" ] = f \" { self . n_samples : , } \" if self . n_features : content [ \"Features\" ] = f \" { self . n_features : , } \" if self . n_outputs : content [ \"Outputs\" ] = f \" { self . n_outputs : , } \" if self . n_classes : content [ \"Classes\" ] = f \" { self . n_classes : , } \" content [ \"Sparse\" ] = str ( self . sparse ) return content def __repr__ ( self ): l_len = max ( map ( len , self . _repr_content . keys ())) r_len = max ( map ( len , self . _repr_content . values ())) out = f \" { self . desc } \\n\\n \" + \" \\n \" . join ( k . rjust ( l_len ) + \" \" + v . ljust ( r_len ) for k , v in self . _repr_content . items () ) if \"Parameters \\n ----------\" in self . __doc__ : params = re . split ( r \"\\w+\\n\\s {4} \\-{3,}\" , re . split ( \"Parameters \\n ----------\" , self . __doc__ )[ 1 ], )[ 0 ] . rstrip () out += f \" \\n\\n Parameters \\n ---------- { params } \" return out","title":"Dataset"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Dataset.desc","text":"Return the description from the docstring. Source code in spotRiver/data/base.py 134 135 136 137 138 @property def desc ( self ): \"\"\"Return the description from the docstring.\"\"\" desc = re . split ( pattern = r \"\\w+\\n\\s {4} \\-{3,}\" , string = self . __doc__ , maxsplit = 0 )[ 0 ] return inspect . cleandoc ( desc )","title":"desc()"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Dataset.take","text":"Iterate over the k samples. Source code in spotRiver/data/base.py 130 131 132 def take ( self , k : int ): \"\"\"Iterate over the k samples.\"\"\" return itertools . islice ( self , k )","title":"take()"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.FileConfig","text":"Bases: Config Base class for configurations that are stored in a local file. Parameters: Name Type Description Default filename str The file\u2019s name. required directory str The directory where the file is contained. Defaults to the location of the datasets module. None desc dict Extra config parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 class FileConfig ( Config ): \"\"\"Base class for configurations that are stored in a local file. Args: filename (str): The file's name. directory (str): The directory where the file is contained. Defaults to the location of the `datasets` module. desc (dict): Extra config parameters to pass as keyword arguments. \"\"\" def __init__ ( self , filename , directory = None , ** desc ): super () . __init__ ( ** desc ) self . filename = filename self . directory = directory @property def path ( self ): if self . directory : return pathlib . Path ( self . directory ) . joinpath ( self . filename ) return pathlib . Path ( __file__ ) . parent . joinpath ( self . filename ) @property def _repr_content ( self ): content = super () . _repr_content content [ \"Path\" ] = str ( self . path ) return content","title":"FileConfig"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.FileDataset","text":"Bases: Dataset Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Parameters: Name Type Description Default filename str The file\u2019s name. required directory str The directory where the file is contained. Defaults to the location of the datasets module. None desc dict Extra dataset parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 class FileDataset ( Dataset ): \"\"\"Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Args: filename (str): The file's name. directory (str): The directory where the file is contained. Defaults to the location of the `datasets` module. desc (dict): Extra dataset parameters to pass as keyword arguments. \"\"\" def __init__ ( self , filename , directory = None , ** desc ): super () . __init__ ( ** desc ) self . filename = filename self . directory = directory @property def path ( self ): if self . directory : return pathlib . Path ( self . directory ) . joinpath ( self . filename ) return pathlib . Path ( __file__ ) . parent . joinpath ( self . filename ) @property def _repr_content ( self ): content = super () . _repr_content content [ \"Path\" ] = str ( self . path ) return content","title":"FileDataset"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.GenericFileDataset","text":"Bases: Dataset Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Parameters: Name Type Description Default filename str The file\u2019s name. required directory str The directory where the file is contained. Defaults to the location of the datasets module. None desc dict Extra dataset parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 class GenericFileDataset ( Dataset ): \"\"\"Base class for datasets that are stored in a local file. Small datasets that are part of the spotRiver package inherit from this class. Args: filename (str): The file's name. directory (str): The directory where the file is contained. Defaults to the location of the `datasets` module. desc (dict): Extra dataset parameters to pass as keyword arguments. \"\"\" def __init__ ( self , filename , target , converters , parse_dates , directory = None , ** desc ): super () . __init__ ( ** desc ) self . filename = filename self . directory = directory self . target = target self . converters = converters self . parse_dates = parse_dates @property def path ( self ): if self . directory : return pathlib . Path ( self . directory ) . joinpath ( self . filename ) return pathlib . Path ( __file__ ) . parent . joinpath ( self . filename ) @property def _repr_content ( self ): content = super () . _repr_content content [ \"Path\" ] = str ( self . path ) return content","title":"GenericFileDataset"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.RemoteDataset","text":"Bases: FileDataset Base class for datasets that are stored in a remote file. Medium and large datasets that are not part of the river package inherit from this class. Note The filename doesn\u2019t have to be provided if unpack is False. Indeed in the latter case the filename will be inferred from the URL. Parameters: Name Type Description Default url str The URL the dataset is located at. required size int The expected download size. required unpack bool Whether to unpack the download or not. True filename str An optional name to given to the file if the file is unpacked. None desc dict Extra dataset parameters to pass as keyword arguments. {} Source code in spotRiver/data/base.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 class RemoteDataset ( FileDataset ): \"\"\"Base class for datasets that are stored in a remote file. Medium and large datasets that are not part of the river package inherit from this class. Note: The filename doesn't have to be provided if unpack is False. Indeed in the latter case the filename will be inferred from the URL. Args: url (str): The URL the dataset is located at. size (int): The expected download size. unpack (bool): Whether to unpack the download or not. filename (str): An optional name to given to the file if the file is unpacked. desc (dict): Extra dataset parameters to pass as keyword arguments. \"\"\" def __init__ ( self , url , size , unpack = True , filename = None , ** desc ): if filename is None : filename = path . basename ( url ) super () . __init__ ( filename = filename , ** desc ) self . url = url self . size = size self . unpack = unpack @property def path ( self ): return pathlib . Path ( get_data_home (), self . __class__ . __name__ , self . filename ) def download ( self , force = False , verbose = True ): if not force and self . is_downloaded : return # Determine where to download the archive directory = self . path . parent directory . mkdir ( parents = True , exist_ok = True ) archive_path = directory . joinpath ( path . basename ( self . url )) with request . urlopen ( self . url ) as r : # Notify the user if verbose : meta = r . info () try : n_bytes = int ( meta [ \"Content-Length\" ]) msg = f \"Downloading { self . url } ( { utils . pretty . humanize_bytes ( n_bytes ) } )\" except KeyError : msg = f \"Downloading { self . url } \" print ( msg ) # Now dump the contents of the requests with open ( archive_path , \"wb\" ) as f : shutil . copyfileobj ( r , f ) if not self . unpack : return if verbose : print ( f \"Uncompressing into { directory } \" ) if archive_path . suffix . endswith ( \"zip\" ): with zipfile . ZipFile ( archive_path , \"r\" ) as zf : zf . extractall ( directory ) elif archive_path . suffix . endswith (( \"gz\" , \"tar\" )): mode = \"r:\" if archive_path . suffix . endswith ( \"tar\" ) else \"r:gz\" tar = tarfile . open ( archive_path , mode ) tar . extractall ( directory ) tar . close () else : raise RuntimeError ( f \"Unhandled extension type: { archive_path . suffix } \" ) # Delete the archive file now that it has been uncompressed archive_path . unlink () @abc . abstractmethod def _iter ( self ): pass @property def is_downloaded ( self ): \"\"\"Indicate whether or the data has been correctly downloaded.\"\"\" if self . path . exists (): if self . path . is_file (): return self . path . stat () . st_size == self . size return sum ( f . stat () . st_size for f in self . path . glob ( \"**/*\" ) if f . is_file ()) return False def __iter__ ( self ): if not self . is_downloaded : self . download ( verbose = True ) if not self . is_downloaded : raise RuntimeError ( \"Something went wrong during the download\" ) yield from self . _iter () @property def _repr_content ( self ): content = super () . _repr_content content [ \"URL\" ] = self . url content [ \"Size\" ] = utils . pretty . humanize_bytes ( self . size ) content [ \"Downloaded\" ] = str ( self . is_downloaded ) return content","title":"RemoteDataset"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.RemoteDataset.is_downloaded","text":"Indicate whether or the data has been correctly downloaded. Source code in spotRiver/data/base.py 363 364 365 366 367 368 369 370 371 @property def is_downloaded ( self ): \"\"\"Indicate whether or the data has been correctly downloaded.\"\"\" if self . path . exists (): if self . path . is_file (): return self . path . stat () . st_size == self . size return sum ( f . stat () . st_size for f in self . path . glob ( \"**/*\" ) if f . is_file ()) return False","title":"is_downloaded()"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.SyntheticDataset","text":"Bases: Dataset A synthetic dataset. All synthetic datasets inherit from this class. Source code in spotRiver/data/base.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 class SyntheticDataset ( Dataset ): \"\"\"A synthetic dataset. All synthetic datasets inherit from this class. \"\"\" def __repr__ ( self ): l_len_prop = max ( map ( len , self . _repr_content . keys ())) r_len_prop = max ( map ( len , self . _repr_content . values ())) params = self . _get_params () l_len_config = max ( map ( len , params . keys ())) r_len_config = max ( map ( len , map ( str , params . values ()))) out = ( \"Synthetic data generator \\n\\n \" + \" \\n \" . join ( k . rjust ( l_len_prop ) + \" \" + v . ljust ( r_len_prop ) for k , v in self . _repr_content . items ()) + \" \\n\\n Configuration \\n ------------- \\n \" + \" \\n \" . join ( k . rjust ( l_len_config ) + \" \" + str ( v ) . ljust ( r_len_config ) for k , v in params . items ()) ) return out def _get_params ( self ) -> typing . Dict [ str , typing . Any ]: \"\"\"Return the parameters that were used during initialization.\"\"\" return { name : getattr ( self , name ) for name , param in inspect . signature ( self . __init__ ) . parameters . items () # type: ignore if param . kind != param . VAR_KEYWORD }","title":"SyntheticDataset"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.get_data_home","text":"Return the location where remote datasets are to be stored. By default the data directory is set to a folder named \u2018spotriver_data\u2019 in the user home folder. Alternatively, it can be set by the \u2018SPOTRIVER_DATA\u2019 environment variable or programmatically by giving an explicit folder path. The \u2018~\u2019 symbol is expanded to the user home folder. If the folder does not already exist, it is automatically created. Parameters: Name Type Description Default data_home str The path to spotriver data directory. If None , the default path is ~/spotriver_data . None Returns: Name Type Description data_home str The path to the spotriver data directory. Source code in spotRiver/data/base.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def get_data_home ( data_home = None ) -> str : \"\"\"Return the location where remote datasets are to be stored. By default the data directory is set to a folder named 'spotriver_data' in the user home folder. Alternatively, it can be set by the 'SPOTRIVER_DATA' environment variable or programmatically by giving an explicit folder path. The '~' symbol is expanded to the user home folder. If the folder does not already exist, it is automatically created. Args: data_home (str): The path to spotriver data directory. If `None`, the default path is `~/spotriver_data`. Returns: data_home (str): The path to the spotriver data directory. \"\"\" if data_home is None : data_home = environ . get ( \"SPOTRIVER_DATA\" , Path . home () / \"spotriver_data\" ) # Ensure data_home is a Path() object pointing to an absolute path data_home = Path ( data_home ) . absolute () # Create data directory if it does not exists. data_home . mkdir ( parents = True , exist_ok = True ) return data_home","title":"get_data_home()"},{"location":"reference/spotRiver/data/bike_sharing/","text":"get_bike_sharing_data ( train_size = 0.6 ) \u00b6 Fetches the Bike Sharing Demand dataset from OpenML and splits it into training and test sets. Parameters: Name Type Description Default train_size float The proportion of the dataset to include in the training set. Default value: 0.6 0.6 Returns: Type Description tuple tuple containing: df (pd.DataFrame): The full dataset. train (pd.DataFrame): The training set. test (pd.DataFrame): The test set. Examples: >>> from spotRiver.data.bike_sharing import get_bike_sharing_data >>> df , train , test = get_bike_sharing_data ( train_size = 0.6 ) Source code in spotRiver/data/bike_sharing.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def get_bike_sharing_data ( train_size = 0.6 ): \"\"\" Fetches the Bike Sharing Demand dataset from OpenML and splits it into training and test sets. Args: train_size (float): The proportion of the dataset to include in the training set. Default value: 0.6 Returns: (tuple): tuple containing: df (pd.DataFrame): The full dataset. train (pd.DataFrame): The training set. test (pd.DataFrame): The test set. Examples: >>> from spotRiver.data.bike_sharing import get_bike_sharing_data >>> df, train, test = get_bike_sharing_data(train_size=0.6) \"\"\" bike_sharing = fetch_openml ( \"Bike_Sharing_Demand\" , version = 2 , as_frame = True , parser = \"pandas\" ) df = bike_sharing . frame # Normalize the count column df [ \"count\" ] = df [ \"count\" ] / df [ \"count\" ] . max () # Replace heavy_rain with rain in the weather column df [ \"weather\" ] . replace ( to_replace = \"heavy_rain\" , value = \"rain\" , inplace = True ) n = df . shape [ 0 ] # Calculate the number of rows in the training set k = int ( n * train_size ) # Split the data into training and test sets train = df [ 0 : k ] test = df [ k : n ] return df , train , test","title":"bike_sharing"},{"location":"reference/spotRiver/data/bike_sharing/#spotRiver.data.bike_sharing.get_bike_sharing_data","text":"Fetches the Bike Sharing Demand dataset from OpenML and splits it into training and test sets. Parameters: Name Type Description Default train_size float The proportion of the dataset to include in the training set. Default value: 0.6 0.6 Returns: Type Description tuple tuple containing: df (pd.DataFrame): The full dataset. train (pd.DataFrame): The training set. test (pd.DataFrame): The test set. Examples: >>> from spotRiver.data.bike_sharing import get_bike_sharing_data >>> df , train , test = get_bike_sharing_data ( train_size = 0.6 ) Source code in spotRiver/data/bike_sharing.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def get_bike_sharing_data ( train_size = 0.6 ): \"\"\" Fetches the Bike Sharing Demand dataset from OpenML and splits it into training and test sets. Args: train_size (float): The proportion of the dataset to include in the training set. Default value: 0.6 Returns: (tuple): tuple containing: df (pd.DataFrame): The full dataset. train (pd.DataFrame): The training set. test (pd.DataFrame): The test set. Examples: >>> from spotRiver.data.bike_sharing import get_bike_sharing_data >>> df, train, test = get_bike_sharing_data(train_size=0.6) \"\"\" bike_sharing = fetch_openml ( \"Bike_Sharing_Demand\" , version = 2 , as_frame = True , parser = \"pandas\" ) df = bike_sharing . frame # Normalize the count column df [ \"count\" ] = df [ \"count\" ] / df [ \"count\" ] . max () # Replace heavy_rain with rain in the weather column df [ \"weather\" ] . replace ( to_replace = \"heavy_rain\" , value = \"rain\" , inplace = True ) n = df . shape [ 0 ] # Calculate the number of rows in the training set k = int ( n * train_size ) # Split the data into training and test sets train = df [ 0 : k ] test = df [ k : n ] return df , train , test","title":"get_bike_sharing_data()"},{"location":"reference/spotRiver/data/generic/","text":"GenericData \u00b6 Bases: base . GenericFileDataset A class for handling generic data. This class inherits from the base.GenericFileDataset class and provides an interface for handling generic data. Parameters: Name Type Description Default filename str The name of the file containing the data. required target str The name of the target column. required n_features int The number of features in the dataset. required n_samples int The number of samples in the dataset. required converters Dict [ str , callable ] A dictionary of functions for converting column data. required parse_dates List [ str ] A list of column names to parse as dates. required directory str The directory where the file is located. required task str The type of task. Default is base.REG for regression. base.REG fraction float The fraction of the data to use. Default is 1.0 for all data. 1.0 Returns: Type Description Generator An iterator over the data in the file. Examples: >>> from spotRiver.data.generic import GenericData import importlib.resources as pkg_resources import spotRiver.data as data inp_file = pkg_resources.files(data) csv_path = str(inp_file.resolve()) dataset = GenericData(filename=\"UnivariateData.csv\", directory=csv_path, target=\"Consumption\", n_features=1, n_samples=51_706, converters={\"Consumption\": float}, parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"}) for x, y in dataset: print(x, y) break {'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217 Source code in spotRiver/data/generic.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class GenericData ( base . GenericFileDataset ): \"\"\"A class for handling generic data. This class inherits from the base.GenericFileDataset class and provides an interface for handling generic data. Args: filename (str): The name of the file containing the data. target (str): The name of the target column. n_features (int): The number of features in the dataset. n_samples (int): The number of samples in the dataset. converters (Dict[str, callable]): A dictionary of functions for converting column data. parse_dates (List[str]): A list of column names to parse as dates. directory (str): The directory where the file is located. task (str): The type of task. Default is base.REG for regression. fraction (float): The fraction of the data to use. Default is 1.0 for all data. Returns: (Generator): An iterator over the data in the file. Examples: >>> from spotRiver.data.generic import GenericData import importlib.resources as pkg_resources import spotRiver.data as data inp_file = pkg_resources.files(data) csv_path = str(inp_file.resolve()) dataset = GenericData(filename=\"UnivariateData.csv\", directory=csv_path, target=\"Consumption\", n_features=1, n_samples=51_706, converters={\"Consumption\": float}, parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"}) for x, y in dataset: print(x, y) break {'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217 \"\"\" def __init__ ( self , filename : str , target : str , n_features : int , n_samples : int , converters : Dict [ str , callable ], parse_dates : List [ str ], directory : str , task : str = base . REG , fraction : float = 1.0 ): super () . __init__ ( filename = filename , n_features = n_features , n_samples = n_samples , task = task , target = target , converters = converters , parse_dates = parse_dates , directory = directory , ) self . fraction = fraction def __iter__ ( self ) -> Union [ Dict [ str , float ], float ]: return stream . iter_csv ( self . path , target = self . target , converters = self . converters , parse_dates = self . parse_dates , fraction = self . fraction , seed = 123 , )","title":"generic"},{"location":"reference/spotRiver/data/generic/#spotRiver.data.generic.GenericData","text":"Bases: base . GenericFileDataset A class for handling generic data. This class inherits from the base.GenericFileDataset class and provides an interface for handling generic data. Parameters: Name Type Description Default filename str The name of the file containing the data. required target str The name of the target column. required n_features int The number of features in the dataset. required n_samples int The number of samples in the dataset. required converters Dict [ str , callable ] A dictionary of functions for converting column data. required parse_dates List [ str ] A list of column names to parse as dates. required directory str The directory where the file is located. required task str The type of task. Default is base.REG for regression. base.REG fraction float The fraction of the data to use. Default is 1.0 for all data. 1.0 Returns: Type Description Generator An iterator over the data in the file. Examples: >>> from spotRiver.data.generic import GenericData import importlib.resources as pkg_resources import spotRiver.data as data inp_file = pkg_resources.files(data) csv_path = str(inp_file.resolve()) dataset = GenericData(filename=\"UnivariateData.csv\", directory=csv_path, target=\"Consumption\", n_features=1, n_samples=51_706, converters={\"Consumption\": float}, parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"}) for x, y in dataset: print(x, y) break {'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217 Source code in spotRiver/data/generic.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class GenericData ( base . GenericFileDataset ): \"\"\"A class for handling generic data. This class inherits from the base.GenericFileDataset class and provides an interface for handling generic data. Args: filename (str): The name of the file containing the data. target (str): The name of the target column. n_features (int): The number of features in the dataset. n_samples (int): The number of samples in the dataset. converters (Dict[str, callable]): A dictionary of functions for converting column data. parse_dates (List[str]): A list of column names to parse as dates. directory (str): The directory where the file is located. task (str): The type of task. Default is base.REG for regression. fraction (float): The fraction of the data to use. Default is 1.0 for all data. Returns: (Generator): An iterator over the data in the file. Examples: >>> from spotRiver.data.generic import GenericData import importlib.resources as pkg_resources import spotRiver.data as data inp_file = pkg_resources.files(data) csv_path = str(inp_file.resolve()) dataset = GenericData(filename=\"UnivariateData.csv\", directory=csv_path, target=\"Consumption\", n_features=1, n_samples=51_706, converters={\"Consumption\": float}, parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"}) for x, y in dataset: print(x, y) break {'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217 \"\"\" def __init__ ( self , filename : str , target : str , n_features : int , n_samples : int , converters : Dict [ str , callable ], parse_dates : List [ str ], directory : str , task : str = base . REG , fraction : float = 1.0 ): super () . __init__ ( filename = filename , n_features = n_features , n_samples = n_samples , task = task , target = target , converters = converters , parse_dates = parse_dates , directory = directory , ) self . fraction = fraction def __iter__ ( self ) -> Union [ Dict [ str , float ], float ]: return stream . iter_csv ( self . path , target = self . target , converters = self . converters , parse_dates = self . parse_dates , fraction = self . fraction , seed = 123 , )","title":"GenericData"},{"location":"reference/spotRiver/data/opm/","text":"Office of Policy and Management dataset The original database is available from CT\u2019s OPM https://portal.ct.gov/OPM/IGPP/Publications/Real-Estate-Sales-Listing The data contains 985,862 observations of up to 14 variables. fetch_opm ( * , data_home = None , download_if_missing = True , return_X_y = False , include_numeric = True , include_categorical = False ) \u00b6 Fetch the OPM dataset from the Connecticut Open Data portal. Parameters \u00b6 str or pathlib.Path, default=None Specify another download and cache folder for the datasets. By default all spotRiver data is stored in \u2018~/spotriver_data\u2019 subfolders. bool, default=True If False, raise an IOError if the data is not locally available rather than trying to download the data from the source site. bool, default=False If True, return (X, y) instead of a Bunch object. See sklearn.utils.Bunch for more information. bool, default=True If True, include numeric columns in the output. Numeric columns include \u2018List Year\u2019, \u2018Assessed Value\u2019, \u2018Sale Amount\u2019, \u2018Sales Ratio\u2019, \u2018lat\u2019, \u2018lon\u2019, and \u2018timestamp_rec\u2019. bool, default=False If True, include categorical columns in the output. Categorical columns include \u2018Town\u2019, \u2018Address\u2019, \u2018Property Type\u2019, \u2018Residential Type\u2019, \u2018Non Use Code\u2019, \u2018Assessor Remarks\u2019, and \u2018OPM remarks\u2019. Columns with fewer than 200 unique values will be treated as categorical. Returns \u00b6 Bunch or Tuple[pd.DataFrame, pd.Series] or pd.DataFrame If return_X_y is False, return a Bunch object with the following attributes: * data : pd.DataFrame of shape (n_samples, n_features) The feature matrix. * target : pd.Series of shape (n_samples,) The target vector. * DESCR : str A short description of the dataset. If return_X_y is True, return a tuple (X, y) where X is the feature matrix and y is the target vector. If only numeric or categorical columns are included in the output, return a pd.DataFrame instead of a Bunch. Examples \u00b6 from spotRiver.data import fetch_opm # Fetch the OPM dataset and return a pandas DataFrame opm_df = fetch_opm() # Fetch the OPM dataset, include categorical columns, and return a Bunch object opm_data = fetch_opm(include_numeric=False, include_categorical=True, return_X_y=False) # Fetch the OPM dataset, include numeric and categorical columns, and return a tuple of pandas DataFrames X, y = fetch_opm(include_categorical=True, return_X_y=True) Source code in spotRiver/data/opm.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 def fetch_opm ( * , data_home : Union [ str , Path ] = None , download_if_missing : bool = True , return_X_y : bool = False , include_numeric : bool = True , include_categorical : bool = False , ) -> Union [ Tuple [ pd . DataFrame , pd . Series ], pd . DataFrame , Bunch ]: \"\"\"Fetch the OPM dataset from the Connecticut Open Data portal. Parameters ---------- data_home : str or pathlib.Path, default=None Specify another download and cache folder for the datasets. By default all spotRiver data is stored in '~/spotriver_data' subfolders. download_if_missing : bool, default=True If False, raise an IOError if the data is not locally available rather than trying to download the data from the source site. return_X_y : bool, default=False If True, return `(X, y)` instead of a `Bunch` object. See `sklearn.utils.Bunch` for more information. include_numeric : bool, default=True If True, include numeric columns in the output. Numeric columns include 'List Year', 'Assessed Value', 'Sale Amount', 'Sales Ratio', 'lat', 'lon', and 'timestamp_rec'. include_categorical : bool, default=False If True, include categorical columns in the output. Categorical columns include 'Town', 'Address', 'Property Type', 'Residential Type', 'Non Use Code', 'Assessor Remarks', and 'OPM remarks'. Columns with fewer than 200 unique values will be treated as categorical. Returns ------- Bunch or Tuple[pd.DataFrame, pd.Series] or pd.DataFrame If `return_X_y` is False, return a `Bunch` object with the following attributes: * data : pd.DataFrame of shape (n_samples, n_features) The feature matrix. * target : pd.Series of shape (n_samples,) The target vector. * DESCR : str A short description of the dataset. If `return_X_y` is True, return a tuple `(X, y)` where `X` is the feature matrix and `y` is the target vector. If only numeric or categorical columns are included in the output, return a pd.DataFrame instead of a Bunch. Examples -------- >>> from spotRiver.data import fetch_opm # Fetch the OPM dataset and return a pandas DataFrame opm_df = fetch_opm() # Fetch the OPM dataset, include categorical columns, and return a Bunch object opm_data = fetch_opm(include_numeric=False, include_categorical=True, return_X_y=False) # Fetch the OPM dataset, include numeric and categorical columns, and return a tuple of pandas DataFrames X, y = fetch_opm(include_categorical=True, return_X_y=True) \"\"\" filename = get_data_home ( data_home = data_home ) / \"opm_2001-2020.csv\" if not filename . is_file (): if not download_if_missing : raise IOError ( \"Data not found and `download_if_missing` is False\" ) logger . info ( f \"Downloading OPM dataset to ' { filename } '.\" ) urlretrieve ( url = OPM_URL , filename = filename ) # FIXME: Add hash check for download. df = pd . read_csv ( filename , dtype = OPM_DTYPE , parse_dates = [ \"Date Recorded\" ]) # Collect rows (observations) we want to keep and subset only once. # # This might look kind of ugly but is much more efficient than making copy # after copy of the (largish) data frame `df`. idx = ( ( df [ \"Date Recorded\" ] >= \"2001-09-30\" ) & ( df [ \"Assessed Value\" ] >= 2000 ) & ( df [ \"Assessed Value\" ] <= 1e8 ) & ( df [ \"Sale Amount\" ] >= 2000 ) & ( df [ \"Sale Amount\" ] <= 2e8 ) ) logger . debug ( f \"Removing { len ( idx ) - idx . sum () } rows for constraint violations.\" ) # Now keep only those rows which we selected with `idx`, sort the values by # the date on which they were recorded and then reset the index. df = df . loc [ idx ] . sort_values ( by = \"Date Recorded\" ) . reset_index ( drop = True ) cols = [] if include_numeric : # Extract latitude and longitude from Location field. # Converting to float32 looses precision. df [[ \"lon\" , \"lat\" ]] = df [ \"Location\" ] . str . extract ( r \"POINT \\((-?\\d+\\.\\d+) (-?\\d+\\.\\d+)\\)\" ) . astype ( \"float\" ) # Check if points are inside the bounding box for CT. # Bounding box taken from https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/ outside_bbox = ( ( df [ \"lon\" ] < - 73.727775 ) | ( df [ \"lon\" ] > - 71.786994 ) | ( df [ \"lat\" ] < 40.980144 ) | ( df [ \"lat\" ] > 42.050587 ) ) df . loc [ outside_bbox , [ \"lon\" , \"lat\" ]] = np . nan logger . debug ( f \"Found { outside_bbox . sum () } locations outside of CT's bounding box.\" ) # Convert types to smaller types to save some space. df [ \"List Year\" ] = df [ \"List Year\" ] . astype ( \"int16\" ) # Add timestamp column by converting the Date Recorded to nanoseconds since epoch # and divide by 1e9 to go from nanoseconds to seconds since epoch. df [ \"timestamp_rec\" ] = df [ \"Date Recorded\" ] . astype ( \"int64\" ) // 1e9 # Converting `Assessed Value` to float32 changes 159 values df [ \"Assessed Value\" ] = df [ \"Assessed Value\" ] . astype ( \"int32\" ) # Converting `Assessed Value` to int32/float32 changes 175/222 values # df[\"Sale Amount\"] = df[\"Sale Amount\"].astype(\"int32\") cols . extend ([ \"List Year\" , \"Assessed Value\" , \"Sale Amount\" , \"Sales Ratio\" , \"lat\" , \"lon\" , \"timestamp_rec\" ]) # FIXME: We probably want to invest some time into deriving more meaninfgul # categorical variables from some of these. Especially the remarks columns # would benefit from a BoW approach and the Address column really carries very # little information. if include_categorical : categorical_columns = [ \"Town\" , \"Address\" , \"Property Type\" , \"Residential Type\" , \"Non Use Code\" , \"Assessor Remarks\" , \"OPM remarks\" , ] cols . extend ( categorical_columns ) for cat_col in categorical_columns : df [ cat_col ] = df [ cat_col ] . fillna ( \"Unknown\" ) # If there less than 200 unique values, convert to \"category\" # instead of storing as a string to save space. if df [ cat_col ] . nunique () < 200 : df [ cat_col ] = df [ cat_col ] . astype ( \"category\" ) if len ( cols ) == 0 : raise Exception ( \"No columns selected. Did you set both `include_numeric` and `include_categorical` to False?\" ) X = df [ cols ] # y = df[\"Sale Amount\"] y = X . pop ( \"Sale Amount\" ) if return_X_y : return ( X , y ) return Bunch ( data = X , target = y )","title":"opm"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm","text":"Fetch the OPM dataset from the Connecticut Open Data portal.","title":"fetch_opm()"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm--parameters","text":"str or pathlib.Path, default=None Specify another download and cache folder for the datasets. By default all spotRiver data is stored in \u2018~/spotriver_data\u2019 subfolders. bool, default=True If False, raise an IOError if the data is not locally available rather than trying to download the data from the source site. bool, default=False If True, return (X, y) instead of a Bunch object. See sklearn.utils.Bunch for more information. bool, default=True If True, include numeric columns in the output. Numeric columns include \u2018List Year\u2019, \u2018Assessed Value\u2019, \u2018Sale Amount\u2019, \u2018Sales Ratio\u2019, \u2018lat\u2019, \u2018lon\u2019, and \u2018timestamp_rec\u2019. bool, default=False If True, include categorical columns in the output. Categorical columns include \u2018Town\u2019, \u2018Address\u2019, \u2018Property Type\u2019, \u2018Residential Type\u2019, \u2018Non Use Code\u2019, \u2018Assessor Remarks\u2019, and \u2018OPM remarks\u2019. Columns with fewer than 200 unique values will be treated as categorical.","title":"Parameters"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm--returns","text":"Bunch or Tuple[pd.DataFrame, pd.Series] or pd.DataFrame If return_X_y is False, return a Bunch object with the following attributes: * data : pd.DataFrame of shape (n_samples, n_features) The feature matrix. * target : pd.Series of shape (n_samples,) The target vector. * DESCR : str A short description of the dataset. If return_X_y is True, return a tuple (X, y) where X is the feature matrix and y is the target vector. If only numeric or categorical columns are included in the output, return a pd.DataFrame instead of a Bunch.","title":"Returns"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm--examples","text":"from spotRiver.data import fetch_opm # Fetch the OPM dataset and return a pandas DataFrame opm_df = fetch_opm() # Fetch the OPM dataset, include categorical columns, and return a Bunch object opm_data = fetch_opm(include_numeric=False, include_categorical=True, return_X_y=False) # Fetch the OPM dataset, include numeric and categorical columns, and return a tuple of pandas DataFrames X, y = fetch_opm(include_categorical=True, return_X_y=True) Source code in spotRiver/data/opm.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 def fetch_opm ( * , data_home : Union [ str , Path ] = None , download_if_missing : bool = True , return_X_y : bool = False , include_numeric : bool = True , include_categorical : bool = False , ) -> Union [ Tuple [ pd . DataFrame , pd . Series ], pd . DataFrame , Bunch ]: \"\"\"Fetch the OPM dataset from the Connecticut Open Data portal. Parameters ---------- data_home : str or pathlib.Path, default=None Specify another download and cache folder for the datasets. By default all spotRiver data is stored in '~/spotriver_data' subfolders. download_if_missing : bool, default=True If False, raise an IOError if the data is not locally available rather than trying to download the data from the source site. return_X_y : bool, default=False If True, return `(X, y)` instead of a `Bunch` object. See `sklearn.utils.Bunch` for more information. include_numeric : bool, default=True If True, include numeric columns in the output. Numeric columns include 'List Year', 'Assessed Value', 'Sale Amount', 'Sales Ratio', 'lat', 'lon', and 'timestamp_rec'. include_categorical : bool, default=False If True, include categorical columns in the output. Categorical columns include 'Town', 'Address', 'Property Type', 'Residential Type', 'Non Use Code', 'Assessor Remarks', and 'OPM remarks'. Columns with fewer than 200 unique values will be treated as categorical. Returns ------- Bunch or Tuple[pd.DataFrame, pd.Series] or pd.DataFrame If `return_X_y` is False, return a `Bunch` object with the following attributes: * data : pd.DataFrame of shape (n_samples, n_features) The feature matrix. * target : pd.Series of shape (n_samples,) The target vector. * DESCR : str A short description of the dataset. If `return_X_y` is True, return a tuple `(X, y)` where `X` is the feature matrix and `y` is the target vector. If only numeric or categorical columns are included in the output, return a pd.DataFrame instead of a Bunch. Examples -------- >>> from spotRiver.data import fetch_opm # Fetch the OPM dataset and return a pandas DataFrame opm_df = fetch_opm() # Fetch the OPM dataset, include categorical columns, and return a Bunch object opm_data = fetch_opm(include_numeric=False, include_categorical=True, return_X_y=False) # Fetch the OPM dataset, include numeric and categorical columns, and return a tuple of pandas DataFrames X, y = fetch_opm(include_categorical=True, return_X_y=True) \"\"\" filename = get_data_home ( data_home = data_home ) / \"opm_2001-2020.csv\" if not filename . is_file (): if not download_if_missing : raise IOError ( \"Data not found and `download_if_missing` is False\" ) logger . info ( f \"Downloading OPM dataset to ' { filename } '.\" ) urlretrieve ( url = OPM_URL , filename = filename ) # FIXME: Add hash check for download. df = pd . read_csv ( filename , dtype = OPM_DTYPE , parse_dates = [ \"Date Recorded\" ]) # Collect rows (observations) we want to keep and subset only once. # # This might look kind of ugly but is much more efficient than making copy # after copy of the (largish) data frame `df`. idx = ( ( df [ \"Date Recorded\" ] >= \"2001-09-30\" ) & ( df [ \"Assessed Value\" ] >= 2000 ) & ( df [ \"Assessed Value\" ] <= 1e8 ) & ( df [ \"Sale Amount\" ] >= 2000 ) & ( df [ \"Sale Amount\" ] <= 2e8 ) ) logger . debug ( f \"Removing { len ( idx ) - idx . sum () } rows for constraint violations.\" ) # Now keep only those rows which we selected with `idx`, sort the values by # the date on which they were recorded and then reset the index. df = df . loc [ idx ] . sort_values ( by = \"Date Recorded\" ) . reset_index ( drop = True ) cols = [] if include_numeric : # Extract latitude and longitude from Location field. # Converting to float32 looses precision. df [[ \"lon\" , \"lat\" ]] = df [ \"Location\" ] . str . extract ( r \"POINT \\((-?\\d+\\.\\d+) (-?\\d+\\.\\d+)\\)\" ) . astype ( \"float\" ) # Check if points are inside the bounding box for CT. # Bounding box taken from https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/ outside_bbox = ( ( df [ \"lon\" ] < - 73.727775 ) | ( df [ \"lon\" ] > - 71.786994 ) | ( df [ \"lat\" ] < 40.980144 ) | ( df [ \"lat\" ] > 42.050587 ) ) df . loc [ outside_bbox , [ \"lon\" , \"lat\" ]] = np . nan logger . debug ( f \"Found { outside_bbox . sum () } locations outside of CT's bounding box.\" ) # Convert types to smaller types to save some space. df [ \"List Year\" ] = df [ \"List Year\" ] . astype ( \"int16\" ) # Add timestamp column by converting the Date Recorded to nanoseconds since epoch # and divide by 1e9 to go from nanoseconds to seconds since epoch. df [ \"timestamp_rec\" ] = df [ \"Date Recorded\" ] . astype ( \"int64\" ) // 1e9 # Converting `Assessed Value` to float32 changes 159 values df [ \"Assessed Value\" ] = df [ \"Assessed Value\" ] . astype ( \"int32\" ) # Converting `Assessed Value` to int32/float32 changes 175/222 values # df[\"Sale Amount\"] = df[\"Sale Amount\"].astype(\"int32\") cols . extend ([ \"List Year\" , \"Assessed Value\" , \"Sale Amount\" , \"Sales Ratio\" , \"lat\" , \"lon\" , \"timestamp_rec\" ]) # FIXME: We probably want to invest some time into deriving more meaninfgul # categorical variables from some of these. Especially the remarks columns # would benefit from a BoW approach and the Address column really carries very # little information. if include_categorical : categorical_columns = [ \"Town\" , \"Address\" , \"Property Type\" , \"Residential Type\" , \"Non Use Code\" , \"Assessor Remarks\" , \"OPM remarks\" , ] cols . extend ( categorical_columns ) for cat_col in categorical_columns : df [ cat_col ] = df [ cat_col ] . fillna ( \"Unknown\" ) # If there less than 200 unique values, convert to \"category\" # instead of storing as a string to save space. if df [ cat_col ] . nunique () < 200 : df [ cat_col ] = df [ cat_col ] . astype ( \"category\" ) if len ( cols ) == 0 : raise Exception ( \"No columns selected. Did you set both `include_numeric` and `include_categorical` to False?\" ) X = df [ cols ] # y = df[\"Sale Amount\"] y = X . pop ( \"Sale Amount\" ) if return_X_y : return ( X , y ) return Bunch ( data = X , target = y )","title":"Examples"},{"location":"reference/spotRiver/data/river_hyper_dict/","text":"RiverHyperDict \u00b6 Bases: base . FileConfig River hyperparameter dictionary. Source code in spotRiver/data/river_hyper_dict.py 5 6 7 8 9 10 11 12 13 14 15 16 class RiverHyperDict ( base . FileConfig ): \"\"\"River hyperparameter dictionary.\"\"\" def __init__ ( self ): super () . __init__ ( filename = \"river_hyper_dict.json\" , ) def load ( self ): with open ( self . path , \"r\" ) as f : d = json . load ( f ) return d","title":"river_hyper_dict"},{"location":"reference/spotRiver/data/river_hyper_dict/#spotRiver.data.river_hyper_dict.RiverHyperDict","text":"Bases: base . FileConfig River hyperparameter dictionary. Source code in spotRiver/data/river_hyper_dict.py 5 6 7 8 9 10 11 12 13 14 15 16 class RiverHyperDict ( base . FileConfig ): \"\"\"River hyperparameter dictionary.\"\"\" def __init__ ( self ): super () . __init__ ( filename = \"river_hyper_dict.json\" , ) def load ( self ): with open ( self . path , \"r\" ) as f : d = json . load ( f ) return d","title":"RiverHyperDict"},{"location":"reference/spotRiver/data/synth/","text":"Synthetic datasets. Each synthetic dataset is a stream generator. The benefit of using a generator is that they do not store the data and each data sample is generated on the fly. Except for a couple of methods, the majority of these methods are infinite data generators. SEA \u00b6 Bases: datasets . base . SyntheticDataset SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. Variant 0 : True if att1 + att2 > 8 Variant 1 : True if att1 + att2 > 9 Variant 2 : True if att1 + att2 > 7 Variant 3 : True if att1 + att2 > 9.5 Parameters: Name Type Description Default variant int The variant of the data stream to use. Can be 0, 1, 2, or 3. 0 noise float The probability of generating label noise. 0.0 seed int Random seed for reproducibility. None Returns: Type Description Generator A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References [1]: A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification Source code in spotRiver/data/synth/sea.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class SEA ( datasets . base . SyntheticDataset ): \"\"\"SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. * **Variant 0**: `True` if `att1 + att2 > 8` * **Variant 1**: `True` if `att1 + att2 > 9` * **Variant 2**: `True` if `att1 + att2 > 7` * **Variant 3**: `True` if `att1 + att2 > 9.5` Args: variant (int): The variant of the data stream to use. Can be 0, 1, 2, or 3. noise (float): The probability of generating label noise. seed (int): Random seed for reproducibility. Returns: (Generator): A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References: [1]: [A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.482.3991&rep=rep1&type=pdf) \"\"\" def __init__ ( self , variant = 0 , noise = 0.0 , seed : int = None ): super () . __init__ ( n_features = 3 , task = datasets . base . BINARY_CLF ) if variant not in ( 0 , 1 , 2 , 3 ): raise ValueError ( \"Unknown variant, possible choices are: 0, 1, 2, 3\" ) self . variant = variant self . noise = noise self . seed = seed self . _threshold = { 0 : 8 , 1 : 9 , 2 : 7 , 3 : 9.5 }[ variant ] def __iter__ ( self ): rng = random . Random ( self . seed ) while True : x = { i : rng . uniform ( 0 , 10 ) for i in range ( 3 )} y = x [ 0 ] + x [ 1 ] > self . _threshold if self . noise and rng . random () < self . noise : y = not y yield x , y @property def _repr_content ( self ): return { ** super () . _repr_content , \"Variant\" : str ( self . variant )}","title":"synth"},{"location":"reference/spotRiver/data/synth/#spotRiver.data.synth.SEA","text":"Bases: datasets . base . SyntheticDataset SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. Variant 0 : True if att1 + att2 > 8 Variant 1 : True if att1 + att2 > 9 Variant 2 : True if att1 + att2 > 7 Variant 3 : True if att1 + att2 > 9.5 Parameters: Name Type Description Default variant int The variant of the data stream to use. Can be 0, 1, 2, or 3. 0 noise float The probability of generating label noise. 0.0 seed int Random seed for reproducibility. None Returns: Type Description Generator A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References [1]: A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification Source code in spotRiver/data/synth/sea.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class SEA ( datasets . base . SyntheticDataset ): \"\"\"SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. * **Variant 0**: `True` if `att1 + att2 > 8` * **Variant 1**: `True` if `att1 + att2 > 9` * **Variant 2**: `True` if `att1 + att2 > 7` * **Variant 3**: `True` if `att1 + att2 > 9.5` Args: variant (int): The variant of the data stream to use. Can be 0, 1, 2, or 3. noise (float): The probability of generating label noise. seed (int): Random seed for reproducibility. Returns: (Generator): A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References: [1]: [A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.482.3991&rep=rep1&type=pdf) \"\"\" def __init__ ( self , variant = 0 , noise = 0.0 , seed : int = None ): super () . __init__ ( n_features = 3 , task = datasets . base . BINARY_CLF ) if variant not in ( 0 , 1 , 2 , 3 ): raise ValueError ( \"Unknown variant, possible choices are: 0, 1, 2, 3\" ) self . variant = variant self . noise = noise self . seed = seed self . _threshold = { 0 : 8 , 1 : 9 , 2 : 7 , 3 : 9.5 }[ variant ] def __iter__ ( self ): rng = random . Random ( self . seed ) while True : x = { i : rng . uniform ( 0 , 10 ) for i in range ( 3 )} y = x [ 0 ] + x [ 1 ] > self . _threshold if self . noise and rng . random () < self . noise : y = not y yield x , y @property def _repr_content ( self ): return { ** super () . _repr_content , \"Variant\" : str ( self . variant )}","title":"SEA"},{"location":"reference/spotRiver/data/synth/sea/","text":"SEA \u00b6 Bases: datasets . base . SyntheticDataset SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. Variant 0 : True if att1 + att2 > 8 Variant 1 : True if att1 + att2 > 9 Variant 2 : True if att1 + att2 > 7 Variant 3 : True if att1 + att2 > 9.5 Parameters: Name Type Description Default variant int The variant of the data stream to use. Can be 0, 1, 2, or 3. 0 noise float The probability of generating label noise. 0.0 seed int Random seed for reproducibility. None Returns: Type Description Generator A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References [1]: A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification Source code in spotRiver/data/synth/sea.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class SEA ( datasets . base . SyntheticDataset ): \"\"\"SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. * **Variant 0**: `True` if `att1 + att2 > 8` * **Variant 1**: `True` if `att1 + att2 > 9` * **Variant 2**: `True` if `att1 + att2 > 7` * **Variant 3**: `True` if `att1 + att2 > 9.5` Args: variant (int): The variant of the data stream to use. Can be 0, 1, 2, or 3. noise (float): The probability of generating label noise. seed (int): Random seed for reproducibility. Returns: (Generator): A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References: [1]: [A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.482.3991&rep=rep1&type=pdf) \"\"\" def __init__ ( self , variant = 0 , noise = 0.0 , seed : int = None ): super () . __init__ ( n_features = 3 , task = datasets . base . BINARY_CLF ) if variant not in ( 0 , 1 , 2 , 3 ): raise ValueError ( \"Unknown variant, possible choices are: 0, 1, 2, 3\" ) self . variant = variant self . noise = noise self . seed = seed self . _threshold = { 0 : 8 , 1 : 9 , 2 : 7 , 3 : 9.5 }[ variant ] def __iter__ ( self ): rng = random . Random ( self . seed ) while True : x = { i : rng . uniform ( 0 , 10 ) for i in range ( 3 )} y = x [ 0 ] + x [ 1 ] > self . _threshold if self . noise and rng . random () < self . noise : y = not y yield x , y @property def _repr_content ( self ): return { ** super () . _repr_content , \"Variant\" : str ( self . variant )}","title":"sea"},{"location":"reference/spotRiver/data/synth/sea/#spotRiver.data.synth.sea.SEA","text":"Bases: datasets . base . SyntheticDataset SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. Variant 0 : True if att1 + att2 > 8 Variant 1 : True if att1 + att2 > 9 Variant 2 : True if att1 + att2 > 7 Variant 3 : True if att1 + att2 > 9.5 Parameters: Name Type Description Default variant int The variant of the data stream to use. Can be 0, 1, 2, or 3. 0 noise float The probability of generating label noise. 0.0 seed int Random seed for reproducibility. None Returns: Type Description Generator A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References [1]: A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification Source code in spotRiver/data/synth/sea.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class SEA ( datasets . base . SyntheticDataset ): \"\"\"SEA synthetic dataset. Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream. * **Variant 0**: `True` if `att1 + att2 > 8` * **Variant 1**: `True` if `att1 + att2 > 9` * **Variant 2**: `True` if `att1 + att2 > 7` * **Variant 3**: `True` if `att1 + att2 > 9.5` Args: variant (int): The variant of the data stream to use. Can be 0, 1, 2, or 3. noise (float): The probability of generating label noise. seed (int): Random seed for reproducibility. Returns: (Generator): A generator of features and labels. Examples: >>> from spotRiver.data.synth import SEA dataset = synth.SEA(variant=0, seed=42) for x, y in dataset.take(5): print(x, y) {0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False References: [1]: [A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.482.3991&rep=rep1&type=pdf) \"\"\" def __init__ ( self , variant = 0 , noise = 0.0 , seed : int = None ): super () . __init__ ( n_features = 3 , task = datasets . base . BINARY_CLF ) if variant not in ( 0 , 1 , 2 , 3 ): raise ValueError ( \"Unknown variant, possible choices are: 0, 1, 2, 3\" ) self . variant = variant self . noise = noise self . seed = seed self . _threshold = { 0 : 8 , 1 : 9 , 2 : 7 , 3 : 9.5 }[ variant ] def __iter__ ( self ): rng = random . Random ( self . seed ) while True : x = { i : rng . uniform ( 0 , 10 ) for i in range ( 3 )} y = x [ 0 ] + x [ 1 ] > self . _threshold if self . noise and rng . random () < self . noise : y = not y yield x , y @property def _repr_content ( self ): return { ** super () . _repr_content , \"Variant\" : str ( self . variant )}","title":"SEA"},{"location":"reference/spotRiver/drift/drift_generator/","text":"generate_drift ( data , drift_values = [ 1.1 , 10.0 , 0.1 , 1.1 ]) \u00b6 Generates a drift array based on the number of rows in the input data and the specified drift values. Parameters: Name Type Description Default data pd.DataFrame or np.ndarray The input data. required drift_values list of float The drift values to use. [1.1, 10.0, 0.1, 1.1] Returns: Type Description np . ndarray The generated drift array. Examples: >>> import numpy as np >>> from spotRiver.drift.drift_generator import generate_drift >>> data = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) >>> generate_drift ( data , drift_values = [ 1.1 , 10.0 , 0.1 , 1.1 ]) array([ 1.1, 10. , 0.1, 1.1]) Source code in spotRiver/drift/drift_generator.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def generate_drift ( data : pd . DataFrame , drift_values = [ 1.1 , 10.0 , 0.1 , 1.1 ]) -> np . ndarray : \"\"\" Generates a drift array based on the number of rows in the input data and the specified drift values. Args: data (pd.DataFrame or np.ndarray): The input data. drift_values (list of float): The drift values to use. Returns: (np.ndarray): The generated drift array. Examples: >>> import numpy as np >>> from spotRiver.drift.drift_generator import generate_drift >>> data = np.array([[1, 2, 3], [4, 5, 6]]) >>> generate_drift(data, drift_values=[1.1, 10.0, 0.1, 1.1]) array([ 1.1, 10. , 0.1, 1.1]) \"\"\" num_rows = data . shape [ 0 ] num_drift_values = len ( drift_values ) quotient , remain = divmod ( num_rows , num_drift_values ) quotient_array = [ value for value in drift_values for _ in range ( quotient )] remain_array = np . full ( remain , drift_values [ - 1 ], dtype = float ) drift = np . concatenate ([ quotient_array , remain_array ]) return drift","title":"drift_generator"},{"location":"reference/spotRiver/drift/drift_generator/#spotRiver.drift.drift_generator.generate_drift","text":"Generates a drift array based on the number of rows in the input data and the specified drift values. Parameters: Name Type Description Default data pd.DataFrame or np.ndarray The input data. required drift_values list of float The drift values to use. [1.1, 10.0, 0.1, 1.1] Returns: Type Description np . ndarray The generated drift array. Examples: >>> import numpy as np >>> from spotRiver.drift.drift_generator import generate_drift >>> data = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) >>> generate_drift ( data , drift_values = [ 1.1 , 10.0 , 0.1 , 1.1 ]) array([ 1.1, 10. , 0.1, 1.1]) Source code in spotRiver/drift/drift_generator.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def generate_drift ( data : pd . DataFrame , drift_values = [ 1.1 , 10.0 , 0.1 , 1.1 ]) -> np . ndarray : \"\"\" Generates a drift array based on the number of rows in the input data and the specified drift values. Args: data (pd.DataFrame or np.ndarray): The input data. drift_values (list of float): The drift values to use. Returns: (np.ndarray): The generated drift array. Examples: >>> import numpy as np >>> from spotRiver.drift.drift_generator import generate_drift >>> data = np.array([[1, 2, 3], [4, 5, 6]]) >>> generate_drift(data, drift_values=[1.1, 10.0, 0.1, 1.1]) array([ 1.1, 10. , 0.1, 1.1]) \"\"\" num_rows = data . shape [ 0 ] num_drift_values = len ( drift_values ) quotient , remain = divmod ( num_rows , num_drift_values ) quotient_array = [ value for value in drift_values for _ in range ( quotient )] remain_array = np . full ( remain , drift_values [ - 1 ], dtype = float ) drift = np . concatenate ([ quotient_array , remain_array ]) return drift","title":"generate_drift()"},{"location":"reference/spotRiver/evaluation/eval_bml/","text":"ResourceMonitor \u00b6 A context manager for monitoring resource usage. Parameters: Name Type Description Default name str A description of the resource usage. Defaults to None. None Raises: Type Description ResourceMonitorError If the resource monitor is already tracing memory usage. Returns: Type Description ResourceMonitor A ResourceMonitor object. Examples: >>> import time >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor () as rm : ... time . sleep ( 1 ) ... print ( rm . result ()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 Source code in spotRiver/evaluation/eval_bml.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class ResourceMonitor : \"\"\" A context manager for monitoring resource usage. Args: name (str, optional): A description of the resource usage. Defaults to None. Raises: (ResourceMonitorError): If the resource monitor is already tracing memory usage. Returns: (ResourceMonitor): A ResourceMonitor object. Examples: >>> import time >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor() as rm: ... time.sleep(1) ... print(rm.result()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 \"\"\" def __init__ ( self , name : Optional [ str ] = None ): self . name = name self . r_time = None self . memory = None self . current_memory = None self . peak_memory = None self . _start = None def __enter__ ( self ): if tracemalloc . is_tracing (): raise ResourceMonitorError ( \"Already tracing memory usage!\" ) tracemalloc . start () tracemalloc . reset_peak () self . _start = time . perf_counter_ns () def __exit__ ( self , type , value , traceback ): self . r_time = ( time . perf_counter_ns () - self . _start ) / 1.0e9 _ , peak = tracemalloc . get_traced_memory () self . memory = peak / ( 1024 * 1024 ) tracemalloc . stop () def result ( self ): \"\"\" Returns a ResourceUsage object with the results of the resource monitor. Raises: (ResourceMonitorError): If the resource monitor has not been used yet. Returns: (ResourceUsage): A ResourceUsage object with the results of the resource monitor. Examples: >>> from time import sleep >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor() as rm: >>> sleep(1) >>> print(rm.result()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 \"\"\" if self . r_time is None or self . memory is None : raise ResourceMonitorError ( \"No resources monitored yet.\" ) return ResourceUsage ( name = self . name , r_time = self . r_time , memory = self . memory ) result () \u00b6 Returns a ResourceUsage object with the results of the resource monitor. Returns: Type Description ResourceUsage A ResourceUsage object with the results of the resource monitor. Examples: >>> from time import sleep >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor () as rm : >>> sleep ( 1 ) >>> print ( rm . result ()) Resource usage Time [s]: 1.000000001 Memory [b]: 0.0 Source code in spotRiver/evaluation/eval_bml.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def result ( self ): \"\"\" Returns a ResourceUsage object with the results of the resource monitor. Raises: (ResourceMonitorError): If the resource monitor has not been used yet. Returns: (ResourceUsage): A ResourceUsage object with the results of the resource monitor. Examples: >>> from time import sleep >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor() as rm: >>> sleep(1) >>> print(rm.result()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 \"\"\" if self . r_time is None or self . memory is None : raise ResourceMonitorError ( \"No resources monitored yet.\" ) return ResourceUsage ( name = self . name , r_time = self . r_time , memory = self . memory ) eval_bml_horizon ( model , train , test , target_column , horizon , include_remainder = True , metric = None ) \u00b6 Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required include_remainder bool Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. True metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None Returns: Name Type Description tuple tuple A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_bml_horizon ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... Source code in spotRiver/evaluation/eval_bml.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def eval_bml_horizon ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , ) -> tuple : \"\"\" Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_bml_horizon(model, train, test, \"y\", horizon=1) >>> print(df_eval) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... \"\"\" # Check if metric is None or null and raise ValueError if it is if metric is None : raise ValueError ( \"The 'metric' parameter must not be None or null.\" ) # Reset index of train and test dataframes train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) # Initialize lists for predictions and differences preds_list = [] diffs_list = [] # Fit the model on the training data rm = ResourceMonitor () with rm : model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) # Evaluate the model on empty arrays to get initial resource usage df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) # If include_remainder is False, remove remainder rows from test dataframe if include_remainder is False : remainder = len ( test ) % horizon if remainder > 0 : test = test [: - remainder ] # Evaluate the model on batches of size horizon from the test dataframe for batch_number , batch_df in test . groupby ( np . arange ( len ( test )) // horizon ): rm = ResourceMonitor () with rm : preds = model . predict ( batch_df . loc [:, batch_df . columns != target_column ]) diffs = batch_df [ target_column ] . values - preds df_eval . loc [ batch_number + 1 ] = pd . Series ( evaluate_model ( y_true = batch_df [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) # Append predictions and differences to their respective lists preds_list . append ( preds ) diffs_list . append ( diffs ) # Concatenate predictions and differences lists into series series_preds = pd . Series ( np . concatenate ( preds_list )) series_diffs = pd . Series ( np . concatenate ( diffs_list )) # Create a dataframe with true values and add columns for predictions and differences df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true eval_bml_landmark ( model , train , test , target_column , horizon , include_remainder = True , metric = None ) \u00b6 Evaluate a machine learning model on a rolling landmark basis. This function evaluates a machine learning model on a rolling landmark basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required include_remainder bool Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. True metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None Returns: Name Type Description tuple tuple A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_bml_landmark ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... Source code in spotRiver/evaluation/eval_bml.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 def eval_bml_landmark ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , ) -> tuple : \"\"\"Evaluate a machine learning model on a rolling landmark basis. This function evaluates a machine learning model on a rolling landmark basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_bml_landmark(model, train, test, \"y\", horizon=1) >>> print(df_eval) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... \"\"\" train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) series_preds = pd . Series ( dtype = float ) series_diffs = pd . Series ( dtype = float ) rm = ResourceMonitor () with rm : model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) if include_remainder is False : rem = len ( test ) % horizon if rem > 0 : test = test [: - rem ] # Landmark Evaluation for i , new_df in enumerate ( gen_sliding_window ( test , horizon )): train = pd . concat ([ train , new_df ], ignore_index = True ) rm = ResourceMonitor () with rm : preds = pd . Series ( model . predict ( new_df . loc [:, new_df . columns != target_column ])) model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) diffs = new_df [ target_column ] . values - preds df_eval . loc [ i + 1 ] = pd . Series ( evaluate_model ( y_true = new_df [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) series_preds = pd . concat ([ series_preds , preds ], ignore_index = True ) series_diffs = pd . concat ([ series_diffs , diffs ], ignore_index = True ) df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true eval_bml_window ( model , train , test , target_column , horizon , include_remainder = True , metric = None ) \u00b6 Evaluate a model on a rolling window basis. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required Returns: Name Type Description tuple tuple A tuple of two data frames. The first one contains evaluation metrics for each window. tuple The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_bml_window ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Source code in spotRiver/evaluation/eval_bml.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 def eval_bml_window ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , ) -> tuple : \"\"\"Evaluate a model on a rolling window basis. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_bml_window(model, train, test, \"y\", horizon=1) >>> print(df_eval) \"\"\" train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) df_all = pd . concat ([ train , test ], ignore_index = True ) series_preds = pd . Series ( dtype = float ) series_diffs = pd . Series ( dtype = float ) rm = ResourceMonitor () with rm : model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) if include_remainder is False : rem = len ( test ) % horizon if rem > 0 : test = test [: - rem ] for i , ( w_train , w_test ) in enumerate ( gen_horizon_shifted_window ( df_all , len ( train ), horizon )): rm = ResourceMonitor () with rm : model . fit ( w_train . loc [:, w_train . columns != target_column ], w_train [ target_column ]) preds = pd . Series ( model . predict ( w_test . loc [:, w_test . columns != target_column ])) diffs = w_test [ target_column ] . values - preds df_eval . loc [ i + 1 ] = pd . Series ( evaluate_model ( y_true = w_test [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) series_preds = pd . concat ([ series_preds , preds ], ignore_index = True ) series_diffs = pd . concat ([ series_diffs , diffs ], ignore_index = True ) df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true eval_oml_horizon ( model , train , test , target_column , horizon , include_remainder = True , metric = None , oml_grace_period = None ) \u00b6 Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required include_remainder bool Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. True metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None oml_grace_period int The number of observations to use for initial training. Defaults to None, in which case the horizon is used. None Returns: Name Type Description tuple Tuple [ pd . DataFrame , pd . DataFrame ] A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_oml_horizon ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... Source code in spotRiver/evaluation/eval_bml.py 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 def eval_oml_horizon ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , oml_grace_period : int = None , ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. oml_grace_period (int, optional): The number of observations to use for initial training. Defaults to None, in which case the horizon is used. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_oml_horizon(model, train, test, \"y\", horizon=1) >>> print(df_eval) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... \"\"\" # Check if metric is None or null and raise ValueError if it is if metric is None : raise ValueError ( \"The 'metric' parameter must not be None or null.\" ) if oml_grace_period is None : oml_grace_period = horizon train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) if include_remainder is False : rem = len ( test ) % horizon if rem > 0 : test = test [: - rem ] series_preds = pd . Series ( dtype = float ) series_diffs = pd . Series ( dtype = float ) # Initial Training on Train Data # For OML, this is performed on a limited subset only (oml_grace_period). train_X = train . loc [:, train . columns != target_column ] train_y = train [ target_column ] train_X = train_X . tail ( oml_grace_period ) train_y = train_y . tail ( oml_grace_period ) rm = ResourceMonitor () with rm : for xi , yi in river_stream . iter_pandas ( train_X , train_y ): # The following line returns y_pred, which is not used, therefore set to \"_\": _ = model . predict_one ( xi ) # metric = metric.update(yi, y_pred) model = model . learn_one ( xi , yi ) # TODO: Add error handling # Return res_dict = {\"Metric\": score, \"Memory (MB)\": memory, \"CompTime (s)\": r_time} df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) # Test Data Evaluation for i , new_df in enumerate ( gen_sliding_window ( test , horizon )): preds = [] test_X = new_df . loc [:, new_df . columns != target_column ] test_y = new_df [ target_column ] rm = ResourceMonitor () with rm : for xi , yi in river_stream . iter_pandas ( test_X , test_y ): pred = model . predict_one ( xi ) preds . append ( pred ) # This is falsly measured with the ResourceMonitor model = model . learn_one ( xi , yi ) preds = pd . Series ( preds ) diffs = new_df [ target_column ] . values - preds df_eval . loc [ i + 1 ] = pd . Series ( evaluate_model ( y_true = new_df [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) series_preds = pd . concat ([ series_preds , preds ], ignore_index = True ) series_diffs = pd . concat ([ series_diffs , diffs ], ignore_index = True ) df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true evaluate_model ( y_true , y_pred , memory , r_time , metric ) \u00b6 Evaluate a machine learning model on a test dataset. This function evaluates a machine learning model on a test dataset using a given evaluation metric. The evaluation results are returned as a dictionary. Parameters: Name Type Description Default y_true np . ndarray A numpy array containing the true values. required y_pred np . ndarray A numpy array containing the predicted values. required memory float The memory usage of the model. required r_time float The computation time of the model. required metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. required Returns: Name Type Description dict dict A dictionary containing the evaluation results. Examples: >>> from sklearn.metrics import accuracy_score >>> y_true = np . array ([ 0 , 1 , 0 , 1 ]) >>> y_pred = np . array ([ 0 , 1 , 1 , 1 ]) >>> memory = 0.0 >>> r_time = 0.0 >>> metric = accuracy_score >>> evaluate_model ( y_true , y_pred , memory , r_time , metric ) {'Metric': 0.75, 'Memory (MB)': 0.0, 'CompTime (s)': 0.0} Source code in spotRiver/evaluation/eval_bml.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def evaluate_model ( y_true : np . ndarray , y_pred : np . ndarray , memory : float , r_time : float , metric ) -> dict : \"\"\" Evaluate a machine learning model on a test dataset. This function evaluates a machine learning model on a test dataset using a given evaluation metric. The evaluation results are returned as a dictionary. Args: y_true (np.ndarray): A numpy array containing the true values. y_pred (np.ndarray): A numpy array containing the predicted values. memory (float): The memory usage of the model. r_time (float): The computation time of the model. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. Returns: dict: A dictionary containing the evaluation results. Examples: >>> from sklearn.metrics import accuracy_score >>> y_true = np.array([0, 1, 0, 1]) >>> y_pred = np.array([0, 1, 1, 1]) >>> memory = 0.0 >>> r_time = 0.0 >>> metric = accuracy_score >>> evaluate_model(y_true, y_pred, memory, r_time, metric) {'Metric': 0.75, 'Memory (MB)': 0.0, 'CompTime (s)': 0.0} \"\"\" if len ( y_true ) != len ( y_pred ): raise ValueError ( \"y_true and y_pred must have the same size\" ) if ( len ( y_true ) == 0 ) or ( len ( y_pred ) == 0 ): res_dict = { \"Metric\" : None , \"Memory (MB)\" : memory , \"CompTime (s)\" : r_time , } return res_dict score = metric ( y_true , y_pred ) res_dict = { \"Metric\" : score , \"Memory (MB)\" : memory , \"CompTime (s)\" : r_time } return res_dict gen_sliding_window ( df , horizon , include_remainder = True ) \u00b6 Generates sliding windows of a given size from a DataFrame. Parameters: Name Type Description Default df pd . DataFrame The input DataFrame. required horizon int The size of the sliding window. required include_remainder bool Whether to include the remainder of the DataFrame if its length is not divisible by the horizon. Defaults to False. True Yields: Type Description pd . DataFrame A sliding window of the input DataFrame. Examples: >>> df = pd . DataFrame ({ 'A' : [ 1 , 2 , 3 ], 'B' : [ 4 , 5 , 6 ]}) >>> for window in gen_sliding_window ( df , 2 ): ... print ( window ) A B 0 1 4 1 2 5 A B 2 3 6 Source code in spotRiver/evaluation/eval_bml.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 def gen_sliding_window ( df : pd . DataFrame , horizon : int , include_remainder : bool = True ) -> Generator [ pd . DataFrame , None , None ]: \"\"\"Generates sliding windows of a given size from a DataFrame. Args: df (pd.DataFrame): The input DataFrame. horizon (int): The size of the sliding window. include_remainder (bool): Whether to include the remainder of the DataFrame if its length is not divisible by the horizon. Defaults to False. Yields: (pd.DataFrame): A sliding window of the input DataFrame. Examples: >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}) >>> for window in gen_sliding_window(df, 2): ... print(window) A B 0 1 4 1 2 5 A B 2 3 6 \"\"\" i = 0 while True : subset = df [ i * horizon : ( i + 1 ) * horizon ] if len ( subset ) == 0 : break elif len ( subset ) < horizon : if include_remainder : yield subset break i += 1 yield subset plot_bml_oml_horizon_metrics ( df_eval = None , df_labels = None , log_x = False , log_y = False , cumulative = True , grid = True , figsize = None , metric = None , filename = None , ** kwargs ) \u00b6 Plot evaluation metrics for machine learning models. This function plots the evaluation metrics for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the evaluation metrics for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Parameters: Name Type Description Default df_eval list [ pd . DataFrame ] A list of pandas dataframes containing the evaluation metrics for each model. Each dataframe should have an index column with the dataset name and three columns with the label names: e.g., \u201cMetric\u201d, \u201cCompTime (s)\u201d and \u201cMemory (MB)\u201d. If None, no plot is generated. Default is None. None df_labels list A list of strings containing the labels for each model. The length of this list should match the length of df_eval. If None, numeric indices are used as labels. Default is None. None log_x bool A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. False log_y bool A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. False cumulative bool A flag indicating whether to plot cumulative metrics. If True, cumulative metrics are plotted. If False, non-cumulative metrics are plotted. Default is True. True grid bool A flag indicating whether to plot a grid. If True, grid is shown. Default is True. True figsize tuple The size of the figure. Default is None. None metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None filename str The name of the file to save the plot to. If None, the plot is not saved. Default is None. None **kwargs Any Additional keyword arguments to be passed to the plot function. {} Returns: Type Description NoneType This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics >>> df_eval = pd . DataFrame ({ \"Metric\" : [ 0.5 , 0.75 , 0.9 ], \"CompTime (s)\" : [ 0.1 , 0.2 , 0.3 ], \"Memory (MB)\" : [ 0.1 , 0.2 , 0.3 ]}) >>> df_labels = [ \"Model 1\" , \"Model 2\" , \"Model 3\" ] >>> plot_bml_oml_horizon_metrics ( df_eval , df_labels , metric = accuracy_score ) Source code in spotRiver/evaluation/eval_bml.py 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 def plot_bml_oml_horizon_metrics ( df_eval : list [ pd . DataFrame ] = None , df_labels : list = None , log_x = False , log_y = False , cumulative = True , grid = True , figsize = None , metric = None , filename = None , ** kwargs , ) -> None : \"\"\"Plot evaluation metrics for machine learning models. This function plots the evaluation metrics for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the evaluation metrics for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Args: df_eval (list[pd.DataFrame], optional): A list of pandas dataframes containing the evaluation metrics for each model. Each dataframe should have an index column with the dataset name and three columns with the label names: e.g., \"Metric\", \"CompTime (s)\" and \"Memory (MB)\". If None, no plot is generated. Default is None. df_labels (list, optional): A list of strings containing the labels for each model. The length of this list should match the length of df_eval. If None, numeric indices are used as labels. Default is None. log_x (bool, optional): A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. log_y (bool, optional): A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. cumulative (bool, optional): A flag indicating whether to plot cumulative metrics. If True, cumulative metrics are plotted. If False, non-cumulative metrics are plotted. Default is True. grid (bool, optional): A flag indicating whether to plot a grid. If True, grid is shown. Default is True. figsize (tuple, optional): The size of the figure. Default is None. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Default is None. **kwargs (Any): Additional keyword arguments to be passed to the plot function. Returns: (NoneType): This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics >>> df_eval = pd.DataFrame({\"Metric\": [0.5, 0.75, 0.9], \"CompTime (s)\": [0.1, 0.2, 0.3], \"Memory (MB)\": [0.1, 0.2, 0.3]}) >>> df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"] >>> plot_bml_oml_horizon_metrics(df_eval, df_labels, metric=accuracy_score) \"\"\" if figsize is None : figsize = ( 10 , 5 ) # Check if metric is None or null and raise ValueError if it is if metric is None : raise ValueError ( \"The 'metric' parameter must not be None or null.\" ) # Check if input dataframes are provided if df_eval is not None : df_list = copy . deepcopy ( df_eval ) # Convert single dataframe input to a list if needed if df_list . __class__ != list : df_list = [ df_list ] # Define metric names and titles metric_name = metric . __name__ metrics = [ \"Metric\" , \"CompTime (s)\" , \"Memory (MB)\" ] titles = [ metric_name , \"Computation time (s)\" , \"Memory (MB)\" ] # Create subplots with shared x-axis fig , axes = plt . subplots ( 3 , figsize = figsize , constrained_layout = True , sharex = True ) # Loop over each dataframe in input list for j , df in enumerate ( df_list ): if cumulative : # df.MAE = np.cumsum(df.MAE) / range(1, (1 + df.MAE.size)) df [ \"Metric\" ] = np . cumsum ( df [ \"Metric\" ]) / range ( 1 , ( 1 + df [ \"Metric\" ] . size )) df [ \"CompTime (s)\" ] = np . cumsum ( df [ \"CompTime (s)\" ]) # / range(1, (1 + df[\"CompTime (s)\"].size)) # df[\"Memory (MB)\"] = np.cumsum(df[\"Memory (MB)\"]) / range(1, (1 + df[\"Memory (MB)\"].size)) # Loop over each metric for i in range ( 3 ): # Assign label based on input or default value if df_labels is None : label = f \" { j } \" else : label = df_labels [ j ] # Plot metric values against dataset names axes [ i ] . plot ( df . index . values . tolist (), df [ metrics [ i ]] . values . tolist (), label = label , ** kwargs ) # Set title and legend axes [ i ] . set_title ( titles [ i ]) axes [ i ] . legend ( loc = \"upper right\" ) axes [ i ] . grid ( grid ) # Set logarithmic scales if specified if log_x : axes [ i ] . set_xscale ( \"log\" ) if log_y : axes [ i ] . set_yscale ( \"log\" ) if filename is not None : plt . savefig ( filename ) plot_bml_oml_horizon_predictions ( df_true = None , df_labels = None , target_column = 'Actual' , log_x = False , log_y = False , skip_first_n = 0 , grid = True , figsize = None , filename = None , ** kwargs ) \u00b6 Plot actual vs predicted values for machine learning models. This function plots the actual vs predicted values for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the actual and predicted values for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Parameters: Name Type Description Default df_true list [ pd . DataFrame ] A list of pandas dataframes containing the actual and predicted values for each model. Each dataframe should have an index column with the dataset name and two columns with the label names: e.g., \u201cActual\u201d and \u201cPrediction\u201d. If None, no plot is generated. Default is None. None df_labels list A list of strings containing the labels for each model. The length of this list should match the length of df_true. If None, numeric indices are used as labels. Default is None. None target_column str The name of the column containing the target variable. Default is \u201cActual\u201d. 'Actual' log_x bool A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. False log_y bool A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. False skip_first_n int The number of rows to skip from the beginning of the dataframes. Default is 0. 0 grid bool A flag indicating whether to plot a grid. If True, grid is shown. Default is True. True figsize tuple The size of the figure. Default is None. None filename str The name of the file to save the plot to. If None, the plot is not saved. Default is None. None **kwargs Any Additional keyword arguments to be passed to the plot function. {} Returns: Type Description NoneType This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions >>> df_true = pd . DataFrame ({ \"Actual\" : [ 0.5 , 0.75 , 0.9 ], \"Prediction\" : [ 0.1 , 0.2 , 0.3 ]}) >>> df_labels = [ \"Model 1\" , \"Model 2\" , \"Model 3\" ] >>> plot_bml_oml_horizon_predictions ( df_true , df_labels , target_column = \"Actual\" ) Source code in spotRiver/evaluation/eval_bml.py 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def plot_bml_oml_horizon_predictions ( df_true : list [ pd . DataFrame ] = None , df_labels : list = None , target_column : str = \"Actual\" , log_x = False , log_y = False , skip_first_n = 0 , grid = True , figsize : tuple = None , filename = None , ** kwargs , ) -> None : \"\"\" Plot actual vs predicted values for machine learning models. This function plots the actual vs predicted values for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the actual and predicted values for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Args: df_true (list[pd.DataFrame], optional): A list of pandas dataframes containing the actual and predicted values for each model. Each dataframe should have an index column with the dataset name and two columns with the label names: e.g., \"Actual\" and \"Prediction\". If None, no plot is generated. Default is None. df_labels (list, optional): A list of strings containing the labels for each model. The length of this list should match the length of df_true. If None, numeric indices are used as labels. Default is None. target_column (str, optional): The name of the column containing the target variable. Default is \"Actual\". log_x (bool, optional): A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. log_y (bool, optional): A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. skip_first_n (int, optional): The number of rows to skip from the beginning of the dataframes. Default is 0. grid (bool, optional): A flag indicating whether to plot a grid. If True, grid is shown. Default is True. figsize (tuple, optional): The size of the figure. Default is None. filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Default is None. **kwargs (Any): Additional keyword arguments to be passed to the plot function. Returns: (NoneType): This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions >>> df_true = pd.DataFrame({\"Actual\": [0.5, 0.75, 0.9], \"Prediction\": [0.1, 0.2, 0.3]}) >>> df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"] >>> plot_bml_oml_horizon_predictions(df_true, df_labels, target_column=\"Actual\") \"\"\" if figsize is None : figsize = ( 10 , 5 ) if df_true is not None : df_plot = copy . deepcopy ( df_true ) if df_plot . __class__ != list : df_plot = [ df_plot ] plt . figure ( figsize = figsize ) for j , df in enumerate ( df_plot ): if df_labels is None : label = f \" { j } \" else : label = df_labels [ j ] df . loc [: skip_first_n - 1 , \"Prediction\" ] = np . nan plt . plot ( df . index , df [ \"Prediction\" ], label = label , ** kwargs ) plt . plot ( df_plot [ 0 ] . index , df_plot [ 0 ][ target_column ], label = \"Actual\" , color = \"black\" , ** kwargs ) plt . title ( \"Actual vs Prediction\" ) if log_x : plt . xscale ( \"log\" ) if log_y : plt . yscale ( \"log\" ) plt . grid ( grid ) plt . legend () if filename is not None : plt . savefig ( filename ) plt . show ()","title":"eval_bml"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.ResourceMonitor","text":"A context manager for monitoring resource usage. Parameters: Name Type Description Default name str A description of the resource usage. Defaults to None. None Raises: Type Description ResourceMonitorError If the resource monitor is already tracing memory usage. Returns: Type Description ResourceMonitor A ResourceMonitor object. Examples: >>> import time >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor () as rm : ... time . sleep ( 1 ) ... print ( rm . result ()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 Source code in spotRiver/evaluation/eval_bml.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class ResourceMonitor : \"\"\" A context manager for monitoring resource usage. Args: name (str, optional): A description of the resource usage. Defaults to None. Raises: (ResourceMonitorError): If the resource monitor is already tracing memory usage. Returns: (ResourceMonitor): A ResourceMonitor object. Examples: >>> import time >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor() as rm: ... time.sleep(1) ... print(rm.result()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 \"\"\" def __init__ ( self , name : Optional [ str ] = None ): self . name = name self . r_time = None self . memory = None self . current_memory = None self . peak_memory = None self . _start = None def __enter__ ( self ): if tracemalloc . is_tracing (): raise ResourceMonitorError ( \"Already tracing memory usage!\" ) tracemalloc . start () tracemalloc . reset_peak () self . _start = time . perf_counter_ns () def __exit__ ( self , type , value , traceback ): self . r_time = ( time . perf_counter_ns () - self . _start ) / 1.0e9 _ , peak = tracemalloc . get_traced_memory () self . memory = peak / ( 1024 * 1024 ) tracemalloc . stop () def result ( self ): \"\"\" Returns a ResourceUsage object with the results of the resource monitor. Raises: (ResourceMonitorError): If the resource monitor has not been used yet. Returns: (ResourceUsage): A ResourceUsage object with the results of the resource monitor. Examples: >>> from time import sleep >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor() as rm: >>> sleep(1) >>> print(rm.result()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 \"\"\" if self . r_time is None or self . memory is None : raise ResourceMonitorError ( \"No resources monitored yet.\" ) return ResourceUsage ( name = self . name , r_time = self . r_time , memory = self . memory )","title":"ResourceMonitor"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.ResourceMonitor.result","text":"Returns a ResourceUsage object with the results of the resource monitor. Returns: Type Description ResourceUsage A ResourceUsage object with the results of the resource monitor. Examples: >>> from time import sleep >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor () as rm : >>> sleep ( 1 ) >>> print ( rm . result ()) Resource usage Time [s]: 1.000000001 Memory [b]: 0.0 Source code in spotRiver/evaluation/eval_bml.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def result ( self ): \"\"\" Returns a ResourceUsage object with the results of the resource monitor. Raises: (ResourceMonitorError): If the resource monitor has not been used yet. Returns: (ResourceUsage): A ResourceUsage object with the results of the resource monitor. Examples: >>> from time import sleep >>> from spotRiver.evaluation.eval_bml import ResourceMonitor >>> with ResourceMonitor() as rm: >>> sleep(1) >>> print(rm.result()) Resource usage: Time [s]: 1.000000001 Memory [b]: 0.0 \"\"\" if self . r_time is None or self . memory is None : raise ResourceMonitorError ( \"No resources monitored yet.\" ) return ResourceUsage ( name = self . name , r_time = self . r_time , memory = self . memory )","title":"result()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_bml_horizon","text":"Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required include_remainder bool Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. True metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None Returns: Name Type Description tuple tuple A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_bml_horizon ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... Source code in spotRiver/evaluation/eval_bml.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def eval_bml_horizon ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , ) -> tuple : \"\"\" Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_bml_horizon(model, train, test, \"y\", horizon=1) >>> print(df_eval) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... \"\"\" # Check if metric is None or null and raise ValueError if it is if metric is None : raise ValueError ( \"The 'metric' parameter must not be None or null.\" ) # Reset index of train and test dataframes train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) # Initialize lists for predictions and differences preds_list = [] diffs_list = [] # Fit the model on the training data rm = ResourceMonitor () with rm : model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) # Evaluate the model on empty arrays to get initial resource usage df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) # If include_remainder is False, remove remainder rows from test dataframe if include_remainder is False : remainder = len ( test ) % horizon if remainder > 0 : test = test [: - remainder ] # Evaluate the model on batches of size horizon from the test dataframe for batch_number , batch_df in test . groupby ( np . arange ( len ( test )) // horizon ): rm = ResourceMonitor () with rm : preds = model . predict ( batch_df . loc [:, batch_df . columns != target_column ]) diffs = batch_df [ target_column ] . values - preds df_eval . loc [ batch_number + 1 ] = pd . Series ( evaluate_model ( y_true = batch_df [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) # Append predictions and differences to their respective lists preds_list . append ( preds ) diffs_list . append ( diffs ) # Concatenate predictions and differences lists into series series_preds = pd . Series ( np . concatenate ( preds_list )) series_diffs = pd . Series ( np . concatenate ( diffs_list )) # Create a dataframe with true values and add columns for predictions and differences df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true","title":"eval_bml_horizon()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_bml_landmark","text":"Evaluate a machine learning model on a rolling landmark basis. This function evaluates a machine learning model on a rolling landmark basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required include_remainder bool Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. True metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None Returns: Name Type Description tuple tuple A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_bml_landmark ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... Source code in spotRiver/evaluation/eval_bml.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 def eval_bml_landmark ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , ) -> tuple : \"\"\"Evaluate a machine learning model on a rolling landmark basis. This function evaluates a machine learning model on a rolling landmark basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_bml_landmark(model, train, test, \"y\", horizon=1) >>> print(df_eval) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... \"\"\" train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) series_preds = pd . Series ( dtype = float ) series_diffs = pd . Series ( dtype = float ) rm = ResourceMonitor () with rm : model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) if include_remainder is False : rem = len ( test ) % horizon if rem > 0 : test = test [: - rem ] # Landmark Evaluation for i , new_df in enumerate ( gen_sliding_window ( test , horizon )): train = pd . concat ([ train , new_df ], ignore_index = True ) rm = ResourceMonitor () with rm : preds = pd . Series ( model . predict ( new_df . loc [:, new_df . columns != target_column ])) model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) diffs = new_df [ target_column ] . values - preds df_eval . loc [ i + 1 ] = pd . Series ( evaluate_model ( y_true = new_df [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) series_preds = pd . concat ([ series_preds , preds ], ignore_index = True ) series_diffs = pd . concat ([ series_diffs , diffs ], ignore_index = True ) df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true","title":"eval_bml_landmark()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_bml_window","text":"Evaluate a model on a rolling window basis. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required Returns: Name Type Description tuple tuple A tuple of two data frames. The first one contains evaluation metrics for each window. tuple The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_bml_window ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Source code in spotRiver/evaluation/eval_bml.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 def eval_bml_window ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , ) -> tuple : \"\"\"Evaluate a model on a rolling window basis. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_bml_window(model, train, test, \"y\", horizon=1) >>> print(df_eval) \"\"\" train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) df_all = pd . concat ([ train , test ], ignore_index = True ) series_preds = pd . Series ( dtype = float ) series_diffs = pd . Series ( dtype = float ) rm = ResourceMonitor () with rm : model . fit ( train . loc [:, train . columns != target_column ], train [ target_column ]) df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) if include_remainder is False : rem = len ( test ) % horizon if rem > 0 : test = test [: - rem ] for i , ( w_train , w_test ) in enumerate ( gen_horizon_shifted_window ( df_all , len ( train ), horizon )): rm = ResourceMonitor () with rm : model . fit ( w_train . loc [:, w_train . columns != target_column ], w_train [ target_column ]) preds = pd . Series ( model . predict ( w_test . loc [:, w_test . columns != target_column ])) diffs = w_test [ target_column ] . values - preds df_eval . loc [ i + 1 ] = pd . Series ( evaluate_model ( y_true = w_test [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) series_preds = pd . concat ([ series_preds , preds ], ignore_index = True ) series_diffs = pd . concat ([ series_diffs , diffs ], ignore_index = True ) df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true","title":"eval_bml_window()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_oml_horizon","text":"Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Parameters: Name Type Description Default model object The model to be evaluated. required train pd . DataFrame The training data set. required test pd . DataFrame The testing data set. required target_column str The name of the column containing the target variable. required horizon int The number of steps ahead to forecast. required include_remainder bool Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. True metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None oml_grace_period int The number of observations to use for initial training. Defaults to None, in which case the horizon is used. None Returns: Name Type Description tuple Tuple [ pd . DataFrame , pd . DataFrame ] A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression () >>> train = pd . DataFrame ({ \"x\" : [ 1 , 2 , 3 ], \"y\" : [ 2 , 4 , 6 ]}) >>> test = pd . DataFrame ({ \"x\" : [ 4 , 5 ], \"y\" : [ 8 , 10 ]}) >>> df_eval , df_true = eval_oml_horizon ( model , train , test , \"y\" , horizon = 1 ) >>> print ( df_eval ) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... Source code in spotRiver/evaluation/eval_bml.py 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 def eval_oml_horizon ( model : object , train : pd . DataFrame , test : pd . DataFrame , target_column : str , horizon : int , include_remainder : bool = True , metric : object = None , oml_grace_period : int = None , ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" Evaluate a machine learning model on a rolling horizon basis. This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Args: model (object): The model to be evaluated. train (pd.DataFrame): The training data set. test (pd.DataFrame): The testing data set. target_column (str): The name of the column containing the target variable. horizon (int, optional): The number of steps ahead to forecast. include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. oml_grace_period (int, optional): The number of observations to use for initial training. Defaults to None, in which case the horizon is used. Returns: tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set. Examples: >>> from sklearn.linear_model import LinearRegression >>> model = LinearRegression() >>> train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]}) >>> test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]}) >>> df_eval, df_true = eval_oml_horizon(model, train, test, \"y\", horizon=1) >>> print(df_eval) Metric Memory (MB) CompTime (s) 0 0.000000 0.0 0.0 1 0.000000 0.0 0.0 ... ... ... ... \"\"\" # Check if metric is None or null and raise ValueError if it is if metric is None : raise ValueError ( \"The 'metric' parameter must not be None or null.\" ) if oml_grace_period is None : oml_grace_period = horizon train = train . reset_index ( drop = True ) test = test . reset_index ( drop = True ) if include_remainder is False : rem = len ( test ) % horizon if rem > 0 : test = test [: - rem ] series_preds = pd . Series ( dtype = float ) series_diffs = pd . Series ( dtype = float ) # Initial Training on Train Data # For OML, this is performed on a limited subset only (oml_grace_period). train_X = train . loc [:, train . columns != target_column ] train_y = train [ target_column ] train_X = train_X . tail ( oml_grace_period ) train_y = train_y . tail ( oml_grace_period ) rm = ResourceMonitor () with rm : for xi , yi in river_stream . iter_pandas ( train_X , train_y ): # The following line returns y_pred, which is not used, therefore set to \"_\": _ = model . predict_one ( xi ) # metric = metric.update(yi, y_pred) model = model . learn_one ( xi , yi ) # TODO: Add error handling # Return res_dict = {\"Metric\": score, \"Memory (MB)\": memory, \"CompTime (s)\": r_time} df_eval = pd . DataFrame . from_dict ( [ evaluate_model ( y_true = np . array ([]), y_pred = np . array ([]), memory = rm . memory , r_time = rm . r_time , metric = metric )] ) # Test Data Evaluation for i , new_df in enumerate ( gen_sliding_window ( test , horizon )): preds = [] test_X = new_df . loc [:, new_df . columns != target_column ] test_y = new_df [ target_column ] rm = ResourceMonitor () with rm : for xi , yi in river_stream . iter_pandas ( test_X , test_y ): pred = model . predict_one ( xi ) preds . append ( pred ) # This is falsly measured with the ResourceMonitor model = model . learn_one ( xi , yi ) preds = pd . Series ( preds ) diffs = new_df [ target_column ] . values - preds df_eval . loc [ i + 1 ] = pd . Series ( evaluate_model ( y_true = new_df [ target_column ], y_pred = preds , memory = rm . memory , r_time = rm . r_time , metric = metric , ) ) series_preds = pd . concat ([ series_preds , preds ], ignore_index = True ) series_diffs = pd . concat ([ series_diffs , diffs ], ignore_index = True ) df_true = pd . DataFrame ( test [ target_column ]) df_true [ \"Prediction\" ] = series_preds df_true [ \"Difference\" ] = series_diffs return df_eval , df_true","title":"eval_oml_horizon()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.evaluate_model","text":"Evaluate a machine learning model on a test dataset. This function evaluates a machine learning model on a test dataset using a given evaluation metric. The evaluation results are returned as a dictionary. Parameters: Name Type Description Default y_true np . ndarray A numpy array containing the true values. required y_pred np . ndarray A numpy array containing the predicted values. required memory float The memory usage of the model. required r_time float The computation time of the model. required metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. required Returns: Name Type Description dict dict A dictionary containing the evaluation results. Examples: >>> from sklearn.metrics import accuracy_score >>> y_true = np . array ([ 0 , 1 , 0 , 1 ]) >>> y_pred = np . array ([ 0 , 1 , 1 , 1 ]) >>> memory = 0.0 >>> r_time = 0.0 >>> metric = accuracy_score >>> evaluate_model ( y_true , y_pred , memory , r_time , metric ) {'Metric': 0.75, 'Memory (MB)': 0.0, 'CompTime (s)': 0.0} Source code in spotRiver/evaluation/eval_bml.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def evaluate_model ( y_true : np . ndarray , y_pred : np . ndarray , memory : float , r_time : float , metric ) -> dict : \"\"\" Evaluate a machine learning model on a test dataset. This function evaluates a machine learning model on a test dataset using a given evaluation metric. The evaluation results are returned as a dictionary. Args: y_true (np.ndarray): A numpy array containing the true values. y_pred (np.ndarray): A numpy array containing the predicted values. memory (float): The memory usage of the model. r_time (float): The computation time of the model. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. Returns: dict: A dictionary containing the evaluation results. Examples: >>> from sklearn.metrics import accuracy_score >>> y_true = np.array([0, 1, 0, 1]) >>> y_pred = np.array([0, 1, 1, 1]) >>> memory = 0.0 >>> r_time = 0.0 >>> metric = accuracy_score >>> evaluate_model(y_true, y_pred, memory, r_time, metric) {'Metric': 0.75, 'Memory (MB)': 0.0, 'CompTime (s)': 0.0} \"\"\" if len ( y_true ) != len ( y_pred ): raise ValueError ( \"y_true and y_pred must have the same size\" ) if ( len ( y_true ) == 0 ) or ( len ( y_pred ) == 0 ): res_dict = { \"Metric\" : None , \"Memory (MB)\" : memory , \"CompTime (s)\" : r_time , } return res_dict score = metric ( y_true , y_pred ) res_dict = { \"Metric\" : score , \"Memory (MB)\" : memory , \"CompTime (s)\" : r_time } return res_dict","title":"evaluate_model()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.gen_sliding_window","text":"Generates sliding windows of a given size from a DataFrame. Parameters: Name Type Description Default df pd . DataFrame The input DataFrame. required horizon int The size of the sliding window. required include_remainder bool Whether to include the remainder of the DataFrame if its length is not divisible by the horizon. Defaults to False. True Yields: Type Description pd . DataFrame A sliding window of the input DataFrame. Examples: >>> df = pd . DataFrame ({ 'A' : [ 1 , 2 , 3 ], 'B' : [ 4 , 5 , 6 ]}) >>> for window in gen_sliding_window ( df , 2 ): ... print ( window ) A B 0 1 4 1 2 5 A B 2 3 6 Source code in spotRiver/evaluation/eval_bml.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 def gen_sliding_window ( df : pd . DataFrame , horizon : int , include_remainder : bool = True ) -> Generator [ pd . DataFrame , None , None ]: \"\"\"Generates sliding windows of a given size from a DataFrame. Args: df (pd.DataFrame): The input DataFrame. horizon (int): The size of the sliding window. include_remainder (bool): Whether to include the remainder of the DataFrame if its length is not divisible by the horizon. Defaults to False. Yields: (pd.DataFrame): A sliding window of the input DataFrame. Examples: >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}) >>> for window in gen_sliding_window(df, 2): ... print(window) A B 0 1 4 1 2 5 A B 2 3 6 \"\"\" i = 0 while True : subset = df [ i * horizon : ( i + 1 ) * horizon ] if len ( subset ) == 0 : break elif len ( subset ) < horizon : if include_remainder : yield subset break i += 1 yield subset","title":"gen_sliding_window()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.plot_bml_oml_horizon_metrics","text":"Plot evaluation metrics for machine learning models. This function plots the evaluation metrics for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the evaluation metrics for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Parameters: Name Type Description Default df_eval list [ pd . DataFrame ] A list of pandas dataframes containing the evaluation metrics for each model. Each dataframe should have an index column with the dataset name and three columns with the label names: e.g., \u201cMetric\u201d, \u201cCompTime (s)\u201d and \u201cMemory (MB)\u201d. If None, no plot is generated. Default is None. None df_labels list A list of strings containing the labels for each model. The length of this list should match the length of df_eval. If None, numeric indices are used as labels. Default is None. None log_x bool A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. False log_y bool A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. False cumulative bool A flag indicating whether to plot cumulative metrics. If True, cumulative metrics are plotted. If False, non-cumulative metrics are plotted. Default is True. True grid bool A flag indicating whether to plot a grid. If True, grid is shown. Default is True. True figsize tuple The size of the figure. Default is None. None metric object An evaluation metric object that has an evaluate method. This metric will be used to evaluate the model\u2019s performance on the test dataset. None filename str The name of the file to save the plot to. If None, the plot is not saved. Default is None. None **kwargs Any Additional keyword arguments to be passed to the plot function. {} Returns: Type Description NoneType This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics >>> df_eval = pd . DataFrame ({ \"Metric\" : [ 0.5 , 0.75 , 0.9 ], \"CompTime (s)\" : [ 0.1 , 0.2 , 0.3 ], \"Memory (MB)\" : [ 0.1 , 0.2 , 0.3 ]}) >>> df_labels = [ \"Model 1\" , \"Model 2\" , \"Model 3\" ] >>> plot_bml_oml_horizon_metrics ( df_eval , df_labels , metric = accuracy_score ) Source code in spotRiver/evaluation/eval_bml.py 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 def plot_bml_oml_horizon_metrics ( df_eval : list [ pd . DataFrame ] = None , df_labels : list = None , log_x = False , log_y = False , cumulative = True , grid = True , figsize = None , metric = None , filename = None , ** kwargs , ) -> None : \"\"\"Plot evaluation metrics for machine learning models. This function plots the evaluation metrics for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the evaluation metrics for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Args: df_eval (list[pd.DataFrame], optional): A list of pandas dataframes containing the evaluation metrics for each model. Each dataframe should have an index column with the dataset name and three columns with the label names: e.g., \"Metric\", \"CompTime (s)\" and \"Memory (MB)\". If None, no plot is generated. Default is None. df_labels (list, optional): A list of strings containing the labels for each model. The length of this list should match the length of df_eval. If None, numeric indices are used as labels. Default is None. log_x (bool, optional): A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. log_y (bool, optional): A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. cumulative (bool, optional): A flag indicating whether to plot cumulative metrics. If True, cumulative metrics are plotted. If False, non-cumulative metrics are plotted. Default is True. grid (bool, optional): A flag indicating whether to plot a grid. If True, grid is shown. Default is True. figsize (tuple, optional): The size of the figure. Default is None. metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset. filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Default is None. **kwargs (Any): Additional keyword arguments to be passed to the plot function. Returns: (NoneType): This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics >>> df_eval = pd.DataFrame({\"Metric\": [0.5, 0.75, 0.9], \"CompTime (s)\": [0.1, 0.2, 0.3], \"Memory (MB)\": [0.1, 0.2, 0.3]}) >>> df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"] >>> plot_bml_oml_horizon_metrics(df_eval, df_labels, metric=accuracy_score) \"\"\" if figsize is None : figsize = ( 10 , 5 ) # Check if metric is None or null and raise ValueError if it is if metric is None : raise ValueError ( \"The 'metric' parameter must not be None or null.\" ) # Check if input dataframes are provided if df_eval is not None : df_list = copy . deepcopy ( df_eval ) # Convert single dataframe input to a list if needed if df_list . __class__ != list : df_list = [ df_list ] # Define metric names and titles metric_name = metric . __name__ metrics = [ \"Metric\" , \"CompTime (s)\" , \"Memory (MB)\" ] titles = [ metric_name , \"Computation time (s)\" , \"Memory (MB)\" ] # Create subplots with shared x-axis fig , axes = plt . subplots ( 3 , figsize = figsize , constrained_layout = True , sharex = True ) # Loop over each dataframe in input list for j , df in enumerate ( df_list ): if cumulative : # df.MAE = np.cumsum(df.MAE) / range(1, (1 + df.MAE.size)) df [ \"Metric\" ] = np . cumsum ( df [ \"Metric\" ]) / range ( 1 , ( 1 + df [ \"Metric\" ] . size )) df [ \"CompTime (s)\" ] = np . cumsum ( df [ \"CompTime (s)\" ]) # / range(1, (1 + df[\"CompTime (s)\"].size)) # df[\"Memory (MB)\"] = np.cumsum(df[\"Memory (MB)\"]) / range(1, (1 + df[\"Memory (MB)\"].size)) # Loop over each metric for i in range ( 3 ): # Assign label based on input or default value if df_labels is None : label = f \" { j } \" else : label = df_labels [ j ] # Plot metric values against dataset names axes [ i ] . plot ( df . index . values . tolist (), df [ metrics [ i ]] . values . tolist (), label = label , ** kwargs ) # Set title and legend axes [ i ] . set_title ( titles [ i ]) axes [ i ] . legend ( loc = \"upper right\" ) axes [ i ] . grid ( grid ) # Set logarithmic scales if specified if log_x : axes [ i ] . set_xscale ( \"log\" ) if log_y : axes [ i ] . set_yscale ( \"log\" ) if filename is not None : plt . savefig ( filename )","title":"plot_bml_oml_horizon_metrics()"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.plot_bml_oml_horizon_predictions","text":"Plot actual vs predicted values for machine learning models. This function plots the actual vs predicted values for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the actual and predicted values for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Parameters: Name Type Description Default df_true list [ pd . DataFrame ] A list of pandas dataframes containing the actual and predicted values for each model. Each dataframe should have an index column with the dataset name and two columns with the label names: e.g., \u201cActual\u201d and \u201cPrediction\u201d. If None, no plot is generated. Default is None. None df_labels list A list of strings containing the labels for each model. The length of this list should match the length of df_true. If None, numeric indices are used as labels. Default is None. None target_column str The name of the column containing the target variable. Default is \u201cActual\u201d. 'Actual' log_x bool A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. False log_y bool A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. False skip_first_n int The number of rows to skip from the beginning of the dataframes. Default is 0. 0 grid bool A flag indicating whether to plot a grid. If True, grid is shown. Default is True. True figsize tuple The size of the figure. Default is None. None filename str The name of the file to save the plot to. If None, the plot is not saved. Default is None. None **kwargs Any Additional keyword arguments to be passed to the plot function. {} Returns: Type Description NoneType This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions >>> df_true = pd . DataFrame ({ \"Actual\" : [ 0.5 , 0.75 , 0.9 ], \"Prediction\" : [ 0.1 , 0.2 , 0.3 ]}) >>> df_labels = [ \"Model 1\" , \"Model 2\" , \"Model 3\" ] >>> plot_bml_oml_horizon_predictions ( df_true , df_labels , target_column = \"Actual\" ) Source code in spotRiver/evaluation/eval_bml.py 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def plot_bml_oml_horizon_predictions ( df_true : list [ pd . DataFrame ] = None , df_labels : list = None , target_column : str = \"Actual\" , log_x = False , log_y = False , skip_first_n = 0 , grid = True , figsize : tuple = None , filename = None , ** kwargs , ) -> None : \"\"\" Plot actual vs predicted values for machine learning models. This function plots the actual vs predicted values for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the actual and predicted values for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis. Args: df_true (list[pd.DataFrame], optional): A list of pandas dataframes containing the actual and predicted values for each model. Each dataframe should have an index column with the dataset name and two columns with the label names: e.g., \"Actual\" and \"Prediction\". If None, no plot is generated. Default is None. df_labels (list, optional): A list of strings containing the labels for each model. The length of this list should match the length of df_true. If None, numeric indices are used as labels. Default is None. target_column (str, optional): The name of the column containing the target variable. Default is \"Actual\". log_x (bool, optional): A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False. log_y (bool, optional): A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False. skip_first_n (int, optional): The number of rows to skip from the beginning of the dataframes. Default is 0. grid (bool, optional): A flag indicating whether to plot a grid. If True, grid is shown. Default is True. figsize (tuple, optional): The size of the figure. Default is None. filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Default is None. **kwargs (Any): Additional keyword arguments to be passed to the plot function. Returns: (NoneType): This function does not return anything. Examples: >>> from sklearn.metrics import accuracy_score >>> from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions >>> df_true = pd.DataFrame({\"Actual\": [0.5, 0.75, 0.9], \"Prediction\": [0.1, 0.2, 0.3]}) >>> df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"] >>> plot_bml_oml_horizon_predictions(df_true, df_labels, target_column=\"Actual\") \"\"\" if figsize is None : figsize = ( 10 , 5 ) if df_true is not None : df_plot = copy . deepcopy ( df_true ) if df_plot . __class__ != list : df_plot = [ df_plot ] plt . figure ( figsize = figsize ) for j , df in enumerate ( df_plot ): if df_labels is None : label = f \" { j } \" else : label = df_labels [ j ] df . loc [: skip_first_n - 1 , \"Prediction\" ] = np . nan plt . plot ( df . index , df [ \"Prediction\" ], label = label , ** kwargs ) plt . plot ( df_plot [ 0 ] . index , df_plot [ 0 ][ target_column ], label = \"Actual\" , color = \"black\" , ** kwargs ) plt . title ( \"Actual vs Prediction\" ) if log_x : plt . xscale ( \"log\" ) if log_y : plt . yscale ( \"log\" ) plt . grid ( grid ) plt . legend () if filename is not None : plt . savefig ( filename ) plt . show ()","title":"plot_bml_oml_horizon_predictions()"},{"location":"reference/spotRiver/evaluation/eval_nowcast/","text":"eval_nowcast_model ( model , dataset , time_interval = 'month' , window_size = 12 ) \u00b6 Evaluates a time series model using a rolling mean absolute error metric. Parameters: Name Type Description Default model river . time_series A predictor object (river.time_series) that implements the forecast and learn_one methods. required dataset object A dataset object that contains the time series data. required time_interval str The name of the attribute that contains the date information in the dataset. 'month' window_size int The number of observations to use for calculating the rolling metric. 12 Returns: Type Description Tuple [ List , utils . Rolling , List , List ] Tuple[List, utils.Rolling, List, List]: A tuple of four lists: - dates: The dates corresponding to each observation in the dataset. - metric: A rolling metric object that contains the mean absolute error values. - y_trues: The true values of the target variable in the dataset. - y_preds: The predicted values of the target variable by the model. Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) Source code in spotRiver/evaluation/eval_nowcast.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def eval_nowcast_model ( model , dataset , time_interval : str = \"month\" , window_size : int = 12 ) -> Tuple [ List , utils . Rolling , List , List ]: \"\"\" Evaluates a time series model using a rolling mean absolute error metric. Args: model (river.time_series): A predictor object (river.time_series) that implements the forecast and learn_one methods. dataset (object): A dataset object that contains the time series data. time_interval (str): The name of the attribute that contains the date information in the dataset. window_size (int): The number of observations to use for calculating the rolling metric. Returns: Tuple[List, utils.Rolling, List, List]: A tuple of four lists: - dates: The dates corresponding to each observation in the dataset. - metric: A rolling metric object that contains the mean absolute error values. - y_trues: The true values of the target variable in the dataset. - y_preds: The predicted values of the target variable by the model. Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) \"\"\" metric = utils . Rolling ( obj = metrics . MAE (), window_size = window_size ) dates = [] y_trues = [] y_preds = [] for x , y in dataset : # Obtain the prior prediction and update the model in one go y_pred = model . predict_one ( x ) model . learn_one ( x , y ) # Update the error metric metric . update ( y , y_pred ) # Store the true value and the prediction dates . append ( x [ time_interval ]) y_trues . append ( y ) y_preds . append ( y_pred ) return dates , metric , y_trues , y_preds plot_nowcast_model ( dates , metric , y_trues , y_preds , range = None ) \u00b6 Plots the true values and the predictions of a nowcast model along with a rolling metric. Parameters: Name Type Description Default dates List [ str ] A list of strings that contains the dates corresponding to each observation. required metric utils . Rolling A rolling metric object that contains the mean absolute error values. required y_trues List [ float ] A list of floats that contains the true values of the target variable. required y_preds List [ float ] A list of floats that contains the predicted values of the target variable. required range List [ int ] A list of 2 int that specify the subset. None Returns: Type Description None None. Displays a matplotlib figure with two lines and a title. Source code in spotRiver/evaluation/eval_nowcast.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def plot_nowcast_model ( dates : List [ str ], metric : utils . Rolling , y_trues : List [ float ], y_preds : List [ float ], range : List [ int ] = None ) -> None : \"\"\" Plots the true values and the predictions of a nowcast model along with a rolling metric. Parameters: dates: A list of strings that contains the dates corresponding to each observation. metric: A rolling metric object that contains the mean absolute error values. y_trues: A list of floats that contains the true values of the target variable. y_preds: A list of floats that contains the predicted values of the target variable. range: A list of 2 int that specify the subset. Returns: None. Displays a matplotlib figure with two lines and a title. \"\"\" # Create a figure and an axis object fig , ax = plt . subplots ( figsize = ( 10 , 6 )) # Add grid lines to the plot ax . grid ( alpha = 0.75 ) if range is not None : dates = dates [ range [ 0 ] : range [ 1 ]] y_preds = y_preds [ range [ 0 ] : range [ 1 ]] y_trues = y_trues [ range [ 0 ] : range [ 1 ]] # Plot the true values and the predictions with different colors and labels ax . plot ( dates , y_trues , lw = 3 , color = \"#2ecc71\" , alpha = 0.8 , label = \"Ground truth\" ) ax . plot ( dates , y_preds , lw = 3 , color = \"#e74c3c\" , alpha = 0.8 , label = \"Prediction\" ) # Add a legend to show the labels ax . legend () # Set the title of the plot to be the rolling metric ax . set_title ( metric )","title":"eval_nowcast"},{"location":"reference/spotRiver/evaluation/eval_nowcast/#spotRiver.evaluation.eval_nowcast.eval_nowcast_model","text":"Evaluates a time series model using a rolling mean absolute error metric. Parameters: Name Type Description Default model river . time_series A predictor object (river.time_series) that implements the forecast and learn_one methods. required dataset object A dataset object that contains the time series data. required time_interval str The name of the attribute that contains the date information in the dataset. 'month' window_size int The number of observations to use for calculating the rolling metric. 12 Returns: Type Description Tuple [ List , utils . Rolling , List , List ] Tuple[List, utils.Rolling, List, List]: A tuple of four lists: - dates: The dates corresponding to each observation in the dataset. - metric: A rolling metric object that contains the mean absolute error values. - y_trues: The true values of the target variable in the dataset. - y_preds: The predicted values of the target variable by the model. Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) Source code in spotRiver/evaluation/eval_nowcast.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def eval_nowcast_model ( model , dataset , time_interval : str = \"month\" , window_size : int = 12 ) -> Tuple [ List , utils . Rolling , List , List ]: \"\"\" Evaluates a time series model using a rolling mean absolute error metric. Args: model (river.time_series): A predictor object (river.time_series) that implements the forecast and learn_one methods. dataset (object): A dataset object that contains the time series data. time_interval (str): The name of the attribute that contains the date information in the dataset. window_size (int): The number of observations to use for calculating the rolling metric. Returns: Tuple[List, utils.Rolling, List, List]: A tuple of four lists: - dates: The dates corresponding to each observation in the dataset. - metric: A rolling metric object that contains the mean absolute error values. - y_trues: The true values of the target variable in the dataset. - y_preds: The predicted values of the target variable by the model. Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) \"\"\" metric = utils . Rolling ( obj = metrics . MAE (), window_size = window_size ) dates = [] y_trues = [] y_preds = [] for x , y in dataset : # Obtain the prior prediction and update the model in one go y_pred = model . predict_one ( x ) model . learn_one ( x , y ) # Update the error metric metric . update ( y , y_pred ) # Store the true value and the prediction dates . append ( x [ time_interval ]) y_trues . append ( y ) y_preds . append ( y_pred ) return dates , metric , y_trues , y_preds","title":"eval_nowcast_model()"},{"location":"reference/spotRiver/evaluation/eval_nowcast/#spotRiver.evaluation.eval_nowcast.plot_nowcast_model","text":"Plots the true values and the predictions of a nowcast model along with a rolling metric. Parameters: Name Type Description Default dates List [ str ] A list of strings that contains the dates corresponding to each observation. required metric utils . Rolling A rolling metric object that contains the mean absolute error values. required y_trues List [ float ] A list of floats that contains the true values of the target variable. required y_preds List [ float ] A list of floats that contains the predicted values of the target variable. required range List [ int ] A list of 2 int that specify the subset. None Returns: Type Description None None. Displays a matplotlib figure with two lines and a title. Source code in spotRiver/evaluation/eval_nowcast.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def plot_nowcast_model ( dates : List [ str ], metric : utils . Rolling , y_trues : List [ float ], y_preds : List [ float ], range : List [ int ] = None ) -> None : \"\"\" Plots the true values and the predictions of a nowcast model along with a rolling metric. Parameters: dates: A list of strings that contains the dates corresponding to each observation. metric: A rolling metric object that contains the mean absolute error values. y_trues: A list of floats that contains the true values of the target variable. y_preds: A list of floats that contains the predicted values of the target variable. range: A list of 2 int that specify the subset. Returns: None. Displays a matplotlib figure with two lines and a title. \"\"\" # Create a figure and an axis object fig , ax = plt . subplots ( figsize = ( 10 , 6 )) # Add grid lines to the plot ax . grid ( alpha = 0.75 ) if range is not None : dates = dates [ range [ 0 ] : range [ 1 ]] y_preds = y_preds [ range [ 0 ] : range [ 1 ]] y_trues = y_trues [ range [ 0 ] : range [ 1 ]] # Plot the true values and the predictions with different colors and labels ax . plot ( dates , y_trues , lw = 3 , color = \"#2ecc71\" , alpha = 0.8 , label = \"Ground truth\" ) ax . plot ( dates , y_preds , lw = 3 , color = \"#e74c3c\" , alpha = 0.8 , label = \"Prediction\" ) # Add a legend to show the labels ax . legend () # Set the title of the plot to be the rolling metric ax . set_title ( metric )","title":"plot_nowcast_model()"},{"location":"reference/spotRiver/evaluation/eval_oml/","text":"eval_oml_iter_progressive ( dataset , metric , models , step = 100 , weight_coeff = 0.0 , log_level = 50 ) \u00b6 Evaluate OML Models on Streaming Data This function evaluates one or more OML models on a streaming dataset. The evaluation is done iteratively, and the models are tested every step iterations. The results are returned as a dictionary of metrics and their values. Parameters: Name Type Description Default dataset list or river.Stream A list of river.Stream objects containing the streaming data to be evaluated. If a single river.Stream object is provided, it is automatically converted to a list. required metric river.metrics.base.MultiClassMetric or river.metrics.base.RegressionMetric The metric to be used for evaluation. required models dict A dictionary of OML models to be evaluated. The keys are the names of the models, and the values are the model objects. required step int Iteration number at which to yield results. This only takes into account the predictions, and not the training steps. Defaults to 100. 100 weight_coeff float Results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff > 1. If weight_coeff == 0, then results are multiplied by 1 and every result has an equal weight. Defaults to 0.0. 0.0 log_level int The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. 50 Returns: Type Description dict A dictionary containing the evaluation results. The keys are the names of the models, and the values are dictionaries with the following keys: - \u201cstep\u201d: A list of iteration numbers at which the model was evaluated. - \u201cerror\u201d: A list of the weighted errors for each iteration. - \u201cr_time\u201d: A list of the weighted running times for each iteration. - \u201cmemory\u201d: A list of the weighted memory usages for each iteration. - \u201cmetric_name\u201d: The name of the metric used for evaluation. Reference https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) Source code in spotRiver/evaluation/eval_oml.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def eval_oml_iter_progressive ( dataset , metric , models , step = 100 , weight_coeff = 0.0 , log_level = 50 ): \"\"\"Evaluate OML Models on Streaming Data This function evaluates one or more OML models on a streaming dataset. The evaluation is done iteratively, and the models are tested every `step` iterations. The results are returned as a dictionary of metrics and their values. Args: dataset (list or river.Stream): A list of river.Stream objects containing the streaming data to be evaluated. If a single river.Stream object is provided, it is automatically converted to a list. metric (river.metrics.base.MultiClassMetric or river.metrics.base.RegressionMetric): The metric to be used for evaluation. models (dict): A dictionary of OML models to be evaluated. The keys are the names of the models, and the values are the model objects. step (int): Iteration number at which to yield results. This only takes into account the predictions, and not the training steps. Defaults to 100. weight_coeff (float): Results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff > 1. If weight_coeff == 0, then results are multiplied by 1 and every result has an equal weight. Defaults to 0.0. log_level (int): The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. Returns: (dict): A dictionary containing the evaluation results. The keys are the names of the models, and the values are dictionaries with the following keys: - \"step\": A list of iteration numbers at which the model was evaluated. - \"error\": A list of the weighted errors for each iteration. - \"r_time\": A list of the weighted running times for each iteration. - \"memory\": A list of the weighted memory usages for each iteration. - \"metric_name\": The name of the metric used for evaluation. Reference: https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) \"\"\" metric_name = metric . __class__ . __name__ # Convert dataset to a list if needed if dataset . __class__ != list : dataset = [ dataset ] n_steps = len ( dataset ) result = {} for model_name , model in models . items (): result_i = { \"step\" : [], \"error\" : [], \"r_time\" : [], \"memory\" : []} for checkpoint in iter_progressive_val_score ( dataset , model , metric , measure_time = True , measure_memory = True , step = step ): if log_level <= 20 : progress_bar ( checkpoint [ \"Step\" ] / n_steps , message = \"Eval iter_prog_val_score:\" ) w = ( checkpoint [ \"Step\" ] / n_steps ) ** weight_coeff result_i [ \"step\" ] . append ( checkpoint [ \"Step\" ]) result_i [ \"error\" ] . append ( w * checkpoint [ metric_name ] . get ()) # Convert timedelta object into seconds result_i [ \"r_time\" ] . append ( w * checkpoint [ \"Time\" ] . total_seconds ()) # Make sure the memory measurements are in MB raw_memory = checkpoint [ \"Memory\" ] result_i [ \"memory\" ] . append ( w * raw_memory * 2 **- 20 ) result_i [ \"metric_name\" ] = metric_name result [ model_name ] = result_i return result fun_eval_oml_iter_progressive ( result , metric = None , weights = None ) \u00b6 Wrapper function for eval_oml_iter_progressive, returning a single function value. Parameters: Name Type Description Default result dict A dictionary of evaluation results, as returned by eval_oml_iter_progressive. required metric function The metric function to use for computing the function value. Defaults to None, in which case the mean function is used. None weights numpy . array An array of weights for error, r_time, and memory. If None, the weights are set to [1, 0, 0], which considers only the error. Defaults to None. None Returns: Type Description numpy . array An array of function values, one for each model in the evaluation results. Raises: Type Description ValueError If the weights array is not of length 3. Reference https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive >>> result = { ... \"model1\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.1 , 0.2 , 0.3 ], ... \"r_time\" : [ 0.1 , 0.2 , 0.3 ], ... \"memory\" : [ 0.1 , 0.2 , 0.3 ], ... \"metric_name\" : \"MAE\" ... }, ... \"model2\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.2 , 0.3 , 0.4 ], ... \"r_time\" : [ 0.2 , 0.3 , 0.4 ], ... \"memory\" : [ 0.2 , 0.3 , 0.4 ], ... \"metric_name\" : \"MAE\" ... } ... } >>> fun_eval_oml_iter_progressive ( result ) array([0.1, 0.2]) Source code in spotRiver/evaluation/eval_oml.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def fun_eval_oml_iter_progressive ( result , metric = None , weights = None ): \"\"\"Wrapper function for eval_oml_iter_progressive, returning a single function value. Args: result (dict): A dictionary of evaluation results, as returned by eval_oml_iter_progressive. metric (function, optional): The metric function to use for computing the function value. Defaults to None, in which case the mean function is used. weights (numpy.array, optional): An array of weights for error, r_time, and memory. If None, the weights are set to [1, 0, 0], which considers only the error. Defaults to None. Returns: (numpy.array): An array of function values, one for each model in the evaluation results. Raises: ValueError: If the weights array is not of length 3. Reference: https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive >>> result = { ... \"model1\": { ... \"step\": [1, 2, 3], ... \"error\": [0.1, 0.2, 0.3], ... \"r_time\": [0.1, 0.2, 0.3], ... \"memory\": [0.1, 0.2, 0.3], ... \"metric_name\": \"MAE\" ... }, ... \"model2\": { ... \"step\": [1, 2, 3], ... \"error\": [0.2, 0.3, 0.4], ... \"r_time\": [0.2, 0.3, 0.4], ... \"memory\": [0.2, 0.3, 0.4], ... \"metric_name\": \"MAE\" ... } ... } >>> fun_eval_oml_iter_progressive(result) array([0.1, 0.2]) \"\"\" if metric is None : metric = mean if weights is None : weights = array ([ 1 , 0 , 0 ]) if len ( weights ) != 3 : raise ValueError ( \"The weights array must be of length 3.\" ) model_names = list ( result . keys ()) n = len ( model_names ) y = zeros ([ n ]) for i in range ( n ): y [ i ] = ( weights [ 0 ] * metric ( result [ model_names [ i ]][ \"error\" ]) + weights [ 1 ] * metric ( result [ model_names [ i ]][ \"r_time\" ]) + weights [ 2 ] * metric ( result [ model_names [ i ]][ \"memory\" ]) ) return y plot_oml_iter_progressive ( result , log_x = False , log_y = False , figsize = None , filename = None ) \u00b6 Plot evaluation of OML models. Parameters: Name Type Description Default result dict A dictionary of evaluation results, as returned by eval_oml_iter_progressive. required log_x bool If True, the x-axis is set to log scale. Defaults to False. False log_y bool If True, the y-axis is set to log scale. Defaults to False. False figsize tuple The size of the figure. Defaults to None, in which case the default figure size (10, 5) is used. None filename str The name of the file to save the plot to. If None, the plot is not saved. Defaults to None. None Returns: Type Description matplotlib . figure . Figure The figure object. Reference https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive >>> result = { ... \"model1\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.1 , 0.2 , 0.3 ], ... \"r_time\" : [ 0.1 , 0.2 , 0.3 ], ... \"memory\" : [ 0.1 , 0.2 , 0.3 ], ... \"metric_name\" : \"MAE\" ... }, ... \"model2\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.2 , 0.3 , 0.4 ], ... \"r_time\" : [ 0.2 , 0.3 , 0.4 ], ... \"memory\" : [ 0.2 , 0.3 , 0.4 ], ... \"metric_name\" : \"MAE\" ... } ... } >>> plot_oml_iter_progressive ( result ) <Figure size 1000x500 with 3 Axes> Source code in spotRiver/evaluation/eval_oml.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def plot_oml_iter_progressive ( result , log_x = False , log_y = False , figsize = None , filename = None ): \"\"\"Plot evaluation of OML models. Args: result (dict): A dictionary of evaluation results, as returned by eval_oml_iter_progressive. log_x (bool, optional): If True, the x-axis is set to log scale. Defaults to False. log_y (bool, optional): If True, the y-axis is set to log scale. Defaults to False. figsize (tuple, optional): The size of the figure. Defaults to None, in which case the default figure size `(10, 5)` is used. filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Defaults to None. Returns: (matplotlib.figure.Figure): The figure object. Reference: https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive >>> result = { ... \"model1\": { ... \"step\": [1, 2, 3], ... \"error\": [0.1, 0.2, 0.3], ... \"r_time\": [0.1, 0.2, 0.3], ... \"memory\": [0.1, 0.2, 0.3], ... \"metric_name\": \"MAE\" ... }, ... \"model2\": { ... \"step\": [1, 2, 3], ... \"error\": [0.2, 0.3, 0.4], ... \"r_time\": [0.2, 0.3, 0.4], ... \"memory\": [0.2, 0.3, 0.4], ... \"metric_name\": \"MAE\" ... } ... } >>> plot_oml_iter_progressive(result) <Figure size 1000x500 with 3 Axes> \"\"\" if figsize is None : figsize = ( 10 , 5 ) fig , ax = plt . subplots ( figsize = figsize , nrows = 3 , dpi = 300 ) for model_name , model in result . items (): ax [ 0 ] . plot ( model [ \"step\" ], model [ \"error\" ], label = model_name ) ax [ 1 ] . plot ( model [ \"step\" ], model [ \"r_time\" ], label = model_name ) ax [ 2 ] . plot ( model [ \"step\" ], model [ \"memory\" ], label = model_name ) ax [ 0 ] . set_ylabel ( model [ \"metric_name\" ]) ax [ 1 ] . set_ylabel ( \"Time (seconds)\" ) ax [ 2 ] . set_ylabel ( \"Memory (MB)\" ) ax [ 2 ] . set_xlabel ( \"Instances\" ) ax [ 0 ] . grid ( True ) ax [ 1 ] . grid ( True ) ax [ 2 ] . grid ( True ) if log_y : ax [ 0 ] . set_yscale ( \"log\" ) ax [ 1 ] . set_yscale ( \"log\" ) ax [ 2 ] . set_yscale ( \"log\" ) ax [ 0 ] . legend ( loc = \"upper center\" , bbox_to_anchor = ( 0.5 , 1.25 ), ncol = 3 , fancybox = True , shadow = True ) plt . tight_layout () plt . close () if filename is not None : fig . savefig ( filename , dpi = 300 ) return fig","title":"eval_oml"},{"location":"reference/spotRiver/evaluation/eval_oml/#spotRiver.evaluation.eval_oml.eval_oml_iter_progressive","text":"Evaluate OML Models on Streaming Data This function evaluates one or more OML models on a streaming dataset. The evaluation is done iteratively, and the models are tested every step iterations. The results are returned as a dictionary of metrics and their values. Parameters: Name Type Description Default dataset list or river.Stream A list of river.Stream objects containing the streaming data to be evaluated. If a single river.Stream object is provided, it is automatically converted to a list. required metric river.metrics.base.MultiClassMetric or river.metrics.base.RegressionMetric The metric to be used for evaluation. required models dict A dictionary of OML models to be evaluated. The keys are the names of the models, and the values are the model objects. required step int Iteration number at which to yield results. This only takes into account the predictions, and not the training steps. Defaults to 100. 100 weight_coeff float Results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff > 1. If weight_coeff == 0, then results are multiplied by 1 and every result has an equal weight. Defaults to 0.0. 0.0 log_level int The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. 50 Returns: Type Description dict A dictionary containing the evaluation results. The keys are the names of the models, and the values are dictionaries with the following keys: - \u201cstep\u201d: A list of iteration numbers at which the model was evaluated. - \u201cerror\u201d: A list of the weighted errors for each iteration. - \u201cr_time\u201d: A list of the weighted running times for each iteration. - \u201cmemory\u201d: A list of the weighted memory usages for each iteration. - \u201cmetric_name\u201d: The name of the metric used for evaluation. Reference https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) Source code in spotRiver/evaluation/eval_oml.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def eval_oml_iter_progressive ( dataset , metric , models , step = 100 , weight_coeff = 0.0 , log_level = 50 ): \"\"\"Evaluate OML Models on Streaming Data This function evaluates one or more OML models on a streaming dataset. The evaluation is done iteratively, and the models are tested every `step` iterations. The results are returned as a dictionary of metrics and their values. Args: dataset (list or river.Stream): A list of river.Stream objects containing the streaming data to be evaluated. If a single river.Stream object is provided, it is automatically converted to a list. metric (river.metrics.base.MultiClassMetric or river.metrics.base.RegressionMetric): The metric to be used for evaluation. models (dict): A dictionary of OML models to be evaluated. The keys are the names of the models, and the values are the model objects. step (int): Iteration number at which to yield results. This only takes into account the predictions, and not the training steps. Defaults to 100. weight_coeff (float): Results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff > 1. If weight_coeff == 0, then results are multiplied by 1 and every result has an equal weight. Defaults to 0.0. log_level (int): The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. Returns: (dict): A dictionary containing the evaluation results. The keys are the names of the models, and the values are dictionaries with the following keys: - \"step\": A list of iteration numbers at which the model was evaluated. - \"error\": A list of the weighted errors for each iteration. - \"r_time\": A list of the weighted running times for each iteration. - \"memory\": A list of the weighted memory usages for each iteration. - \"metric_name\": The name of the metric used for evaluation. Reference: https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from river import compose from river import linear_model from river import preprocessing, datasets, utils, metrics import matplotlib.pyplot as plt from spotRiver.utils.features import get_ordinal_date from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model model = compose.Pipeline( ('ordinal_date', compose.FuncTransformer(get_ordinal_date)), ('scale', preprocessing.StandardScaler()), ('lin_reg', linear_model.LinearRegression()) ) dataset = datasets.AirlinePassengers() dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset) plot_nowcast_model(dates, metric, y_trues, y_preds) \"\"\" metric_name = metric . __class__ . __name__ # Convert dataset to a list if needed if dataset . __class__ != list : dataset = [ dataset ] n_steps = len ( dataset ) result = {} for model_name , model in models . items (): result_i = { \"step\" : [], \"error\" : [], \"r_time\" : [], \"memory\" : []} for checkpoint in iter_progressive_val_score ( dataset , model , metric , measure_time = True , measure_memory = True , step = step ): if log_level <= 20 : progress_bar ( checkpoint [ \"Step\" ] / n_steps , message = \"Eval iter_prog_val_score:\" ) w = ( checkpoint [ \"Step\" ] / n_steps ) ** weight_coeff result_i [ \"step\" ] . append ( checkpoint [ \"Step\" ]) result_i [ \"error\" ] . append ( w * checkpoint [ metric_name ] . get ()) # Convert timedelta object into seconds result_i [ \"r_time\" ] . append ( w * checkpoint [ \"Time\" ] . total_seconds ()) # Make sure the memory measurements are in MB raw_memory = checkpoint [ \"Memory\" ] result_i [ \"memory\" ] . append ( w * raw_memory * 2 **- 20 ) result_i [ \"metric_name\" ] = metric_name result [ model_name ] = result_i return result","title":"eval_oml_iter_progressive()"},{"location":"reference/spotRiver/evaluation/eval_oml/#spotRiver.evaluation.eval_oml.fun_eval_oml_iter_progressive","text":"Wrapper function for eval_oml_iter_progressive, returning a single function value. Parameters: Name Type Description Default result dict A dictionary of evaluation results, as returned by eval_oml_iter_progressive. required metric function The metric function to use for computing the function value. Defaults to None, in which case the mean function is used. None weights numpy . array An array of weights for error, r_time, and memory. If None, the weights are set to [1, 0, 0], which considers only the error. Defaults to None. None Returns: Type Description numpy . array An array of function values, one for each model in the evaluation results. Raises: Type Description ValueError If the weights array is not of length 3. Reference https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive >>> result = { ... \"model1\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.1 , 0.2 , 0.3 ], ... \"r_time\" : [ 0.1 , 0.2 , 0.3 ], ... \"memory\" : [ 0.1 , 0.2 , 0.3 ], ... \"metric_name\" : \"MAE\" ... }, ... \"model2\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.2 , 0.3 , 0.4 ], ... \"r_time\" : [ 0.2 , 0.3 , 0.4 ], ... \"memory\" : [ 0.2 , 0.3 , 0.4 ], ... \"metric_name\" : \"MAE\" ... } ... } >>> fun_eval_oml_iter_progressive ( result ) array([0.1, 0.2]) Source code in spotRiver/evaluation/eval_oml.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def fun_eval_oml_iter_progressive ( result , metric = None , weights = None ): \"\"\"Wrapper function for eval_oml_iter_progressive, returning a single function value. Args: result (dict): A dictionary of evaluation results, as returned by eval_oml_iter_progressive. metric (function, optional): The metric function to use for computing the function value. Defaults to None, in which case the mean function is used. weights (numpy.array, optional): An array of weights for error, r_time, and memory. If None, the weights are set to [1, 0, 0], which considers only the error. Defaults to None. Returns: (numpy.array): An array of function values, one for each model in the evaluation results. Raises: ValueError: If the weights array is not of length 3. Reference: https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive >>> result = { ... \"model1\": { ... \"step\": [1, 2, 3], ... \"error\": [0.1, 0.2, 0.3], ... \"r_time\": [0.1, 0.2, 0.3], ... \"memory\": [0.1, 0.2, 0.3], ... \"metric_name\": \"MAE\" ... }, ... \"model2\": { ... \"step\": [1, 2, 3], ... \"error\": [0.2, 0.3, 0.4], ... \"r_time\": [0.2, 0.3, 0.4], ... \"memory\": [0.2, 0.3, 0.4], ... \"metric_name\": \"MAE\" ... } ... } >>> fun_eval_oml_iter_progressive(result) array([0.1, 0.2]) \"\"\" if metric is None : metric = mean if weights is None : weights = array ([ 1 , 0 , 0 ]) if len ( weights ) != 3 : raise ValueError ( \"The weights array must be of length 3.\" ) model_names = list ( result . keys ()) n = len ( model_names ) y = zeros ([ n ]) for i in range ( n ): y [ i ] = ( weights [ 0 ] * metric ( result [ model_names [ i ]][ \"error\" ]) + weights [ 1 ] * metric ( result [ model_names [ i ]][ \"r_time\" ]) + weights [ 2 ] * metric ( result [ model_names [ i ]][ \"memory\" ]) ) return y","title":"fun_eval_oml_iter_progressive()"},{"location":"reference/spotRiver/evaluation/eval_oml/#spotRiver.evaluation.eval_oml.plot_oml_iter_progressive","text":"Plot evaluation of OML models. Parameters: Name Type Description Default result dict A dictionary of evaluation results, as returned by eval_oml_iter_progressive. required log_x bool If True, the x-axis is set to log scale. Defaults to False. False log_y bool If True, the y-axis is set to log scale. Defaults to False. False figsize tuple The size of the figure. Defaults to None, in which case the default figure size (10, 5) is used. None filename str The name of the file to save the plot to. If None, the plot is not saved. Defaults to None. None Returns: Type Description matplotlib . figure . Figure The figure object. Reference https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive >>> result = { ... \"model1\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.1 , 0.2 , 0.3 ], ... \"r_time\" : [ 0.1 , 0.2 , 0.3 ], ... \"memory\" : [ 0.1 , 0.2 , 0.3 ], ... \"metric_name\" : \"MAE\" ... }, ... \"model2\" : { ... \"step\" : [ 1 , 2 , 3 ], ... \"error\" : [ 0.2 , 0.3 , 0.4 ], ... \"r_time\" : [ 0.2 , 0.3 , 0.4 ], ... \"memory\" : [ 0.2 , 0.3 , 0.4 ], ... \"metric_name\" : \"MAE\" ... } ... } >>> plot_oml_iter_progressive ( result ) <Figure size 1000x500 with 3 Axes> Source code in spotRiver/evaluation/eval_oml.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def plot_oml_iter_progressive ( result , log_x = False , log_y = False , figsize = None , filename = None ): \"\"\"Plot evaluation of OML models. Args: result (dict): A dictionary of evaluation results, as returned by eval_oml_iter_progressive. log_x (bool, optional): If True, the x-axis is set to log scale. Defaults to False. log_y (bool, optional): If True, the y-axis is set to log scale. Defaults to False. figsize (tuple, optional): The size of the figure. Defaults to None, in which case the default figure size `(10, 5)` is used. filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Defaults to None. Returns: (matplotlib.figure.Figure): The figure object. Reference: https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/ Examples: >>> from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive >>> result = { ... \"model1\": { ... \"step\": [1, 2, 3], ... \"error\": [0.1, 0.2, 0.3], ... \"r_time\": [0.1, 0.2, 0.3], ... \"memory\": [0.1, 0.2, 0.3], ... \"metric_name\": \"MAE\" ... }, ... \"model2\": { ... \"step\": [1, 2, 3], ... \"error\": [0.2, 0.3, 0.4], ... \"r_time\": [0.2, 0.3, 0.4], ... \"memory\": [0.2, 0.3, 0.4], ... \"metric_name\": \"MAE\" ... } ... } >>> plot_oml_iter_progressive(result) <Figure size 1000x500 with 3 Axes> \"\"\" if figsize is None : figsize = ( 10 , 5 ) fig , ax = plt . subplots ( figsize = figsize , nrows = 3 , dpi = 300 ) for model_name , model in result . items (): ax [ 0 ] . plot ( model [ \"step\" ], model [ \"error\" ], label = model_name ) ax [ 1 ] . plot ( model [ \"step\" ], model [ \"r_time\" ], label = model_name ) ax [ 2 ] . plot ( model [ \"step\" ], model [ \"memory\" ], label = model_name ) ax [ 0 ] . set_ylabel ( model [ \"metric_name\" ]) ax [ 1 ] . set_ylabel ( \"Time (seconds)\" ) ax [ 2 ] . set_ylabel ( \"Memory (MB)\" ) ax [ 2 ] . set_xlabel ( \"Instances\" ) ax [ 0 ] . grid ( True ) ax [ 1 ] . grid ( True ) ax [ 2 ] . grid ( True ) if log_y : ax [ 0 ] . set_yscale ( \"log\" ) ax [ 1 ] . set_yscale ( \"log\" ) ax [ 2 ] . set_yscale ( \"log\" ) ax [ 0 ] . legend ( loc = \"upper center\" , bbox_to_anchor = ( 0.5 , 1.25 ), ncol = 3 , fancybox = True , shadow = True ) plt . tight_layout () plt . close () if filename is not None : fig . savefig ( filename , dpi = 300 ) return fig","title":"plot_oml_iter_progressive()"},{"location":"reference/spotRiver/fun/hyperriver/","text":"HyperRiver \u00b6 Hyperparameter Tuning for River. Parameters: Name Type Description Default seed int seed. See Numpy Random Sampling 126 Source code in spotRiver/fun/hyperriver.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 class HyperRiver : \"\"\" Hyperparameter Tuning for River. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) \"\"\" def __init__ ( self , seed = 126 , log_level = 50 ): \"\"\"Initialize the class. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) log_level (int): The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. Returns: (NoneType): None \"\"\" self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"seed\" : None , \"data\" : None , \"step\" : 10_000 , \"horizon\" : None , \"grace_period\" : None , \"metric_river\" : None , \"metric_sklearn\" : mean_absolute_error , \"weights\" : array ([ 1 , 0 , 0 ]), \"weight_coeff\" : 0.0 , \"log_level\" : log_level , \"var_name\" : [], \"var_type\" : [], \"prep_model\" : None , } self . log_level = self . fun_control [ \"log_level\" ] logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y def check_X_shape ( self , X ): \"\"\" Check the shape of X. Args: X (np.ndarray): The input data. Returns: (NoneType): None Examples: >>> X = np.array([[1, 2, 3], [4, 5, 6]]) >>> check_X_shape(X) >>> X = np.array([1, 2, 3]) >>> check_X_shape(X) Traceback (most recent call last): ... Exception \"\"\" try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception def evaluate_model ( self , model : object , fun_control : dict ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" Evaluates a model using the eval_oml_horizon function. Args: model (object): The model to be evaluated. fun_control (dict): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> fun_control = { ... \"train\": train_data, ... \"test\": test_data, ... \"target_column\": \"target\", ... \"horizon\": 5, ... \"oml_grace_period\": 10, ... \"metric_sklearn\": \"accuracy\" ... } >>> df_eval, df_preds = evaluate_model(model, fun_control) \"\"\" try : df_eval , df_preds = eval_oml_horizon ( model = model , train = fun_control [ \"train\" ], test = fun_control [ \"test\" ], target_column = fun_control [ \"target_column\" ], horizon = fun_control [ \"horizon\" ], oml_grace_period = fun_control [ \"oml_grace_period\" ], metric = fun_control [ \"metric_sklearn\" ], ) except Exception as err : print ( f \"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. { err =} , { type ( err ) =} \" ) return df_eval , df_preds def get_river_df_eval_preds ( self , model ): \"\"\"Get the evaluation and prediction dataframes for a river model. Args: model (object): The model to be evaluated. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> df_eval, df_preds = get_river_df_eval_preds(model) \"\"\" try : df_eval , df_preds = self . evaluate_model ( model , self . fun_control ) except Exception as err : print ( f \"Error in get_river_df_eval_preds(). Call to evaluate_model failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval and df.preds to np.nan\" ) df_eval = np . nan df_preds = np . nan return df_eval , df_preds def fun_oml_horizon ( self , X : np . ndarray , fun_control : Optional [ Dict [ str , Any ]] = None ) -> np . ndarray : \"\"\" The objective function for hyperparameter tuning. This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning. Args: X (np.ndarray): The input data. fun_control (dict, optional): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (np.ndarray): The objective function values. Examples: >>> fun_oml_horizon(X, fun_control={'train': train_data, 'test': test_data, 'target_column': 'y', 'horizon': 5, 'oml_grace_period': 10, 'metric_sklearn': 'accuracy'}) array([0.8, 0.85, 0.9]) \"\"\" z_res = [] self . fun_control . update ( fun_control ) self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) for config in generate_one_config_from_var_dict ( var_dict , self . fun_control ): config_id = generate_config_id ( config ) if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res ) __init__ ( seed = 126 , log_level = 50 ) \u00b6 Initialize the class. Parameters: Name Type Description Default seed int seed. See Numpy Random Sampling 126 log_level int The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. 50 Returns: Type Description NoneType None Source code in spotRiver/fun/hyperriver.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def __init__ ( self , seed = 126 , log_level = 50 ): \"\"\"Initialize the class. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) log_level (int): The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. Returns: (NoneType): None \"\"\" self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"seed\" : None , \"data\" : None , \"step\" : 10_000 , \"horizon\" : None , \"grace_period\" : None , \"metric_river\" : None , \"metric_sklearn\" : mean_absolute_error , \"weights\" : array ([ 1 , 0 , 0 ]), \"weight_coeff\" : 0.0 , \"log_level\" : log_level , \"var_name\" : [], \"var_type\" : [], \"prep_model\" : None , } self . log_level = self . fun_control [ \"log_level\" ] logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) check_X_shape ( X ) \u00b6 Check the shape of X. Parameters: Name Type Description Default X np . ndarray The input data. required Returns: Type Description NoneType None Examples: >>> X = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) >>> check_X_shape ( X ) >>> X = np . array ([ 1 , 2 , 3 ]) >>> check_X_shape ( X ) Traceback (most recent call last): ... Exception Source code in spotRiver/fun/hyperriver.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def check_X_shape ( self , X ): \"\"\" Check the shape of X. Args: X (np.ndarray): The input data. Returns: (NoneType): None Examples: >>> X = np.array([[1, 2, 3], [4, 5, 6]]) >>> check_X_shape(X) >>> X = np.array([1, 2, 3]) >>> check_X_shape(X) Traceback (most recent call last): ... Exception \"\"\" try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception compute_y ( df_eval ) \u00b6 Compute the objective function value. Parameters: Name Type Description Default df_eval pd . DataFrame DataFrame with the evaluation results. required Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd . DataFrame ( [[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]], columns = [ 'Metric' , 'CompTime (s)' , 'Memory (MB)' ]) >>> weights = [ 1 , 1 , 1 ] >>> compute_y ( df_eval , weights ) 4.0 Source code in spotRiver/fun/hyperriver.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y evaluate_model ( model , fun_control ) \u00b6 Evaluates a model using the eval_oml_horizon function. Parameters: Name Type Description Default model object The model to be evaluated. required fun_control dict A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. required Returns: Type Description Tuple [ pd . DataFrame , pd . DataFrame ] A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel () >>> fun_control = { ... \"train\" : train_data , ... \"test\" : test_data , ... \"target_column\" : \"target\" , ... \"horizon\" : 5 , ... \"oml_grace_period\" : 10 , ... \"metric_sklearn\" : \"accuracy\" ... } >>> df_eval , df_preds = evaluate_model ( model , fun_control ) Source code in spotRiver/fun/hyperriver.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def evaluate_model ( self , model : object , fun_control : dict ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" Evaluates a model using the eval_oml_horizon function. Args: model (object): The model to be evaluated. fun_control (dict): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> fun_control = { ... \"train\": train_data, ... \"test\": test_data, ... \"target_column\": \"target\", ... \"horizon\": 5, ... \"oml_grace_period\": 10, ... \"metric_sklearn\": \"accuracy\" ... } >>> df_eval, df_preds = evaluate_model(model, fun_control) \"\"\" try : df_eval , df_preds = eval_oml_horizon ( model = model , train = fun_control [ \"train\" ], test = fun_control [ \"test\" ], target_column = fun_control [ \"target_column\" ], horizon = fun_control [ \"horizon\" ], oml_grace_period = fun_control [ \"oml_grace_period\" ], metric = fun_control [ \"metric_sklearn\" ], ) except Exception as err : print ( f \"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. { err =} , { type ( err ) =} \" ) return df_eval , df_preds fun_oml_horizon ( X , fun_control = None ) \u00b6 The objective function for hyperparameter tuning. This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning. Parameters: Name Type Description Default X np . ndarray The input data. required fun_control dict A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. None Returns: Type Description np . ndarray The objective function values. Examples: >>> fun_oml_horizon ( X , fun_control = { 'train' : train_data , 'test' : test_data , 'target_column' : 'y' , 'horizon' : 5 , 'oml_grace_period' : 10 , 'metric_sklearn' : 'accuracy' }) array([0.8, 0.85, 0.9]) Source code in spotRiver/fun/hyperriver.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 def fun_oml_horizon ( self , X : np . ndarray , fun_control : Optional [ Dict [ str , Any ]] = None ) -> np . ndarray : \"\"\" The objective function for hyperparameter tuning. This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning. Args: X (np.ndarray): The input data. fun_control (dict, optional): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (np.ndarray): The objective function values. Examples: >>> fun_oml_horizon(X, fun_control={'train': train_data, 'test': test_data, 'target_column': 'y', 'horizon': 5, 'oml_grace_period': 10, 'metric_sklearn': 'accuracy'}) array([0.8, 0.85, 0.9]) \"\"\" z_res = [] self . fun_control . update ( fun_control ) self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) for config in generate_one_config_from_var_dict ( var_dict , self . fun_control ): config_id = generate_config_id ( config ) if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res ) get_river_df_eval_preds ( model ) \u00b6 Get the evaluation and prediction dataframes for a river model. Parameters: Name Type Description Default model object The model to be evaluated. required Returns: Type Description Tuple [ pd . DataFrame , pd . DataFrame ] A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel () >>> df_eval , df_preds = get_river_df_eval_preds ( model ) Source code in spotRiver/fun/hyperriver.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def get_river_df_eval_preds ( self , model ): \"\"\"Get the evaluation and prediction dataframes for a river model. Args: model (object): The model to be evaluated. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> df_eval, df_preds = get_river_df_eval_preds(model) \"\"\" try : df_eval , df_preds = self . evaluate_model ( model , self . fun_control ) except Exception as err : print ( f \"Error in get_river_df_eval_preds(). Call to evaluate_model failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval and df.preds to np.nan\" ) df_eval = np . nan df_preds = np . nan return df_eval , df_preds","title":"hyperriver"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver","text":"Hyperparameter Tuning for River. Parameters: Name Type Description Default seed int seed. See Numpy Random Sampling 126 Source code in spotRiver/fun/hyperriver.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 class HyperRiver : \"\"\" Hyperparameter Tuning for River. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) \"\"\" def __init__ ( self , seed = 126 , log_level = 50 ): \"\"\"Initialize the class. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) log_level (int): The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. Returns: (NoneType): None \"\"\" self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"seed\" : None , \"data\" : None , \"step\" : 10_000 , \"horizon\" : None , \"grace_period\" : None , \"metric_river\" : None , \"metric_sklearn\" : mean_absolute_error , \"weights\" : array ([ 1 , 0 , 0 ]), \"weight_coeff\" : 0.0 , \"log_level\" : log_level , \"var_name\" : [], \"var_type\" : [], \"prep_model\" : None , } self . log_level = self . fun_control [ \"log_level\" ] logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y def check_X_shape ( self , X ): \"\"\" Check the shape of X. Args: X (np.ndarray): The input data. Returns: (NoneType): None Examples: >>> X = np.array([[1, 2, 3], [4, 5, 6]]) >>> check_X_shape(X) >>> X = np.array([1, 2, 3]) >>> check_X_shape(X) Traceback (most recent call last): ... Exception \"\"\" try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception def evaluate_model ( self , model : object , fun_control : dict ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" Evaluates a model using the eval_oml_horizon function. Args: model (object): The model to be evaluated. fun_control (dict): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> fun_control = { ... \"train\": train_data, ... \"test\": test_data, ... \"target_column\": \"target\", ... \"horizon\": 5, ... \"oml_grace_period\": 10, ... \"metric_sklearn\": \"accuracy\" ... } >>> df_eval, df_preds = evaluate_model(model, fun_control) \"\"\" try : df_eval , df_preds = eval_oml_horizon ( model = model , train = fun_control [ \"train\" ], test = fun_control [ \"test\" ], target_column = fun_control [ \"target_column\" ], horizon = fun_control [ \"horizon\" ], oml_grace_period = fun_control [ \"oml_grace_period\" ], metric = fun_control [ \"metric_sklearn\" ], ) except Exception as err : print ( f \"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. { err =} , { type ( err ) =} \" ) return df_eval , df_preds def get_river_df_eval_preds ( self , model ): \"\"\"Get the evaluation and prediction dataframes for a river model. Args: model (object): The model to be evaluated. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> df_eval, df_preds = get_river_df_eval_preds(model) \"\"\" try : df_eval , df_preds = self . evaluate_model ( model , self . fun_control ) except Exception as err : print ( f \"Error in get_river_df_eval_preds(). Call to evaluate_model failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval and df.preds to np.nan\" ) df_eval = np . nan df_preds = np . nan return df_eval , df_preds def fun_oml_horizon ( self , X : np . ndarray , fun_control : Optional [ Dict [ str , Any ]] = None ) -> np . ndarray : \"\"\" The objective function for hyperparameter tuning. This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning. Args: X (np.ndarray): The input data. fun_control (dict, optional): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (np.ndarray): The objective function values. Examples: >>> fun_oml_horizon(X, fun_control={'train': train_data, 'test': test_data, 'target_column': 'y', 'horizon': 5, 'oml_grace_period': 10, 'metric_sklearn': 'accuracy'}) array([0.8, 0.85, 0.9]) \"\"\" z_res = [] self . fun_control . update ( fun_control ) self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) for config in generate_one_config_from_var_dict ( var_dict , self . fun_control ): config_id = generate_config_id ( config ) if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res )","title":"HyperRiver"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.__init__","text":"Initialize the class. Parameters: Name Type Description Default seed int seed. See Numpy Random Sampling 126 log_level int The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. 50 Returns: Type Description NoneType None Source code in spotRiver/fun/hyperriver.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def __init__ ( self , seed = 126 , log_level = 50 ): \"\"\"Initialize the class. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) log_level (int): The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50. Returns: (NoneType): None \"\"\" self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"seed\" : None , \"data\" : None , \"step\" : 10_000 , \"horizon\" : None , \"grace_period\" : None , \"metric_river\" : None , \"metric_sklearn\" : mean_absolute_error , \"weights\" : array ([ 1 , 0 , 0 ]), \"weight_coeff\" : 0.0 , \"log_level\" : log_level , \"var_name\" : [], \"var_type\" : [], \"prep_model\" : None , } self . log_level = self . fun_control [ \"log_level\" ] logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" )","title":"__init__()"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.check_X_shape","text":"Check the shape of X. Parameters: Name Type Description Default X np . ndarray The input data. required Returns: Type Description NoneType None Examples: >>> X = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) >>> check_X_shape ( X ) >>> X = np . array ([ 1 , 2 , 3 ]) >>> check_X_shape ( X ) Traceback (most recent call last): ... Exception Source code in spotRiver/fun/hyperriver.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def check_X_shape ( self , X ): \"\"\" Check the shape of X. Args: X (np.ndarray): The input data. Returns: (NoneType): None Examples: >>> X = np.array([[1, 2, 3], [4, 5, 6]]) >>> check_X_shape(X) >>> X = np.array([1, 2, 3]) >>> check_X_shape(X) Traceback (most recent call last): ... Exception \"\"\" try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception","title":"check_X_shape()"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.compute_y","text":"Compute the objective function value. Parameters: Name Type Description Default df_eval pd . DataFrame DataFrame with the evaluation results. required Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd . DataFrame ( [[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]], columns = [ 'Metric' , 'CompTime (s)' , 'Memory (MB)' ]) >>> weights = [ 1 , 1 , 1 ] >>> compute_y ( df_eval , weights ) 4.0 Source code in spotRiver/fun/hyperriver.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y","title":"compute_y()"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.evaluate_model","text":"Evaluates a model using the eval_oml_horizon function. Parameters: Name Type Description Default model object The model to be evaluated. required fun_control dict A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. required Returns: Type Description Tuple [ pd . DataFrame , pd . DataFrame ] A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel () >>> fun_control = { ... \"train\" : train_data , ... \"test\" : test_data , ... \"target_column\" : \"target\" , ... \"horizon\" : 5 , ... \"oml_grace_period\" : 10 , ... \"metric_sklearn\" : \"accuracy\" ... } >>> df_eval , df_preds = evaluate_model ( model , fun_control ) Source code in spotRiver/fun/hyperriver.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def evaluate_model ( self , model : object , fun_control : dict ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" Evaluates a model using the eval_oml_horizon function. Args: model (object): The model to be evaluated. fun_control (dict): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> fun_control = { ... \"train\": train_data, ... \"test\": test_data, ... \"target_column\": \"target\", ... \"horizon\": 5, ... \"oml_grace_period\": 10, ... \"metric_sklearn\": \"accuracy\" ... } >>> df_eval, df_preds = evaluate_model(model, fun_control) \"\"\" try : df_eval , df_preds = eval_oml_horizon ( model = model , train = fun_control [ \"train\" ], test = fun_control [ \"test\" ], target_column = fun_control [ \"target_column\" ], horizon = fun_control [ \"horizon\" ], oml_grace_period = fun_control [ \"oml_grace_period\" ], metric = fun_control [ \"metric_sklearn\" ], ) except Exception as err : print ( f \"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. { err =} , { type ( err ) =} \" ) return df_eval , df_preds","title":"evaluate_model()"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.fun_oml_horizon","text":"The objective function for hyperparameter tuning. This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning. Parameters: Name Type Description Default X np . ndarray The input data. required fun_control dict A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. None Returns: Type Description np . ndarray The objective function values. Examples: >>> fun_oml_horizon ( X , fun_control = { 'train' : train_data , 'test' : test_data , 'target_column' : 'y' , 'horizon' : 5 , 'oml_grace_period' : 10 , 'metric_sklearn' : 'accuracy' }) array([0.8, 0.85, 0.9]) Source code in spotRiver/fun/hyperriver.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 def fun_oml_horizon ( self , X : np . ndarray , fun_control : Optional [ Dict [ str , Any ]] = None ) -> np . ndarray : \"\"\" The objective function for hyperparameter tuning. This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning. Args: X (np.ndarray): The input data. fun_control (dict, optional): A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation. Returns: (np.ndarray): The objective function values. Examples: >>> fun_oml_horizon(X, fun_control={'train': train_data, 'test': test_data, 'target_column': 'y', 'horizon': 5, 'oml_grace_period': 10, 'metric_sklearn': 'accuracy'}) array([0.8, 0.85, 0.9]) \"\"\" z_res = [] self . fun_control . update ( fun_control ) self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) for config in generate_one_config_from_var_dict ( var_dict , self . fun_control ): config_id = generate_config_id ( config ) if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res )","title":"fun_oml_horizon()"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.get_river_df_eval_preds","text":"Get the evaluation and prediction dataframes for a river model. Parameters: Name Type Description Default model object The model to be evaluated. required Returns: Type Description Tuple [ pd . DataFrame , pd . DataFrame ] A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel () >>> df_eval , df_preds = get_river_df_eval_preds ( model ) Source code in spotRiver/fun/hyperriver.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def get_river_df_eval_preds ( self , model ): \"\"\"Get the evaluation and prediction dataframes for a river model. Args: model (object): The model to be evaluated. Returns: (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe. Examples: >>> model = SomeModel() >>> df_eval, df_preds = get_river_df_eval_preds(model) \"\"\" try : df_eval , df_preds = self . evaluate_model ( model , self . fun_control ) except Exception as err : print ( f \"Error in get_river_df_eval_preds(). Call to evaluate_model failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval and df.preds to np.nan\" ) df_eval = np . nan df_preds = np . nan return df_eval , df_preds","title":"get_river_df_eval_preds()"},{"location":"reference/spotRiver/fun/hyperriver_old/","text":"HyperRiver \u00b6 Hyperparameter Tuning for River. Parameters: Name Type Description Default seed int seed. See Numpy Random Sampling 126 Source code in spotRiver/fun/hyperriver_old.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 class HyperRiver : \"\"\" Hyperparameter Tuning for River. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) \"\"\" def __init__ ( self , seed = 126 , log_level = 50 ): self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"seed\" : None , \"data\" : None , \"step\" : 10_000 , \"horizon\" : None , \"grace_period\" : None , \"metric\" : metrics . MAE (), \"metric_sklearn\" : mean_absolute_error , \"weights\" : array ([ 1 , 0 , 0 ]), \"weight_coeff\" : 0.0 , \"log_level\" : log_level , \"var_name\" : [], \"var_type\" : [], \"prep_model\" : None , } self . log_level = self . fun_control [ \"log_level\" ] logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) # def get_month_distances(x): # return { # calendar.month_name[month]: math.exp(-(x['month'].month - month) ** 2) # for month in range(1, 13) # } # def get_ordinal_date(x): # return {'ordinal_date': x['month'].toordinal()} def fun_nowcasting ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the nowcasting model. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception lr = X [:, 0 ] intercept_lr = X [:, 1 ] hour = X [:, 2 ] weekday = X [:, 3 ] month = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( ( \"features\" , extract_features ), ( \"scale\" , preprocessing . StandardScaler ()), ( \"lin_reg\" , linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]) ), ), ) # eval: dates , metric , y_trues , y_preds = eval_nowcast_model ( model , dataset = self . fun_control [ \"data\" ], time_interval = \"Time\" ) z = metric . get () z_res = np . append ( z_res , z ) return z_res def fun_snarimax ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the SNARIMAX model. SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include features that will be available both at training and prediction time. Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model. This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time. Parameters of the hyperparameter vector: `p`: Order of the autoregressive part. This is the number of past target values that will be included as features. `d`: Differencing order. `q`: Order of the moving average part. This is the number of past error terms that will be included as features. `m`: Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp`: Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd`: Seasonal differencing order. `sq`: Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekdy` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. Args: X (array): Seven hyperparameters to be optimized. Here: `p` (int): Order of the autoregressive part. This is the number of past target values that will be included as features. `d` (int): Differencing order. `q` (int): Order of the moving average part. This is the number of past error terms that will be included as features. `m` (int): Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp` (int): Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd` (int): Seasonal differencing order. `sq`(int): Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekday` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. fun_control (dict): parameter that are not optimized, e.g., `horizon`. Commonly referred to as \"design of experiments\" parameters: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 3. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 12 : raise Exception p = X [:, 0 ] d = X [:, 1 ] q = X [:, 2 ] m = X [:, 3 ] sp = X [:, 4 ] sd = X [:, 5 ] sq = X [:, 6 ] lr = X [:, 7 ] intercept_lr = X [:, 8 ] hour = X [:, 9 ] weekday = X [:, 10 ] month = X [:, 11 ] # TODO: # horizon = fun_control[\"horizon\"] # future = [ # {\"month\": dt.date(year=1961, month=m, day=1)} for m in range(1, horizon + 1) # ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( extract_features , time_series . SNARIMAX ( p = int ( p [ i ]), d = int ( d [ i ]), q = int ( q [ i ]), m = int ( m [ i ]), sp = int ( sp [ i ]), sd = int ( sd [ i ]), sq = int ( sq [ i ]), regressor = compose . Pipeline ( preprocessing . StandardScaler (), linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]), ), ), ), ) # eval: res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res def fun_hw ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the HoltWinters model. Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method. Certain parameterizations result in special cases, such as simple exponential smoothing. Args: X (array): five hyperparameters. The parameters of the hyperparameter vector are: 1. `alpha`: Smoothing parameter for the level. 2. `beta`: Smoothing parameter for the trend. 3. `gamma`: Smoothing parameter for the seasonality. 4. `seasonality`: The number of periods in a season. For instance, this should be 4 for quarterly data, and 12 for yearly data. 5. `multiplicative`: Whether or not to use a multiplicative formulation. fun_control (dict): Parameters that are are not tuned: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 2. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception alpha = X [:, 0 ] beta = X [:, 1 ] gamma = X [:, 2 ] seasonality = X [:, 3 ] multiplicative = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): model = time_series . HoltWinters ( alpha = alpha [ i ], beta = beta [ i ], gamma = gamma [ i ], seasonality = int ( seasonality [ i ]), multiplicative = int ( multiplicative [ i ]), ) res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], grace_period = self . fun_control [ \"grace_period\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res # def fun_HTR_iter_progressive(self, X, fun_control=None): # \"\"\"Hyperparameter Tuning of HTR model. # See: https://riverml.xyz/0.15.0/api/tree/HoeffdingTreeRegressor/ # Parameters # ---------- # grace_period # Number of instances a leaf should observe between split attempts. # max_depth # The maximum depth a tree can reach. If `None`, the tree will grow indefinitely. # delta # Significance level to calculate the Hoeffding bound. The significance level is given by # `1 - delta`. Values closer to zero imply longer split decision delays. # tau # Threshold below which a split will be forced to break ties. # leaf_prediction # Prediction mechanism used at leafs. NOTE: order differs from the order in river!</br> # - 'mean' - Target mean</br> # - 'adaptive' - Chooses between 'mean' and 'model' dynamically</br> # - 'model' - Uses the model defined in `leaf_model`</br> # NOT IMPLEMENTED: leaf_model # The regression model used to provide responses if `leaf_prediction='model'`. If not # provided an instance of `river.linear_model.LinearRegression` with the default # hyperparameters is used. # model_selector_decay # The exponential decaying factor applied to the learning models' squared errors, that # are monitored if `leaf_prediction='adaptive'`. Must be between `0` and `1`. The closer # to `1`, the more importance is going to be given to past observations. On the other hand, # if its value approaches `0`, the recent observed errors are going to have more influence # on the final decision. # nominal_attributes # List of Nominal attributes identifiers. If empty, then assume that all numeric attributes # should be treated as continuous. # splitter # The Splitter or Attribute Observer (AO) used to monitor the class statistics of numeric # features and perform splits. Splitters are available in the `tree.splitter` module. # Different splitters are available for classification and regression tasks. Classification # and regression splitters can be distinguished by their property `is_target_class`. # This is an advanced option. Special care must be taken when choosing different splitters. # By default, `tree.splitter.TEBSTSplitter` is used if `splitter` is `None`. # min_samples_split # The minimum number of samples every branch resulting from a split candidate must have # to be considered valid. # binary_split # If True, only allow binary splits. # max_size # The max size of the tree, in Megabytes (MB). # memory_estimate_period # Interval (number of processed instances) between memory consumption checks. # stop_mem_management # If True, stop growing as soon as memory limit is hit. # remove_poor_attrs # If True, disable poor attributes to reduce memory usage. # merit_preprune # If True, enable merit-based tree pre-pruning. # fun_control # Parameters that are are not tuned: # 1. `horizon`: (int) # 2. `grace_period`: (int) Initial period during which the metric is not updated. # This is to fairly evaluate models which need a warming up period to start # producing meaningful forecasts. # The value of this parameter is equal to the `horizon` by default. # 3. `data`: dataset. Default `AirlinePassengers`. # Returns # ------- # (float): objective function value. Mean of the MAEs of the predicted values. # \"\"\" # self.fun_control.update(fun_control) # try: # X.shape[1] # except ValueError: # X = np.array([X]) # if X.shape[1] != 11: # raise Exception # grace_period = X[:, 0] # max_depth = X[:, 1] # delta = X[:, 2] # tau = X[:, 3] # leaf_prediction = X[:, 4] # leaf_model = X[:, 5] # model_selector_decay = X[:, 6] # splitter = X[:, 7] # min_samples_split = X[:, 8] # binary_split = X[:, 9] # max_size = X[:, 10] # z_res = np.array([], dtype=float) # dataset_list = self.fun_control[\"data\"] # for i in range(X.shape[0]): # num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler() # cat = compose.SelectType(str) | preprocessing.FeatureHasher(n_features=1000, seed=1) # try: # res = eval_oml_iter_progressive( # dataset=dataset_list, # step=self.fun_control[\"step\"], # log_level=self.fun_control[\"log_level\"], # metric=fun_control[\"metric\"], # weight_coeff=fun_control[\"weight_coeff\"], # models={ # \"HTR\": ( # (num + cat) # | tree.HoeffdingTreeRegressor( # grace_period=int(grace_period[i]), # max_depth=transform_power_10(int(max_depth[i])), # delta=float(delta[i]), # tau=float(tau[i]), # leaf_prediction=select_leaf_prediction(int(leaf_prediction[i])), # leaf_model=select_leaf_model(int(leaf_model[i])), # model_selector_decay=float(model_selector_decay[i]), # splitter=select_splitter(int(splitter[i])), # min_samples_split=int(min_samples_split[i]), # binary_split=int(binary_split[i]), # max_size=float(max_size[i]), # ) # ), # }, # ) # logger.debug(\"res from eval_oml_iter_progressive: %s\", res) # y = fun_eval_oml_iter_progressive(res, metric=None, weights=self.fun_control[\"weights\"]) # except Exception as err: # y = np.nan # print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\") # print(f\"Setting y to {y:.2f}.\") # z_res = np.append(z_res, y / self.fun_control[\"n_samples\"]) # return z_res def fun_oml_iter_progressive ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of an arbitrary model. Returns ------- (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = np . array ([], dtype = float ) dataset_list = self . fun_control [ \"data\" ] for values in iterate_dict_values ( var_dict ): values = convert_keys ( values , self . fun_control [ \"var_type\" ]) print ( values ) values = get_dict_with_levels_and_types ( fun_control = self . fun_control , v = values ) values = transform_hyper_parameter_values ( fun_control = self . fun_control , hyper_parameter_values = values ) print ( values ) model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** values )) try : res = eval_oml_iter_progressive ( dataset = dataset_list , step = self . fun_control [ \"step\" ], log_level = self . fun_control [ \"log_level\" ], metric = fun_control [ \"metric\" ], weight_coeff = fun_control [ \"weight_coeff\" ], models = { self . fun_control [ \"model_name\" ]: ( model ), }, ) logger . debug ( \"res from eval_oml_iter_progressive: %s \" , res ) y = fun_eval_oml_iter_progressive ( res , metric = None , weights = self . fun_control [ \"weights\" ]) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting y to { y : .2f } .\" ) z_res = np . append ( z_res , y / self . fun_control [ \"n_samples\" ]) return z_res def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y # def fun_oml_horizon_old(self, X, fun_control=None, return_model=False, return_df=False): # \"\"\"Hyperparameter Tuning of an arbitrary model. # Returns # ------- # (float): objective function value. Mean of the MAEs of the predicted values. # \"\"\" # self.fun_control.update(fun_control) # weights = self.fun_control[\"weights\"] # if len(weights) != 3: # raise ValueError(\"The weights array must be of length 3.\") # try: # X.shape[1] # except ValueError: # X = np.array([X]) # if X.shape[1] != len(self.fun_control[\"var_name\"]): # raise Exception # var_dict = assign_values(X, self.fun_control[\"var_name\"]) # z_res = np.array([], dtype=float) # for values in iterate_dict_values(var_dict): # values = convert_keys(values, self.fun_control[\"var_type\"]) # values = get_dict_with_levels_and_types(fun_control=self.fun_control, v=values) # values = transform_hyper_parameter_values(fun_control=self.fun_control, hyper_parameter_values=values) # model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**values)) # if return_model: # return model # try: # df_eval, df_preds = eval_oml_horizon( # model=model, # train=self.fun_control[\"train\"], # test=self.fun_control[\"test\"], # target_column=self.fun_control[\"target_column\"], # horizon=self.fun_control[\"horizon\"], # oml_grace_period=self.fun_control[\"oml_grace_period\"], # metric=self.fun_control[\"metric_sklearn\"], # ) # except Exception as err: # print(f\"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. {err=}, {type(err)=}\") # if return_df: # return df_eval, df_preds # try: # y = self.compute_y(df_eval, weights) # except Exception as err: # y = np.nan # print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\") # print(f\"Setting y to {y:.2f}.\") # z_res = np.append(z_res, y / self.fun_control[\"n_samples\"]) # return z_res def check_weights ( self ): if len ( self . fun_control [ \"weights\" ]) != 3 : raise ValueError ( \"The weights array must be of length 3.\" ) def check_X_shape ( self , X ): try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception def evaluate_model ( self , model , fun_control ): try : df_eval , df_preds = eval_oml_horizon ( model = model , train = fun_control [ \"train\" ], test = fun_control [ \"test\" ], target_column = fun_control [ \"target_column\" ], horizon = fun_control [ \"horizon\" ], oml_grace_period = fun_control [ \"oml_grace_period\" ], metric = fun_control [ \"metric_sklearn\" ], ) except Exception as err : print ( f \"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. { err =} , { type ( err ) =} \" ) return df_eval , df_preds def get_river_df_eval_preds ( self , model ): try : df_eval , df_preds = self . evaluate_model ( model , self . fun_control ) except Exception as err : print ( f \"Error in get_river_df_eval_preds(). Call to evaluate_model failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval and df.preds to np.nan\" ) df_eval = np . nan df_preds = np . nan return df_eval , df_preds def fun_oml_horizon_old ( self , X , fun_control = None ): z_res = np . array ([], dtype = float ) self . fun_control . update ( fun_control ) self . check_weights () self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) for config in get_one_config_from_var_dict ( var_dict , self . fun_control ): if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) except Exception as err : df_eval = np . nan print ( f \"Error in fun(). Call to evaluate failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval to np.nan.\" ) try : y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res = np . append ( z_res , y / self . fun_control [ \"n_samples\" ]) return z_res def fun_oml_horizon ( self , X , fun_control = None ): \"\"\" This function calculates the horizon for a given set of data X and control parameters. :param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values \"\"\" self . fun_control . update ( fun_control ) self . check_weights () self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = [] for config in get_one_config_from_var_dict ( var_dict , self . fun_control ): if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res ) compute_y ( df_eval ) \u00b6 Compute the objective function value. Parameters: Name Type Description Default df_eval pd . DataFrame DataFrame with the evaluation results. required Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd . DataFrame ( [[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]], columns = [ 'Metric' , 'CompTime (s)' , 'Memory (MB)' ]) >>> weights = [ 1 , 1 , 1 ] >>> compute_y ( df_eval , weights ) 4.0 Source code in spotRiver/fun/hyperriver_old.py 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y fun_hw ( X , fun_control = None ) \u00b6 Hyperparameter Tuning of the HoltWinters model. Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method. Certain parameterizations result in special cases, such as simple exponential smoothing. Parameters: Name Type Description Default X array five hyperparameters. The parameters of the hyperparameter vector are: alpha : Smoothing parameter for the level. beta : Smoothing parameter for the trend. gamma : Smoothing parameter for the seasonality. seasonality : The number of periods in a season. For instance, this should be 4 for quarterly data, and 12 for yearly data. multiplicative : Whether or not to use a multiplicative formulation. required fun_control dict Parameters that are are not tuned: horizon : (int) grace_period : (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the horizon by default. data : dataset. Default AirlinePassengers . None Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def fun_hw ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the HoltWinters model. Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method. Certain parameterizations result in special cases, such as simple exponential smoothing. Args: X (array): five hyperparameters. The parameters of the hyperparameter vector are: 1. `alpha`: Smoothing parameter for the level. 2. `beta`: Smoothing parameter for the trend. 3. `gamma`: Smoothing parameter for the seasonality. 4. `seasonality`: The number of periods in a season. For instance, this should be 4 for quarterly data, and 12 for yearly data. 5. `multiplicative`: Whether or not to use a multiplicative formulation. fun_control (dict): Parameters that are are not tuned: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 2. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception alpha = X [:, 0 ] beta = X [:, 1 ] gamma = X [:, 2 ] seasonality = X [:, 3 ] multiplicative = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): model = time_series . HoltWinters ( alpha = alpha [ i ], beta = beta [ i ], gamma = gamma [ i ], seasonality = int ( seasonality [ i ]), multiplicative = int ( multiplicative [ i ]), ) res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], grace_period = self . fun_control [ \"grace_period\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res fun_nowcasting ( X , fun_control = None ) \u00b6 Hyperparameter Tuning of the nowcasting model. Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def fun_nowcasting ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the nowcasting model. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception lr = X [:, 0 ] intercept_lr = X [:, 1 ] hour = X [:, 2 ] weekday = X [:, 3 ] month = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( ( \"features\" , extract_features ), ( \"scale\" , preprocessing . StandardScaler ()), ( \"lin_reg\" , linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]) ), ), ) # eval: dates , metric , y_trues , y_preds = eval_nowcast_model ( model , dataset = self . fun_control [ \"data\" ], time_interval = \"Time\" ) z = metric . get () z_res = np . append ( z_res , z ) return z_res fun_oml_horizon ( X , fun_control = None ) \u00b6 This function calculates the horizon for a given set of data X and control parameters. :param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values Source code in spotRiver/fun/hyperriver_old.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 def fun_oml_horizon ( self , X , fun_control = None ): \"\"\" This function calculates the horizon for a given set of data X and control parameters. :param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values \"\"\" self . fun_control . update ( fun_control ) self . check_weights () self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = [] for config in get_one_config_from_var_dict ( var_dict , self . fun_control ): if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res ) fun_oml_iter_progressive ( X , fun_control = None ) \u00b6 Hyperparameter Tuning of an arbitrary model. Returns (float): objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 def fun_oml_iter_progressive ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of an arbitrary model. Returns ------- (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = np . array ([], dtype = float ) dataset_list = self . fun_control [ \"data\" ] for values in iterate_dict_values ( var_dict ): values = convert_keys ( values , self . fun_control [ \"var_type\" ]) print ( values ) values = get_dict_with_levels_and_types ( fun_control = self . fun_control , v = values ) values = transform_hyper_parameter_values ( fun_control = self . fun_control , hyper_parameter_values = values ) print ( values ) model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** values )) try : res = eval_oml_iter_progressive ( dataset = dataset_list , step = self . fun_control [ \"step\" ], log_level = self . fun_control [ \"log_level\" ], metric = fun_control [ \"metric\" ], weight_coeff = fun_control [ \"weight_coeff\" ], models = { self . fun_control [ \"model_name\" ]: ( model ), }, ) logger . debug ( \"res from eval_oml_iter_progressive: %s \" , res ) y = fun_eval_oml_iter_progressive ( res , metric = None , weights = self . fun_control [ \"weights\" ]) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting y to { y : .2f } .\" ) z_res = np . append ( z_res , y / self . fun_control [ \"n_samples\" ]) return z_res fun_snarimax ( X , fun_control = None ) \u00b6 Hyperparameter Tuning of the SNARIMAX model. SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include features that will be available both at training and prediction time. Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model. This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time. Parameters of the hyperparameter vector p : Order of the autoregressive part. This is the number of past target values that will be included as features. d : Differencing order. q : Order of the moving average part. This is the number of past error terms that will be included as features. m : Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to 12 . Note that for this parameter to have any impact you should also set at least one of the p , d , and q parameters. sp : Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. sd : Seasonal differencing order. sq : Seasonal order of the moving average part. This is the number of past error terms that will be included as features. lr (float): learn rate of the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. intercept_lr (float): intercept of the the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. hour (bool): If True , an hourly component is added. weekdy (bool): If True , an weekday component is added. month (bool): If True , an monthly component is added. Parameters: Name Type Description Default X array Seven hyperparameters to be optimized. Here: p (int): Order of the autoregressive part. This is the number of past target values that will be included as features. d (int): Differencing order. q (int): Order of the moving average part. This is the number of past error terms that will be included as features. m (int): Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to 12 . Note that for this parameter to have any impact you should also set at least one of the p , d , and q parameters. sp (int): Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. sd (int): Seasonal differencing order. sq (int): Seasonal order of the moving average part. This is the number of past error terms that will be included as features. lr (float): learn rate of the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. intercept_lr (float): intercept of the the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. hour (bool): If True , an hourly component is added. weekday (bool): If True , an weekday component is added. month (bool): If True , an monthly component is added. required fun_control dict parameter that are not optimized, e.g., horizon . Commonly referred to as \u201cdesign of experiments\u201d parameters: horizon : (int) grace_period : (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the horizon by default. data : dataset. Default AirlinePassengers . None Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 def fun_snarimax ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the SNARIMAX model. SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include features that will be available both at training and prediction time. Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model. This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time. Parameters of the hyperparameter vector: `p`: Order of the autoregressive part. This is the number of past target values that will be included as features. `d`: Differencing order. `q`: Order of the moving average part. This is the number of past error terms that will be included as features. `m`: Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp`: Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd`: Seasonal differencing order. `sq`: Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekdy` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. Args: X (array): Seven hyperparameters to be optimized. Here: `p` (int): Order of the autoregressive part. This is the number of past target values that will be included as features. `d` (int): Differencing order. `q` (int): Order of the moving average part. This is the number of past error terms that will be included as features. `m` (int): Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp` (int): Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd` (int): Seasonal differencing order. `sq`(int): Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekday` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. fun_control (dict): parameter that are not optimized, e.g., `horizon`. Commonly referred to as \"design of experiments\" parameters: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 3. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 12 : raise Exception p = X [:, 0 ] d = X [:, 1 ] q = X [:, 2 ] m = X [:, 3 ] sp = X [:, 4 ] sd = X [:, 5 ] sq = X [:, 6 ] lr = X [:, 7 ] intercept_lr = X [:, 8 ] hour = X [:, 9 ] weekday = X [:, 10 ] month = X [:, 11 ] # TODO: # horizon = fun_control[\"horizon\"] # future = [ # {\"month\": dt.date(year=1961, month=m, day=1)} for m in range(1, horizon + 1) # ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( extract_features , time_series . SNARIMAX ( p = int ( p [ i ]), d = int ( d [ i ]), q = int ( q [ i ]), m = int ( m [ i ]), sp = int ( sp [ i ]), sd = int ( sd [ i ]), sq = int ( sq [ i ]), regressor = compose . Pipeline ( preprocessing . StandardScaler (), linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]), ), ), ), ) # eval: res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res","title":"hyperriver_old"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver","text":"Hyperparameter Tuning for River. Parameters: Name Type Description Default seed int seed. See Numpy Random Sampling 126 Source code in spotRiver/fun/hyperriver_old.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 class HyperRiver : \"\"\" Hyperparameter Tuning for River. Args: seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) \"\"\" def __init__ ( self , seed = 126 , log_level = 50 ): self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"seed\" : None , \"data\" : None , \"step\" : 10_000 , \"horizon\" : None , \"grace_period\" : None , \"metric\" : metrics . MAE (), \"metric_sklearn\" : mean_absolute_error , \"weights\" : array ([ 1 , 0 , 0 ]), \"weight_coeff\" : 0.0 , \"log_level\" : log_level , \"var_name\" : [], \"var_type\" : [], \"prep_model\" : None , } self . log_level = self . fun_control [ \"log_level\" ] logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) # def get_month_distances(x): # return { # calendar.month_name[month]: math.exp(-(x['month'].month - month) ** 2) # for month in range(1, 13) # } # def get_ordinal_date(x): # return {'ordinal_date': x['month'].toordinal()} def fun_nowcasting ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the nowcasting model. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception lr = X [:, 0 ] intercept_lr = X [:, 1 ] hour = X [:, 2 ] weekday = X [:, 3 ] month = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( ( \"features\" , extract_features ), ( \"scale\" , preprocessing . StandardScaler ()), ( \"lin_reg\" , linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]) ), ), ) # eval: dates , metric , y_trues , y_preds = eval_nowcast_model ( model , dataset = self . fun_control [ \"data\" ], time_interval = \"Time\" ) z = metric . get () z_res = np . append ( z_res , z ) return z_res def fun_snarimax ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the SNARIMAX model. SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include features that will be available both at training and prediction time. Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model. This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time. Parameters of the hyperparameter vector: `p`: Order of the autoregressive part. This is the number of past target values that will be included as features. `d`: Differencing order. `q`: Order of the moving average part. This is the number of past error terms that will be included as features. `m`: Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp`: Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd`: Seasonal differencing order. `sq`: Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekdy` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. Args: X (array): Seven hyperparameters to be optimized. Here: `p` (int): Order of the autoregressive part. This is the number of past target values that will be included as features. `d` (int): Differencing order. `q` (int): Order of the moving average part. This is the number of past error terms that will be included as features. `m` (int): Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp` (int): Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd` (int): Seasonal differencing order. `sq`(int): Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekday` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. fun_control (dict): parameter that are not optimized, e.g., `horizon`. Commonly referred to as \"design of experiments\" parameters: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 3. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 12 : raise Exception p = X [:, 0 ] d = X [:, 1 ] q = X [:, 2 ] m = X [:, 3 ] sp = X [:, 4 ] sd = X [:, 5 ] sq = X [:, 6 ] lr = X [:, 7 ] intercept_lr = X [:, 8 ] hour = X [:, 9 ] weekday = X [:, 10 ] month = X [:, 11 ] # TODO: # horizon = fun_control[\"horizon\"] # future = [ # {\"month\": dt.date(year=1961, month=m, day=1)} for m in range(1, horizon + 1) # ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( extract_features , time_series . SNARIMAX ( p = int ( p [ i ]), d = int ( d [ i ]), q = int ( q [ i ]), m = int ( m [ i ]), sp = int ( sp [ i ]), sd = int ( sd [ i ]), sq = int ( sq [ i ]), regressor = compose . Pipeline ( preprocessing . StandardScaler (), linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]), ), ), ), ) # eval: res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res def fun_hw ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the HoltWinters model. Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method. Certain parameterizations result in special cases, such as simple exponential smoothing. Args: X (array): five hyperparameters. The parameters of the hyperparameter vector are: 1. `alpha`: Smoothing parameter for the level. 2. `beta`: Smoothing parameter for the trend. 3. `gamma`: Smoothing parameter for the seasonality. 4. `seasonality`: The number of periods in a season. For instance, this should be 4 for quarterly data, and 12 for yearly data. 5. `multiplicative`: Whether or not to use a multiplicative formulation. fun_control (dict): Parameters that are are not tuned: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 2. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception alpha = X [:, 0 ] beta = X [:, 1 ] gamma = X [:, 2 ] seasonality = X [:, 3 ] multiplicative = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): model = time_series . HoltWinters ( alpha = alpha [ i ], beta = beta [ i ], gamma = gamma [ i ], seasonality = int ( seasonality [ i ]), multiplicative = int ( multiplicative [ i ]), ) res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], grace_period = self . fun_control [ \"grace_period\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res # def fun_HTR_iter_progressive(self, X, fun_control=None): # \"\"\"Hyperparameter Tuning of HTR model. # See: https://riverml.xyz/0.15.0/api/tree/HoeffdingTreeRegressor/ # Parameters # ---------- # grace_period # Number of instances a leaf should observe between split attempts. # max_depth # The maximum depth a tree can reach. If `None`, the tree will grow indefinitely. # delta # Significance level to calculate the Hoeffding bound. The significance level is given by # `1 - delta`. Values closer to zero imply longer split decision delays. # tau # Threshold below which a split will be forced to break ties. # leaf_prediction # Prediction mechanism used at leafs. NOTE: order differs from the order in river!</br> # - 'mean' - Target mean</br> # - 'adaptive' - Chooses between 'mean' and 'model' dynamically</br> # - 'model' - Uses the model defined in `leaf_model`</br> # NOT IMPLEMENTED: leaf_model # The regression model used to provide responses if `leaf_prediction='model'`. If not # provided an instance of `river.linear_model.LinearRegression` with the default # hyperparameters is used. # model_selector_decay # The exponential decaying factor applied to the learning models' squared errors, that # are monitored if `leaf_prediction='adaptive'`. Must be between `0` and `1`. The closer # to `1`, the more importance is going to be given to past observations. On the other hand, # if its value approaches `0`, the recent observed errors are going to have more influence # on the final decision. # nominal_attributes # List of Nominal attributes identifiers. If empty, then assume that all numeric attributes # should be treated as continuous. # splitter # The Splitter or Attribute Observer (AO) used to monitor the class statistics of numeric # features and perform splits. Splitters are available in the `tree.splitter` module. # Different splitters are available for classification and regression tasks. Classification # and regression splitters can be distinguished by their property `is_target_class`. # This is an advanced option. Special care must be taken when choosing different splitters. # By default, `tree.splitter.TEBSTSplitter` is used if `splitter` is `None`. # min_samples_split # The minimum number of samples every branch resulting from a split candidate must have # to be considered valid. # binary_split # If True, only allow binary splits. # max_size # The max size of the tree, in Megabytes (MB). # memory_estimate_period # Interval (number of processed instances) between memory consumption checks. # stop_mem_management # If True, stop growing as soon as memory limit is hit. # remove_poor_attrs # If True, disable poor attributes to reduce memory usage. # merit_preprune # If True, enable merit-based tree pre-pruning. # fun_control # Parameters that are are not tuned: # 1. `horizon`: (int) # 2. `grace_period`: (int) Initial period during which the metric is not updated. # This is to fairly evaluate models which need a warming up period to start # producing meaningful forecasts. # The value of this parameter is equal to the `horizon` by default. # 3. `data`: dataset. Default `AirlinePassengers`. # Returns # ------- # (float): objective function value. Mean of the MAEs of the predicted values. # \"\"\" # self.fun_control.update(fun_control) # try: # X.shape[1] # except ValueError: # X = np.array([X]) # if X.shape[1] != 11: # raise Exception # grace_period = X[:, 0] # max_depth = X[:, 1] # delta = X[:, 2] # tau = X[:, 3] # leaf_prediction = X[:, 4] # leaf_model = X[:, 5] # model_selector_decay = X[:, 6] # splitter = X[:, 7] # min_samples_split = X[:, 8] # binary_split = X[:, 9] # max_size = X[:, 10] # z_res = np.array([], dtype=float) # dataset_list = self.fun_control[\"data\"] # for i in range(X.shape[0]): # num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler() # cat = compose.SelectType(str) | preprocessing.FeatureHasher(n_features=1000, seed=1) # try: # res = eval_oml_iter_progressive( # dataset=dataset_list, # step=self.fun_control[\"step\"], # log_level=self.fun_control[\"log_level\"], # metric=fun_control[\"metric\"], # weight_coeff=fun_control[\"weight_coeff\"], # models={ # \"HTR\": ( # (num + cat) # | tree.HoeffdingTreeRegressor( # grace_period=int(grace_period[i]), # max_depth=transform_power_10(int(max_depth[i])), # delta=float(delta[i]), # tau=float(tau[i]), # leaf_prediction=select_leaf_prediction(int(leaf_prediction[i])), # leaf_model=select_leaf_model(int(leaf_model[i])), # model_selector_decay=float(model_selector_decay[i]), # splitter=select_splitter(int(splitter[i])), # min_samples_split=int(min_samples_split[i]), # binary_split=int(binary_split[i]), # max_size=float(max_size[i]), # ) # ), # }, # ) # logger.debug(\"res from eval_oml_iter_progressive: %s\", res) # y = fun_eval_oml_iter_progressive(res, metric=None, weights=self.fun_control[\"weights\"]) # except Exception as err: # y = np.nan # print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\") # print(f\"Setting y to {y:.2f}.\") # z_res = np.append(z_res, y / self.fun_control[\"n_samples\"]) # return z_res def fun_oml_iter_progressive ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of an arbitrary model. Returns ------- (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = np . array ([], dtype = float ) dataset_list = self . fun_control [ \"data\" ] for values in iterate_dict_values ( var_dict ): values = convert_keys ( values , self . fun_control [ \"var_type\" ]) print ( values ) values = get_dict_with_levels_and_types ( fun_control = self . fun_control , v = values ) values = transform_hyper_parameter_values ( fun_control = self . fun_control , hyper_parameter_values = values ) print ( values ) model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** values )) try : res = eval_oml_iter_progressive ( dataset = dataset_list , step = self . fun_control [ \"step\" ], log_level = self . fun_control [ \"log_level\" ], metric = fun_control [ \"metric\" ], weight_coeff = fun_control [ \"weight_coeff\" ], models = { self . fun_control [ \"model_name\" ]: ( model ), }, ) logger . debug ( \"res from eval_oml_iter_progressive: %s \" , res ) y = fun_eval_oml_iter_progressive ( res , metric = None , weights = self . fun_control [ \"weights\" ]) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting y to { y : .2f } .\" ) z_res = np . append ( z_res , y / self . fun_control [ \"n_samples\" ]) return z_res def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y # def fun_oml_horizon_old(self, X, fun_control=None, return_model=False, return_df=False): # \"\"\"Hyperparameter Tuning of an arbitrary model. # Returns # ------- # (float): objective function value. Mean of the MAEs of the predicted values. # \"\"\" # self.fun_control.update(fun_control) # weights = self.fun_control[\"weights\"] # if len(weights) != 3: # raise ValueError(\"The weights array must be of length 3.\") # try: # X.shape[1] # except ValueError: # X = np.array([X]) # if X.shape[1] != len(self.fun_control[\"var_name\"]): # raise Exception # var_dict = assign_values(X, self.fun_control[\"var_name\"]) # z_res = np.array([], dtype=float) # for values in iterate_dict_values(var_dict): # values = convert_keys(values, self.fun_control[\"var_type\"]) # values = get_dict_with_levels_and_types(fun_control=self.fun_control, v=values) # values = transform_hyper_parameter_values(fun_control=self.fun_control, hyper_parameter_values=values) # model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**values)) # if return_model: # return model # try: # df_eval, df_preds = eval_oml_horizon( # model=model, # train=self.fun_control[\"train\"], # test=self.fun_control[\"test\"], # target_column=self.fun_control[\"target_column\"], # horizon=self.fun_control[\"horizon\"], # oml_grace_period=self.fun_control[\"oml_grace_period\"], # metric=self.fun_control[\"metric_sklearn\"], # ) # except Exception as err: # print(f\"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. {err=}, {type(err)=}\") # if return_df: # return df_eval, df_preds # try: # y = self.compute_y(df_eval, weights) # except Exception as err: # y = np.nan # print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\") # print(f\"Setting y to {y:.2f}.\") # z_res = np.append(z_res, y / self.fun_control[\"n_samples\"]) # return z_res def check_weights ( self ): if len ( self . fun_control [ \"weights\" ]) != 3 : raise ValueError ( \"The weights array must be of length 3.\" ) def check_X_shape ( self , X ): try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception def evaluate_model ( self , model , fun_control ): try : df_eval , df_preds = eval_oml_horizon ( model = model , train = fun_control [ \"train\" ], test = fun_control [ \"test\" ], target_column = fun_control [ \"target_column\" ], horizon = fun_control [ \"horizon\" ], oml_grace_period = fun_control [ \"oml_grace_period\" ], metric = fun_control [ \"metric_sklearn\" ], ) except Exception as err : print ( f \"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. { err =} , { type ( err ) =} \" ) return df_eval , df_preds def get_river_df_eval_preds ( self , model ): try : df_eval , df_preds = self . evaluate_model ( model , self . fun_control ) except Exception as err : print ( f \"Error in get_river_df_eval_preds(). Call to evaluate_model failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval and df.preds to np.nan\" ) df_eval = np . nan df_preds = np . nan return df_eval , df_preds def fun_oml_horizon_old ( self , X , fun_control = None ): z_res = np . array ([], dtype = float ) self . fun_control . update ( fun_control ) self . check_weights () self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) for config in get_one_config_from_var_dict ( var_dict , self . fun_control ): if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) except Exception as err : df_eval = np . nan print ( f \"Error in fun(). Call to evaluate failed. { err =} , { type ( err ) =} \" ) print ( \"Setting df_eval to np.nan.\" ) try : y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res = np . append ( z_res , y / self . fun_control [ \"n_samples\" ]) return z_res def fun_oml_horizon ( self , X , fun_control = None ): \"\"\" This function calculates the horizon for a given set of data X and control parameters. :param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values \"\"\" self . fun_control . update ( fun_control ) self . check_weights () self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = [] for config in get_one_config_from_var_dict ( var_dict , self . fun_control ): if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res )","title":"HyperRiver"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.compute_y","text":"Compute the objective function value. Parameters: Name Type Description Default df_eval pd . DataFrame DataFrame with the evaluation results. required Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd . DataFrame ( [[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]], columns = [ 'Metric' , 'CompTime (s)' , 'Memory (MB)' ]) >>> weights = [ 1 , 1 , 1 ] >>> compute_y ( df_eval , weights ) 4.0 Source code in spotRiver/fun/hyperriver_old.py 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def compute_y ( self , df_eval ): \"\"\"Compute the objective function value. Args: df_eval (pd.DataFrame): DataFrame with the evaluation results. Returns: (float): objective function value. Mean of the MAEs of the predicted values. Examples: >>> df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)']) >>> weights = [1, 1, 1] >>> compute_y(df_eval, weights) 4.0 \"\"\" # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values df_eval = df_eval . dropna () y_error = df_eval [ \"Metric\" ] . mean () logger . debug ( \"y_error from eval_oml_horizon: %s \" , y_error ) y_r_time = df_eval [ \"CompTime (s)\" ] . mean () logger . debug ( \"y_r_time from eval_oml_horizon: %s \" , y_r_time ) y_memory = df_eval [ \"Memory (MB)\" ] . mean () logger . debug ( \"y_memory from eval_oml_horizon: %s \" , y_memory ) weights = self . fun_control [ \"weights\" ] logger . debug ( \"weights from eval_oml_horizon: %s \" , weights ) y = weights [ 0 ] * y_error + weights [ 1 ] * y_r_time + weights [ 2 ] * y_memory logger . debug ( \"weighted res from eval_oml_horizon: %s \" , y ) return y","title":"compute_y()"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_hw","text":"Hyperparameter Tuning of the HoltWinters model. Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method. Certain parameterizations result in special cases, such as simple exponential smoothing. Parameters: Name Type Description Default X array five hyperparameters. The parameters of the hyperparameter vector are: alpha : Smoothing parameter for the level. beta : Smoothing parameter for the trend. gamma : Smoothing parameter for the seasonality. seasonality : The number of periods in a season. For instance, this should be 4 for quarterly data, and 12 for yearly data. multiplicative : Whether or not to use a multiplicative formulation. required fun_control dict Parameters that are are not tuned: horizon : (int) grace_period : (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the horizon by default. data : dataset. Default AirlinePassengers . None Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def fun_hw ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the HoltWinters model. Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method. Certain parameterizations result in special cases, such as simple exponential smoothing. Args: X (array): five hyperparameters. The parameters of the hyperparameter vector are: 1. `alpha`: Smoothing parameter for the level. 2. `beta`: Smoothing parameter for the trend. 3. `gamma`: Smoothing parameter for the seasonality. 4. `seasonality`: The number of periods in a season. For instance, this should be 4 for quarterly data, and 12 for yearly data. 5. `multiplicative`: Whether or not to use a multiplicative formulation. fun_control (dict): Parameters that are are not tuned: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 2. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception alpha = X [:, 0 ] beta = X [:, 1 ] gamma = X [:, 2 ] seasonality = X [:, 3 ] multiplicative = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): model = time_series . HoltWinters ( alpha = alpha [ i ], beta = beta [ i ], gamma = gamma [ i ], seasonality = int ( seasonality [ i ]), multiplicative = int ( multiplicative [ i ]), ) res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], grace_period = self . fun_control [ \"grace_period\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res","title":"fun_hw()"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_nowcasting","text":"Hyperparameter Tuning of the nowcasting model. Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def fun_nowcasting ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the nowcasting model. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 5 : raise Exception lr = X [:, 0 ] intercept_lr = X [:, 1 ] hour = X [:, 2 ] weekday = X [:, 3 ] month = X [:, 4 ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( ( \"features\" , extract_features ), ( \"scale\" , preprocessing . StandardScaler ()), ( \"lin_reg\" , linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]) ), ), ) # eval: dates , metric , y_trues , y_preds = eval_nowcast_model ( model , dataset = self . fun_control [ \"data\" ], time_interval = \"Time\" ) z = metric . get () z_res = np . append ( z_res , z ) return z_res","title":"fun_nowcasting()"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_oml_horizon","text":"This function calculates the horizon for a given set of data X and control parameters. :param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values Source code in spotRiver/fun/hyperriver_old.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 def fun_oml_horizon ( self , X , fun_control = None ): \"\"\" This function calculates the horizon for a given set of data X and control parameters. :param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values \"\"\" self . fun_control . update ( fun_control ) self . check_weights () self . check_X_shape ( X ) var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = [] for config in get_one_config_from_var_dict ( var_dict , self . fun_control ): if self . fun_control [ \"prep_model\" ] is not None : model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** config )) else : model = self . fun_control [ \"core_model\" ]( ** config ) try : df_eval , _ = self . evaluate_model ( model , self . fun_control ) y = self . compute_y ( df_eval ) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate or compute_y failed. { err =} , { type ( err ) =} \" ) print ( \"Setting y to np.nan.\" ) z_res . append ( y / self . fun_control [ \"n_samples\" ]) return np . array ( z_res )","title":"fun_oml_horizon()"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_oml_iter_progressive","text":"Hyperparameter Tuning of an arbitrary model. Returns (float): objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 def fun_oml_iter_progressive ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of an arbitrary model. Returns ------- (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != len ( self . fun_control [ \"var_name\" ]): raise Exception var_dict = assign_values ( X , self . fun_control [ \"var_name\" ]) z_res = np . array ([], dtype = float ) dataset_list = self . fun_control [ \"data\" ] for values in iterate_dict_values ( var_dict ): values = convert_keys ( values , self . fun_control [ \"var_type\" ]) print ( values ) values = get_dict_with_levels_and_types ( fun_control = self . fun_control , v = values ) values = transform_hyper_parameter_values ( fun_control = self . fun_control , hyper_parameter_values = values ) print ( values ) model = compose . Pipeline ( self . fun_control [ \"prep_model\" ], self . fun_control [ \"core_model\" ]( ** values )) try : res = eval_oml_iter_progressive ( dataset = dataset_list , step = self . fun_control [ \"step\" ], log_level = self . fun_control [ \"log_level\" ], metric = fun_control [ \"metric\" ], weight_coeff = fun_control [ \"weight_coeff\" ], models = { self . fun_control [ \"model_name\" ]: ( model ), }, ) logger . debug ( \"res from eval_oml_iter_progressive: %s \" , res ) y = fun_eval_oml_iter_progressive ( res , metric = None , weights = self . fun_control [ \"weights\" ]) except Exception as err : y = np . nan print ( f \"Error in fun(). Call to evaluate failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting y to { y : .2f } .\" ) z_res = np . append ( z_res , y / self . fun_control [ \"n_samples\" ]) return z_res","title":"fun_oml_iter_progressive()"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_snarimax","text":"Hyperparameter Tuning of the SNARIMAX model. SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include features that will be available both at training and prediction time. Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model. This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time. Parameters of the hyperparameter vector p : Order of the autoregressive part. This is the number of past target values that will be included as features. d : Differencing order. q : Order of the moving average part. This is the number of past error terms that will be included as features. m : Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to 12 . Note that for this parameter to have any impact you should also set at least one of the p , d , and q parameters. sp : Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. sd : Seasonal differencing order. sq : Seasonal order of the moving average part. This is the number of past error terms that will be included as features. lr (float): learn rate of the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. intercept_lr (float): intercept of the the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. hour (bool): If True , an hourly component is added. weekdy (bool): If True , an weekday component is added. month (bool): If True , an monthly component is added. Parameters: Name Type Description Default X array Seven hyperparameters to be optimized. Here: p (int): Order of the autoregressive part. This is the number of past target values that will be included as features. d (int): Differencing order. q (int): Order of the moving average part. This is the number of past error terms that will be included as features. m (int): Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to 12 . Note that for this parameter to have any impact you should also set at least one of the p , d , and q parameters. sp (int): Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. sd (int): Seasonal differencing order. sq (int): Seasonal order of the moving average part. This is the number of past error terms that will be included as features. lr (float): learn rate of the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. intercept_lr (float): intercept of the the linear regression model. A river preprocessing.StandardScaler piped with a river linear_model.LinearRegression will be used. hour (bool): If True , an hourly component is added. weekday (bool): If True , an weekday component is added. month (bool): If True , an monthly component is added. required fun_control dict parameter that are not optimized, e.g., horizon . Commonly referred to as \u201cdesign of experiments\u201d parameters: horizon : (int) grace_period : (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the horizon by default. data : dataset. Default AirlinePassengers . None Returns: Type Description float objective function value. Mean of the MAEs of the predicted values. Source code in spotRiver/fun/hyperriver_old.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 def fun_snarimax ( self , X , fun_control = None ): \"\"\"Hyperparameter Tuning of the SNARIMAX model. SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include features that will be available both at training and prediction time. Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model. This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time. Parameters of the hyperparameter vector: `p`: Order of the autoregressive part. This is the number of past target values that will be included as features. `d`: Differencing order. `q`: Order of the moving average part. This is the number of past error terms that will be included as features. `m`: Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp`: Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd`: Seasonal differencing order. `sq`: Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekdy` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. Args: X (array): Seven hyperparameters to be optimized. Here: `p` (int): Order of the autoregressive part. This is the number of past target values that will be included as features. `d` (int): Differencing order. `q` (int): Order of the moving average part. This is the number of past error terms that will be included as features. `m` (int): Season length used for extracting seasonal features. If you believe your data has a seasonal pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality, and that your data is spaced by month, then you should set this to `12`. Note that for this parameter to have any impact you should also set at least one of the `p`, `d`, and `q` parameters. `sp` (int): Seasonal order of the autoregressive part. This is the number of past target values that will be included as features. `sd` (int): Seasonal differencing order. `sq`(int): Seasonal order of the moving average part. This is the number of past error terms that will be included as features. `lr` (float): learn rate of the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression` will be used. `hour` (bool): If `True`, an hourly component is added. `weekday` (bool): If `True`, an weekday component is added. `month` (bool): If `True`, an monthly component is added. fun_control (dict): parameter that are not optimized, e.g., `horizon`. Commonly referred to as \"design of experiments\" parameters: 1. `horizon`: (int) 2. `grace_period`: (int) Initial period during which the metric is not updated. This is to fairly evaluate models which need a warming up period to start producing meaningful forecasts. The value of this parameter is equal to the `horizon` by default. 3. `data`: dataset. Default `AirlinePassengers`. Returns: (float): objective function value. Mean of the MAEs of the predicted values. \"\"\" self . fun_control . update ( fun_control ) try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 12 : raise Exception p = X [:, 0 ] d = X [:, 1 ] q = X [:, 2 ] m = X [:, 3 ] sp = X [:, 4 ] sd = X [:, 5 ] sq = X [:, 6 ] lr = X [:, 7 ] intercept_lr = X [:, 8 ] hour = X [:, 9 ] weekday = X [:, 10 ] month = X [:, 11 ] # TODO: # horizon = fun_control[\"horizon\"] # future = [ # {\"month\": dt.date(year=1961, month=m, day=1)} for m in range(1, horizon + 1) # ] z_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): h_i = int ( hour [ i ]) w_i = int ( weekday [ i ]) m_i = int ( month [ i ]) # baseline: extract_features = compose . TransformerUnion ( get_ordinal_date ) if h_i : extract_features = compose . TransformerUnion ( get_ordinal_date , get_hour_distances ) if w_i : extract_features = compose . TransformerUnion ( extract_features , get_weekday_distances ) if m_i : extract_features = compose . TransformerUnion ( extract_features , get_month_distances ) model = compose . Pipeline ( extract_features , time_series . SNARIMAX ( p = int ( p [ i ]), d = int ( d [ i ]), q = int ( q [ i ]), m = int ( m [ i ]), sp = int ( sp [ i ]), sd = int ( sd [ i ]), sq = int ( sq [ i ]), regressor = compose . Pipeline ( preprocessing . StandardScaler (), linear_model . LinearRegression ( intercept_init = 0 , optimizer = optim . SGD ( float ( lr [ i ])), intercept_lr = float ( intercept_lr [ i ]), ), ), ), ) # eval: res = time_series . evaluate ( self . fun_control [ \"data\" ], model , metric = self . fun_control [ \"metric\" ], horizon = self . fun_control [ \"horizon\" ], agg_func = statistics . mean , ) z = res . get () z_res = np . append ( z_res , z ) return z_res","title":"fun_snarimax()"},{"location":"reference/spotRiver/plot/stats/","text":"corrplot ( df , numeric_only = True ) \u00b6 Function plots a graphical correlation matrix for each pair of columns in the dataframe. The function takes a DataFrame df as input and generates a graphical correlation matrix for each pair of columns in the dataframe. The upper triangle of the correlation matrix is masked out and set to NaN values. The resulting matrix is then styled and returned as a heatmap with colors ranging from blue (for negative correlations) to red (for positive correlations). Parameters: Name Type Description Default df pd . DataFrame Data to plot. required numeric_only bool, default True Include only float, int or boolean data. True Returns: Type Description pd . DataFrame A styled correlation matrix heatmap. Examples: >>> from spotRiver.plot.stats import corrplot import pandas as pd X = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}) corrplot(X) Source code in spotRiver/plot/stats.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def corrplot ( df : pd . DataFrame , numeric_only = True ) -> None : \"\"\"Function plots a graphical correlation matrix for each pair of columns in the dataframe. The function takes a DataFrame df as input and generates a graphical correlation matrix for each pair of columns in the dataframe. The upper triangle of the correlation matrix is masked out and set to NaN values. The resulting matrix is then styled and returned as a heatmap with colors ranging from blue (for negative correlations) to red (for positive correlations). Args: df (pd.DataFrame): Data to plot. numeric_only (bool, default True): Include only float, int or boolean data. Returns: (pd.DataFrame): A styled correlation matrix heatmap. Examples: >>> from spotRiver.plot.stats import corrplot import pandas as pd X = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}) corrplot(X) \"\"\" # Compute the correlation matrix corr = df . corr ( numeric_only = numeric_only ) # Generate a mask for the upper triangle mask = np . zeros_like ( corr , dtype = bool ) mask [ np . triu_indices_from ( mask )] = True # Set values in the upper triangle to NaN corr [ mask ] = np . nan # Apply styling to the correlation matrix and return it as a heatmap return corr . style . background_gradient ( cmap = \"coolwarm\" , axis = None , vmin =- 1 , vmax = 1 ) . highlight_null ( color = \"#f1f1f1\" )","title":"stats"},{"location":"reference/spotRiver/plot/stats/#spotRiver.plot.stats.corrplot","text":"Function plots a graphical correlation matrix for each pair of columns in the dataframe. The function takes a DataFrame df as input and generates a graphical correlation matrix for each pair of columns in the dataframe. The upper triangle of the correlation matrix is masked out and set to NaN values. The resulting matrix is then styled and returned as a heatmap with colors ranging from blue (for negative correlations) to red (for positive correlations). Parameters: Name Type Description Default df pd . DataFrame Data to plot. required numeric_only bool, default True Include only float, int or boolean data. True Returns: Type Description pd . DataFrame A styled correlation matrix heatmap. Examples: >>> from spotRiver.plot.stats import corrplot import pandas as pd X = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}) corrplot(X) Source code in spotRiver/plot/stats.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def corrplot ( df : pd . DataFrame , numeric_only = True ) -> None : \"\"\"Function plots a graphical correlation matrix for each pair of columns in the dataframe. The function takes a DataFrame df as input and generates a graphical correlation matrix for each pair of columns in the dataframe. The upper triangle of the correlation matrix is masked out and set to NaN values. The resulting matrix is then styled and returned as a heatmap with colors ranging from blue (for negative correlations) to red (for positive correlations). Args: df (pd.DataFrame): Data to plot. numeric_only (bool, default True): Include only float, int or boolean data. Returns: (pd.DataFrame): A styled correlation matrix heatmap. Examples: >>> from spotRiver.plot.stats import corrplot import pandas as pd X = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}) corrplot(X) \"\"\" # Compute the correlation matrix corr = df . corr ( numeric_only = numeric_only ) # Generate a mask for the upper triangle mask = np . zeros_like ( corr , dtype = bool ) mask [ np . triu_indices_from ( mask )] = True # Set values in the upper triangle to NaN corr [ mask ] = np . nan # Apply styling to the correlation matrix and return it as a heatmap return corr . style . background_gradient ( cmap = \"coolwarm\" , axis = None , vmin =- 1 , vmax = 1 ) . highlight_null ( color = \"#f1f1f1\" )","title":"corrplot()"},{"location":"reference/spotRiver/preprocess/impute/","text":"impute_opm ( include_categorical = False , data_home = 'data' , strategy = 'most_frequent' , columns = [ 'lat' , 'lon' ], archive_name = 'opm_cat.csv' , path_or_buf = 'opm_cat.zip' , write_csv = True , return_df = False ) \u00b6 Impute missing values in OPM dataset. Parameters: Name Type Description Default include_categorical bool Whether to include categorical features. Default is False. False data_home str The directory to use as a data store. Default is \u201cdata\u201d. 'data' strategy str The imputation strategy to use. Can be one of \u201cmean\u201d, \u201cmedian\u201d, \u201cmost_frequent\u201d, or \u201cconstant\u201d. Default is \u201cmost_frequent\u201d. 'most_frequent' columns list [ str ] A list of column names to impute. If None, impute all columns. Default is [\u201clat\u201d, \u201clon\u201d]. ['lat', 'lon'] archive_name str The name of the archive file to write. Default is \u201copm_cat.csv\u201d. 'opm_cat.csv' path_or_buf str The file path or buffer to write. Default is \u201copm_cat.zip\u201d. 'opm_cat.zip' write_csv bool Whether to write the imputed data to a CSV file. Default is True. True return_df bool Whether to return the imputed data as a DataFrame. Default is False. False Returns: Type Description pd . DataFrame If return_df is True, returns a pandas DataFrame containing the imputed data. Source code in spotRiver/preprocess/impute.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def impute_opm ( include_categorical : bool = False , data_home : str = \"data\" , strategy : str = \"most_frequent\" , columns : list [ str ] = [ \"lat\" , \"lon\" ], archive_name : str = \"opm_cat.csv\" , path_or_buf : str = \"opm_cat.zip\" , write_csv : bool = True , return_df : bool = False , ) -> pd . DataFrame : \"\"\"Impute missing values in OPM dataset. Args: include_categorical: Whether to include categorical features. Default is False. data_home: The directory to use as a data store. Default is \"data\". strategy: The imputation strategy to use. Can be one of \"mean\", \"median\", \"most_frequent\", or \"constant\". Default is \"most_frequent\". columns: A list of column names to impute. If None, impute all columns. Default is [\"lat\", \"lon\"]. archive_name: The name of the archive file to write. Default is \"opm_cat.csv\". path_or_buf: The file path or buffer to write. Default is \"opm_cat.zip\". write_csv: Whether to write the imputed data to a CSV file. Default is True. return_df: Whether to return the imputed data as a DataFrame. Default is False. Returns: If `return_df` is True, returns a pandas DataFrame containing the imputed data. \"\"\" # Validate input parameters valid_strategies = [ \"mean\" , \"median\" , \"most_frequent\" , \"constant\" ] if strategy not in valid_strategies : raise ValueError ( f \"Invalid strategy: { strategy } . Must be one of { valid_strategies } .\" ) # Fetch and concatenate data X , y = fetch_opm ( include_categorical = include_categorical , data_home = data_home , return_X_y = True ) df = pd . concat ([ X , y ], axis = 1 ) # Impute missing values imp = SimpleImputer ( missing_values = np . nan , strategy = strategy ) if columns is None : # Impute all columns df [:] = imp . fit_transform ( df ) else : # Impute only specified columns for col in columns : if col not in df . columns : raise ValueError ( f \"Invalid column: { col } . Not in dataframe.\" ) df [ col ] = imp . fit_transform ( np . array ( df [ col ]) . reshape ( - 1 , 1 )) # Write csv file if requested if write_csv : compression_opts = dict ( method = \"zip\" , archive_name = archive_name ) df . to_csv ( path_or_buf , index = False , compression = compression_opts ) # Return dataframe if requested if return_df : return df","title":"impute"},{"location":"reference/spotRiver/preprocess/impute/#spotRiver.preprocess.impute.impute_opm","text":"Impute missing values in OPM dataset. Parameters: Name Type Description Default include_categorical bool Whether to include categorical features. Default is False. False data_home str The directory to use as a data store. Default is \u201cdata\u201d. 'data' strategy str The imputation strategy to use. Can be one of \u201cmean\u201d, \u201cmedian\u201d, \u201cmost_frequent\u201d, or \u201cconstant\u201d. Default is \u201cmost_frequent\u201d. 'most_frequent' columns list [ str ] A list of column names to impute. If None, impute all columns. Default is [\u201clat\u201d, \u201clon\u201d]. ['lat', 'lon'] archive_name str The name of the archive file to write. Default is \u201copm_cat.csv\u201d. 'opm_cat.csv' path_or_buf str The file path or buffer to write. Default is \u201copm_cat.zip\u201d. 'opm_cat.zip' write_csv bool Whether to write the imputed data to a CSV file. Default is True. True return_df bool Whether to return the imputed data as a DataFrame. Default is False. False Returns: Type Description pd . DataFrame If return_df is True, returns a pandas DataFrame containing the imputed data. Source code in spotRiver/preprocess/impute.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def impute_opm ( include_categorical : bool = False , data_home : str = \"data\" , strategy : str = \"most_frequent\" , columns : list [ str ] = [ \"lat\" , \"lon\" ], archive_name : str = \"opm_cat.csv\" , path_or_buf : str = \"opm_cat.zip\" , write_csv : bool = True , return_df : bool = False , ) -> pd . DataFrame : \"\"\"Impute missing values in OPM dataset. Args: include_categorical: Whether to include categorical features. Default is False. data_home: The directory to use as a data store. Default is \"data\". strategy: The imputation strategy to use. Can be one of \"mean\", \"median\", \"most_frequent\", or \"constant\". Default is \"most_frequent\". columns: A list of column names to impute. If None, impute all columns. Default is [\"lat\", \"lon\"]. archive_name: The name of the archive file to write. Default is \"opm_cat.csv\". path_or_buf: The file path or buffer to write. Default is \"opm_cat.zip\". write_csv: Whether to write the imputed data to a CSV file. Default is True. return_df: Whether to return the imputed data as a DataFrame. Default is False. Returns: If `return_df` is True, returns a pandas DataFrame containing the imputed data. \"\"\" # Validate input parameters valid_strategies = [ \"mean\" , \"median\" , \"most_frequent\" , \"constant\" ] if strategy not in valid_strategies : raise ValueError ( f \"Invalid strategy: { strategy } . Must be one of { valid_strategies } .\" ) # Fetch and concatenate data X , y = fetch_opm ( include_categorical = include_categorical , data_home = data_home , return_X_y = True ) df = pd . concat ([ X , y ], axis = 1 ) # Impute missing values imp = SimpleImputer ( missing_values = np . nan , strategy = strategy ) if columns is None : # Impute all columns df [:] = imp . fit_transform ( df ) else : # Impute only specified columns for col in columns : if col not in df . columns : raise ValueError ( f \"Invalid column: { col } . Not in dataframe.\" ) df [ col ] = imp . fit_transform ( np . array ( df [ col ]) . reshape ( - 1 , 1 )) # Write csv file if requested if write_csv : compression_opts = dict ( method = \"zip\" , archive_name = archive_name ) df . to_csv ( path_or_buf , index = False , compression = compression_opts ) # Return dataframe if requested if return_df : return df","title":"impute_opm()"},{"location":"reference/spotRiver/utils/data_conversion/","text":"compare_two_tree_models ( model1 , model2 , headers = [ 'Parameter' , 'Default' , 'Spot' ]) \u00b6 Compares two tree models and returns a table of the differences. Parameters: Name Type Description Default model1 Pipeline A river model pipeline. required model2 Pipeline A river model pipeline. required Returns: Type Description str A table of the differences between the two models. Source code in spotRiver/utils/data_conversion.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def compare_two_tree_models ( model1 , model2 , headers = [ \"Parameter\" , \"Default\" , \"Spot\" ]): \"\"\"Compares two tree models and returns a table of the differences. Args: model1 (Pipeline): A river model pipeline. model2 (Pipeline): A river model pipeline. Returns: (str): A table of the differences between the two models. \"\"\" keys = model1 [ 1 ] . summary . keys () values1 = model1 [ 1 ] . summary . values () values2 = model2 [ 1 ] . summary . values () tbl = [] for key , value1 , value2 in zip ( keys , values1 , values2 ): tbl . append ([ key , value1 , value2 ]) return tabulate ( tbl , headers = headers , numalign = \"right\" , tablefmt = \"github\" ) convert_to_df ( dataset , target_column , n_total = None ) \u00b6 Converts a river dataset into a pandas DataFrame. Parameters: Name Type Description Default dataset datasets . base . Dataset The river dataset to be converted. required target_column str The name of the target column in the resulting DataFrame. required Returns: Type Description pd . DataFrame A pandas DataFrame representation of the given dataset. Examples: >>> dataset = datasets . TrumpApproval () target_column = \"Approval\" df = convert_to_df(dataset, target_column) df.rename(columns={ 'date': 'ordinal_date', 'Gallup': 'gallup', 'Ipsos': 'ipsos', 'Morning Consult': 'morning_consult', 'Rasmussen': 'rasmussen', 'YouGov': 'you_gov'}, inplace=True) # Split the data into train and test sets train = df[:500] test = df[500:] Source code in spotRiver/utils/data_conversion.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def convert_to_df ( dataset : datasets . base . Dataset , target_column : str , n_total = None ) -> pd . DataFrame : \"\"\"Converts a river dataset into a pandas DataFrame. Args: dataset (datasets.base.Dataset): The river dataset to be converted. target_column (str): The name of the target column in the resulting DataFrame. Returns: (pd.DataFrame): A pandas DataFrame representation of the given dataset. Examples: >>> dataset = datasets.TrumpApproval() target_column = \"Approval\" df = convert_to_df(dataset, target_column) df.rename(columns={ 'date': 'ordinal_date', 'Gallup': 'gallup', 'Ipsos': 'ipsos', 'Morning Consult': 'morning_consult', 'Rasmussen': 'rasmussen', 'YouGov': 'you_gov'}, inplace=True) # Split the data into train and test sets train = df[:500] test = df[500:] \"\"\" data_dict = { key : [] for key in list ( dataset . take ( 1 ))[ 0 ][ 0 ] . keys ()} data_dict [ target_column ] = [] if n_total is None : for x in dataset : for key , value in x [ 0 ] . items (): data_dict [ key ] . append ( value ) data_dict [ target_column ] . append ( x [ 1 ]) else : for x in dataset . take ( n_total ): for key , value in x [ 0 ] . items (): data_dict [ key ] . append ( value ) data_dict [ target_column ] . append ( x [ 1 ]) df = pd . DataFrame ( data_dict ) return df","title":"data_conversion"},{"location":"reference/spotRiver/utils/data_conversion/#spotRiver.utils.data_conversion.compare_two_tree_models","text":"Compares two tree models and returns a table of the differences. Parameters: Name Type Description Default model1 Pipeline A river model pipeline. required model2 Pipeline A river model pipeline. required Returns: Type Description str A table of the differences between the two models. Source code in spotRiver/utils/data_conversion.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def compare_two_tree_models ( model1 , model2 , headers = [ \"Parameter\" , \"Default\" , \"Spot\" ]): \"\"\"Compares two tree models and returns a table of the differences. Args: model1 (Pipeline): A river model pipeline. model2 (Pipeline): A river model pipeline. Returns: (str): A table of the differences between the two models. \"\"\" keys = model1 [ 1 ] . summary . keys () values1 = model1 [ 1 ] . summary . values () values2 = model2 [ 1 ] . summary . values () tbl = [] for key , value1 , value2 in zip ( keys , values1 , values2 ): tbl . append ([ key , value1 , value2 ]) return tabulate ( tbl , headers = headers , numalign = \"right\" , tablefmt = \"github\" )","title":"compare_two_tree_models()"},{"location":"reference/spotRiver/utils/data_conversion/#spotRiver.utils.data_conversion.convert_to_df","text":"Converts a river dataset into a pandas DataFrame. Parameters: Name Type Description Default dataset datasets . base . Dataset The river dataset to be converted. required target_column str The name of the target column in the resulting DataFrame. required Returns: Type Description pd . DataFrame A pandas DataFrame representation of the given dataset. Examples: >>> dataset = datasets . TrumpApproval () target_column = \"Approval\" df = convert_to_df(dataset, target_column) df.rename(columns={ 'date': 'ordinal_date', 'Gallup': 'gallup', 'Ipsos': 'ipsos', 'Morning Consult': 'morning_consult', 'Rasmussen': 'rasmussen', 'YouGov': 'you_gov'}, inplace=True) # Split the data into train and test sets train = df[:500] test = df[500:] Source code in spotRiver/utils/data_conversion.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def convert_to_df ( dataset : datasets . base . Dataset , target_column : str , n_total = None ) -> pd . DataFrame : \"\"\"Converts a river dataset into a pandas DataFrame. Args: dataset (datasets.base.Dataset): The river dataset to be converted. target_column (str): The name of the target column in the resulting DataFrame. Returns: (pd.DataFrame): A pandas DataFrame representation of the given dataset. Examples: >>> dataset = datasets.TrumpApproval() target_column = \"Approval\" df = convert_to_df(dataset, target_column) df.rename(columns={ 'date': 'ordinal_date', 'Gallup': 'gallup', 'Ipsos': 'ipsos', 'Morning Consult': 'morning_consult', 'Rasmussen': 'rasmussen', 'YouGov': 'you_gov'}, inplace=True) # Split the data into train and test sets train = df[:500] test = df[500:] \"\"\" data_dict = { key : [] for key in list ( dataset . take ( 1 ))[ 0 ][ 0 ] . keys ()} data_dict [ target_column ] = [] if n_total is None : for x in dataset : for key , value in x [ 0 ] . items (): data_dict [ key ] . append ( value ) data_dict [ target_column ] . append ( x [ 1 ]) else : for x in dataset . take ( n_total ): for key , value in x [ 0 ] . items (): data_dict [ key ] . append ( value ) data_dict [ target_column ] . append ( x [ 1 ]) df = pd . DataFrame ( data_dict ) return df","title":"convert_to_df()"},{"location":"reference/spotRiver/utils/features/","text":"get_hour_distances ( x ) \u00b6 This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Examples: >>> from spotRiver.utils.features import get_hour_distances >>> from datetime import datetime >>> get_hour_distances ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'0': 0.6065306597126334, '1': 0.36787944117144233, '2': 0.1353352832366127, '3': 0.01831563888873418, '4': 0.00033546262790251185, '5': 3.354626279025118e-06, '6': 2.0611536224385582e-08, '7': 8.315287191035679e-11, '8': 2.0611536224385582e-13, '9': 3.354626279025118e-16, '10': 3.354626279025118e-19, '11': 2.0611536224385582e-22, '12': 8.315287191035679e-26, '13': 2.0611536224385582e-29, '14': 3.354626279025118e-33, '15': 3.354626279025118e-37, '16': 2.0611536224385582e-41, '17': 8.315287191035679e-46, '18': 2.0611536224385582e-50, '19': 3.354626279025118e-55, '20': 3.354626279025118e-60, '21': 2.0611536224385582e-65, '22': 8.315287191035679e-71, '23': 2.0611536224385582e-76} Source code in spotRiver/utils/features.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_hour_distances ( x ): \"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Examples: >>> from spotRiver.utils.features import get_hour_distances >>> from datetime import datetime >>> get_hour_distances({\"date\": datetime(2020, 1, 1)}) {'0': 0.6065306597126334, '1': 0.36787944117144233, '2': 0.1353352832366127, '3': 0.01831563888873418, '4': 0.00033546262790251185, '5': 3.354626279025118e-06, '6': 2.0611536224385582e-08, '7': 8.315287191035679e-11, '8': 2.0611536224385582e-13, '9': 3.354626279025118e-16, '10': 3.354626279025118e-19, '11': 2.0611536224385582e-22, '12': 8.315287191035679e-26, '13': 2.0611536224385582e-29, '14': 3.354626279025118e-33, '15': 3.354626279025118e-37, '16': 2.0611536224385582e-41, '17': 8.315287191035679e-46, '18': 2.0611536224385582e-50, '19': 3.354626279025118e-55, '20': 3.354626279025118e-60, '21': 2.0611536224385582e-65, '22': 8.315287191035679e-71, '23': 2.0611536224385582e-76} \"\"\" k = list ( x . keys ())[ 0 ] return { str ( hour ): math . exp ( - (( x [ k ] . hour - hour ) ** 2 )) for hour in range ( 0 , 24 )} get_month_distances ( x ) \u00b6 This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Examples: >>> from spotRiver.utils.features import get_month_distances >>> from datetime import datetime >>> get_month_distances ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'January': 0.6065306597126334, 'February': 0.36787944117144233, 'March': 0.1353352832366127, 'April': 0.01831563888873418, 'May': 0.00033546262790251185, 'June': 3.354626279025118e-06, 'July': 2.0611536224385582e-08, 'August': 8.315287191035679e-11, 'September': 2.0611536224385582e-13, 'October': 3.354626279025118e-16, 'November': 3.354626279025118e-19, 'December': 2.0611536224385582e-22} Source code in spotRiver/utils/features.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def get_month_distances ( x : Dict [ str , datetime ]) -> Dict [ str , float ]: \"\"\" This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Examples: >>> from spotRiver.utils.features import get_month_distances >>> from datetime import datetime >>> get_month_distances({\"date\": datetime(2020, 1, 1)}) {'January': 0.6065306597126334, 'February': 0.36787944117144233, 'March': 0.1353352832366127, 'April': 0.01831563888873418, 'May': 0.00033546262790251185, 'June': 3.354626279025118e-06, 'July': 2.0611536224385582e-08, 'August': 8.315287191035679e-11, 'September': 2.0611536224385582e-13, 'October': 3.354626279025118e-16, 'November': 3.354626279025118e-19, 'December': 2.0611536224385582e-22} \"\"\" k = list ( x . keys ())[ 0 ] return { calendar . month_name [ month ]: math . exp ( - (( x [ k ] . month - month ) ** 2 )) for month in range ( 1 , 13 )} get_ordinal_date ( x ) \u00b6 This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the string \u201cordinal_date\u201d and the value is the ordinal date of the input datetime object. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the string \u201cordinal_date\u201d and the value is the ordinal date of the input datetime object. Examples: >>> from datetime import datetime >>> from spotRiver.utils.features import get_ordinal_date >>> get_ordinal_date ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'ordinal_date': 737424} Source code in spotRiver/utils/features.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def get_ordinal_date ( x ): \"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the string \"ordinal_date\" and the value is the ordinal date of the input datetime object. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the string \"ordinal_date\" and the value is the ordinal date of the input datetime object. Examples: >>> from datetime import datetime >>> from spotRiver.utils.features import get_ordinal_date >>> get_ordinal_date({\"date\": datetime(2020, 1, 1)}) {'ordinal_date': 737424} \"\"\" k = list ( x . keys ())[ 0 ] return { \"ordinal_date\" : x [ k ] . toordinal ()} get_weekday_distances ( x ) \u00b6 This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Examples: >>> from spotRiver.utils.features import get_weekday_distances >>> from datetime import datetime >>> get_weekday_distances ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'Monday': 0.6065306597126334, 'Tuesday': 0.36787944117144233, 'Wednesday': 0.1353352832366127, 'Thursday': 0.01831563888873418, 'Friday': 0.00033546262790251185, 'Saturday': 3.354626279025118e-06, 'Sunday': 2.0611536224385582e-08} Source code in spotRiver/utils/features.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_weekday_distances ( x ): \"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Examples: >>> from spotRiver.utils.features import get_weekday_distances >>> from datetime import datetime >>> get_weekday_distances({\"date\": datetime(2020, 1, 1)}) {'Monday': 0.6065306597126334, 'Tuesday': 0.36787944117144233, 'Wednesday': 0.1353352832366127, 'Thursday': 0.01831563888873418, 'Friday': 0.00033546262790251185, 'Saturday': 3.354626279025118e-06, 'Sunday': 2.0611536224385582e-08} \"\"\" # Monday is the first day, i.e., 0: k = list ( x . keys ())[ 0 ] return { calendar . day_name [ weekday ]: math . exp ( - (( x [ k ] . weekday () - weekday ) ** 2 )) for weekday in range ( 0 , 7 )}","title":"features"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_hour_distances","text":"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Examples: >>> from spotRiver.utils.features import get_hour_distances >>> from datetime import datetime >>> get_hour_distances ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'0': 0.6065306597126334, '1': 0.36787944117144233, '2': 0.1353352832366127, '3': 0.01831563888873418, '4': 0.00033546262790251185, '5': 3.354626279025118e-06, '6': 2.0611536224385582e-08, '7': 8.315287191035679e-11, '8': 2.0611536224385582e-13, '9': 3.354626279025118e-16, '10': 3.354626279025118e-19, '11': 2.0611536224385582e-22, '12': 8.315287191035679e-26, '13': 2.0611536224385582e-29, '14': 3.354626279025118e-33, '15': 3.354626279025118e-37, '16': 2.0611536224385582e-41, '17': 8.315287191035679e-46, '18': 2.0611536224385582e-50, '19': 3.354626279025118e-55, '20': 3.354626279025118e-60, '21': 2.0611536224385582e-65, '22': 8.315287191035679e-71, '23': 2.0611536224385582e-76} Source code in spotRiver/utils/features.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_hour_distances ( x ): \"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day. Examples: >>> from spotRiver.utils.features import get_hour_distances >>> from datetime import datetime >>> get_hour_distances({\"date\": datetime(2020, 1, 1)}) {'0': 0.6065306597126334, '1': 0.36787944117144233, '2': 0.1353352832366127, '3': 0.01831563888873418, '4': 0.00033546262790251185, '5': 3.354626279025118e-06, '6': 2.0611536224385582e-08, '7': 8.315287191035679e-11, '8': 2.0611536224385582e-13, '9': 3.354626279025118e-16, '10': 3.354626279025118e-19, '11': 2.0611536224385582e-22, '12': 8.315287191035679e-26, '13': 2.0611536224385582e-29, '14': 3.354626279025118e-33, '15': 3.354626279025118e-37, '16': 2.0611536224385582e-41, '17': 8.315287191035679e-46, '18': 2.0611536224385582e-50, '19': 3.354626279025118e-55, '20': 3.354626279025118e-60, '21': 2.0611536224385582e-65, '22': 8.315287191035679e-71, '23': 2.0611536224385582e-76} \"\"\" k = list ( x . keys ())[ 0 ] return { str ( hour ): math . exp ( - (( x [ k ] . hour - hour ) ** 2 )) for hour in range ( 0 , 24 )}","title":"get_hour_distances()"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_month_distances","text":"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Examples: >>> from spotRiver.utils.features import get_month_distances >>> from datetime import datetime >>> get_month_distances ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'January': 0.6065306597126334, 'February': 0.36787944117144233, 'March': 0.1353352832366127, 'April': 0.01831563888873418, 'May': 0.00033546262790251185, 'June': 3.354626279025118e-06, 'July': 2.0611536224385582e-08, 'August': 8.315287191035679e-11, 'September': 2.0611536224385582e-13, 'October': 3.354626279025118e-16, 'November': 3.354626279025118e-19, 'December': 2.0611536224385582e-22} Source code in spotRiver/utils/features.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def get_month_distances ( x : Dict [ str , datetime ]) -> Dict [ str , float ]: \"\"\" This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month. Examples: >>> from spotRiver.utils.features import get_month_distances >>> from datetime import datetime >>> get_month_distances({\"date\": datetime(2020, 1, 1)}) {'January': 0.6065306597126334, 'February': 0.36787944117144233, 'March': 0.1353352832366127, 'April': 0.01831563888873418, 'May': 0.00033546262790251185, 'June': 3.354626279025118e-06, 'July': 2.0611536224385582e-08, 'August': 8.315287191035679e-11, 'September': 2.0611536224385582e-13, 'October': 3.354626279025118e-16, 'November': 3.354626279025118e-19, 'December': 2.0611536224385582e-22} \"\"\" k = list ( x . keys ())[ 0 ] return { calendar . month_name [ month ]: math . exp ( - (( x [ k ] . month - month ) ** 2 )) for month in range ( 1 , 13 )}","title":"get_month_distances()"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_ordinal_date","text":"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the string \u201cordinal_date\u201d and the value is the ordinal date of the input datetime object. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the string \u201cordinal_date\u201d and the value is the ordinal date of the input datetime object. Examples: >>> from datetime import datetime >>> from spotRiver.utils.features import get_ordinal_date >>> get_ordinal_date ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'ordinal_date': 737424} Source code in spotRiver/utils/features.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def get_ordinal_date ( x ): \"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the string \"ordinal_date\" and the value is the ordinal date of the input datetime object. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the string \"ordinal_date\" and the value is the ordinal date of the input datetime object. Examples: >>> from datetime import datetime >>> from spotRiver.utils.features import get_ordinal_date >>> get_ordinal_date({\"date\": datetime(2020, 1, 1)}) {'ordinal_date': 737424} \"\"\" k = list ( x . keys ())[ 0 ] return { \"ordinal_date\" : x [ k ] . toordinal ()}","title":"get_ordinal_date()"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_weekday_distances","text":"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Parameters: Name Type Description Default x Dict [ str , datetime ] A dictionary with a single key-value pair where the key is a string and the value is a datetime object. required Returns: Type Description Dict [ str , float ] A dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Examples: >>> from spotRiver.utils.features import get_weekday_distances >>> from datetime import datetime >>> get_weekday_distances ({ \"date\" : datetime ( 2020 , 1 , 1 )}) {'Monday': 0.6065306597126334, 'Tuesday': 0.36787944117144233, 'Wednesday': 0.1353352832366127, 'Thursday': 0.01831563888873418, 'Friday': 0.00033546262790251185, 'Saturday': 3.354626279025118e-06, 'Sunday': 2.0611536224385582e-08} Source code in spotRiver/utils/features.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_weekday_distances ( x ): \"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Args: x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object. Returns: (Dict[str, float]): A dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week. Examples: >>> from spotRiver.utils.features import get_weekday_distances >>> from datetime import datetime >>> get_weekday_distances({\"date\": datetime(2020, 1, 1)}) {'Monday': 0.6065306597126334, 'Tuesday': 0.36787944117144233, 'Wednesday': 0.1353352832366127, 'Thursday': 0.01831563888873418, 'Friday': 0.00033546262790251185, 'Saturday': 3.354626279025118e-06, 'Sunday': 2.0611536224385582e-08} \"\"\" # Monday is the first day, i.e., 0: k = list ( x . keys ())[ 0 ] return { calendar . day_name [ weekday ]: math . exp ( - (( x [ k ] . weekday () - weekday ) ** 2 )) for weekday in range ( 0 , 7 )}","title":"get_weekday_distances()"}]}