{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to spotRiver","text":"<p>For official information see SPOTSeven</p>"},{"location":"about/","title":"Contact/Privacy Policy","text":""},{"location":"about/#address","title":"Address","text":"<p>Prof. Dr. Thomas Bartz-Beielstein TH K\u00f6ln Raum 1.519 Steinm\u00fcllerallee 6 51643 Gummersbach +49 (0)2261 8196 6391 thomas.bartz-beielstein [at] th-koeln.de www.spotseven.de</p>"},{"location":"about/#privacy-policy","title":"Privacy Policy","text":"<p>We are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. The use of the Internet pages of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject.</p> <p>The processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled.</p> <p>As the controller, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone.</p> <ol> <li>Definitions</li> </ol> <p>The data protection declaration of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used.</p> <p>In this data protection declaration, we use, inter alia, the following terms:</p> <p>a)    Personal data</p> <p>Personal data means any information relating to an identified or identifiable natural person (\u201cdata subject\u201d). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.</p> <p>b) Data subject</p> <p>Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing.</p> <p>c)    Processing</p> <p>Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction.</p> <p>d)    Restriction of processing</p> <p>Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future.</p> <p>e)    Profiling</p> <p>Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements.</p> <p>f)     Pseudonymisation</p> <p>Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person.</p> <p>g)    Controller or controller responsible for the processing</p> <p>Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law.</p> <p>h)    Processor</p> <p>Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller.</p> <p>i)      Recipient</p> <p>Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing.</p> <p>j)      Third party</p> <p>Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data.</p> <p>k)    Consent</p> <p>Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her.</p> <ol> <li>Name and Address of the controller</li> </ol> <p>Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is:</p> <p>TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab</p> <p>Steinm\u00fcllerallee 1</p> <p>51643 Gummersbach</p> <p>Deutschland</p> <p>Phone: +49 2261 81966391</p> <p>Email: thomas.bartz-beielstein@th-koeln.de</p> <p>Website: www.spotseven.de</p> <ol> <li>Collection of general data and information</li> </ol> <p>The website of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems.</p> <p>When using these general data and information, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject.</p> <ol> <li>Comments function in the blog on the website</li> </ol> <p>The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties.</p> <p>If a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user\u2019s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller.</p> <ol> <li>Routine erasure and blocking of personal data</li> </ol> <p>The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to.</p> <p>If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements.</p> <ol> <li>Rights of the data subject</li> </ol> <p>a) Right of confirmation</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact our Data Protection Officer or another employee of the controller.</p> <p>b) Right of access</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information:</p> <p>the purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer.</p> <p>If a data subject wishes to avail himself of this right of access, he or she may at any time contact our Data Protection Officer or another employee of the controller.</p> <p>c) Right to rectification</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement.</p> <p>If a data subject wishes to exercise this right to rectification, he or she may, at any time, contact our Data Protection Officer or another employee of the controller.</p> <p>d) Right to erasure (Right to be forgotten)</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary:</p> <p>The personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee shall promptly ensure that the erasure request is complied with immediately.</p> <p>Where the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the necessary measures in individual cases.</p> <p>e) Right of restriction of processing</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies:</p> <p>The accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the restriction of the processing.</p> <p>f) Right to data portability</p> <p>Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller.</p> <p>Furthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others.</p> <p>In order to assert the right to data portability, the data subject may at any time contact the Data Protection Officer designated by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee.</p> <p>g) Right to object</p> <p>Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions.</p> <p>The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims.</p> <p>If the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab to the processing for direct marketing purposes, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab will no longer process the personal data for these purposes.</p> <p>In addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest.</p> <p>In order to exercise the right to object, the data subject may directly contact the Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications.</p> <p>h) Automated individual decision-making, including profiling</p> <p>Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, or (3) is not based on the data subject\u2019s explicit consent.</p> <p>If the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject\u2019s explicit consent, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall implement suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision.</p> <p>If the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller.</p> <p>i) Right to withdraw data protection consent</p> <p>Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time.</p> <p>f the data subject wishes to exercise the right to withdraw the consent, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller.</p> <ol> <li>Data protection provisions about the application and use of Facebook</li> </ol> <p>On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network.</p> <p>A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests.</p> <p>The operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland.</p> <p>With each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject.</p> <p>If the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the \u201cLike\u201d button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data.</p> <p>Facebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made.</p> <p>The data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook, e.g. the Facebook blocker of the provider Webgraph, which may be obtained under http://webgraph.com/resources/facebookblocker/. These applications may be used by the data subject to eliminate a data transmission to Facebook.</p> <ol> <li>Data protection provisions about the application and use of Google+</li> </ol> <p>On this website, the controller has integrated the Google+ button as a component. Google+ is a so-called social network. A social network is a social meeting place on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Google+ allows users of the social network to include the creation of private profiles, upload photos and network through friend requests.</p> <p>The operating company of Google+ is Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES.</p> <p>With each call-up to one of the individual pages of this website, which is operated by the controller and on which a Google+ button has been integrated, the Internet browser on the information technology system of the data subject automatically downloads a display of the corresponding Google+ button of Google through the respective Google+ button component. During the course of this technical procedure, Google is made aware of what specific sub-page of our website was visited by the data subject. More detailed information about Google+ is available under https://developers.google.com/+/.</p> <p>If the data subject is logged in at the same time to Google+, Google recognizes with each call-up to our website by the data subject and for the entire duration of his or her stay on our Internet site, which specific sub-pages of our Internet page were visited by the data subject. This information is collected through the Google+ button and Google matches this with the respective Google+ account associated with the data subject.</p> <p>If the data subject clicks on the Google+ button integrated on our website and thus gives a Google+ 1 recommendation, then Google assigns this information to the personal Google+ user account of the data subject and stores the personal data. Google stores the Google+ 1 recommendation of the data subject, making it publicly available in accordance with the terms and conditions accepted by the data subject in this regard. Subsequently, a Google+ 1 recommendation given by the data subject on this website together with other personal data, such as the Google+ account name used by the data subject and the stored photo, is stored and processed on other Google services, such as search-engine results of the Google search engine, the Google account of the data subject or in other places, e.g. on Internet pages, or in relation to advertisements. Google is also able to link the visit to this website with other personal data stored on Google. Google further records this personal information with the purpose of improving or optimizing the various Google services.</p> <p>Through the Google+ button, Google receives information that the data subject visited our website, if the data subject at the time of the call-up to our website is logged in to Google+. This occurs regardless of whether the data subject clicks or doesn\u2019t click on the Google+ button.</p> <p>If the data subject does not wish to transmit personal data to Google, he or she may prevent such transmission by logging out of his Google+ account before calling up our website.</p> <p>Further information and the data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/. More references from Google about the Google+ 1 button may be obtained under https://developers.google.com/+/web/buttons-policy.</p> <ol> <li>Data protection provisions about the application and use of Jetpack for WordPress</li> </ol> <p>On this website, the controller has integrated Jetpack. Jetpack is a WordPress plug-in, which provides additional features to the operator of a website based on WordPress. Jetpack allows the Internet site operator, inter alia, an overview of the visitors of the site. By displaying related posts and publications, or the ability to share content on the page, it is also possible to increase visitor numbers. In addition, security features are integrated into Jetpack, so a Jetpack-using site is better protected against brute-force attacks. Jetpack also optimizes and accelerates the loading of images on the website.</p> <p>The operating company of Jetpack Plug-Ins for WordPress is the Automattic Inc., 132 Hawthorne Street, San Francisco, CA 94107, UNITED STATES. The operating enterprise uses the tracking technology created by Quantcast Inc., 201 Third Street, San Francisco, CA 94103, UNITED STATES.</p> <p>Jetpack sets a cookie on the information technology system used by the data subject. The definition of cookies is explained above. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Jetpack component was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to submit data through the Jetpack component for analysis purposes to Automattic. During the course of this technical procedure Automattic receives data that is used to create an overview of website visits. The data obtained in this way serves the analysis of the behaviour of the data subject, which has access to the Internet page of the controller and is analyzed with the aim to optimize the website. The data collected through the Jetpack component is not used to identify the data subject without a prior obtaining of a separate express consent of the data subject. The data comes also to the notice of Quantcast. Quantcast uses the data for the same purposes as Automattic.</p> <p>The data subject can, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Automattic/Quantcast from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Automattic/Quantcast may be deleted at any time via a web browser or other software programs.</p> <p>In addition, the data subject has the possibility of objecting to a collection of data relating to a use of this Internet site that are generated by the Jetpack cookie as well as the processing of these data by Automattic/Quantcast and the chance to preclude any such. For this purpose, the data subject must press the \u2018opt-out\u2019 button under the link https://www.quantcast.com/opt-out/ which sets an opt-out cookie. The opt-out cookie set with this purpose is placed on the information technology system used by the data subject. If the cookies are deleted on the system of the data subject, then the data subject must call up the link again and set a new opt-out cookie.</p> <p>With the setting of the opt-out cookie, however, the possibility exists that the websites of the controller are not fully usable anymore by the data subject.</p> <p>The applicable data protection provisions of Automattic may be accessed under https://automattic.com/privacy/. The applicable data protection provisions of Quantcast can be accessed under https://www.quantcast.com/privacy/.</p> <ol> <li>Data protection provisions about the application and use of LinkedIn</li> </ol> <p>The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world.</p> <p>The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible.</p> <p>With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject.</p> <p>If the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data.</p> <p>LinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made.</p> <p>LinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy.</p> <ol> <li>Data protection provisions about the application and use of Twitter</li> </ol> <p>On this website, the controller has integrated components of Twitter. Twitter is a multilingual, publicly-accessible microblogging service on which users may publish and spread so-called \u2018tweets,\u2019 e.g. short messages, which are limited to 140 characters. These short messages are available for everyone, including those who are not logged on to Twitter. The tweets are also displayed to so-called followers of the respective user. Followers are other Twitter users who follow a user\u2019s tweets. Furthermore, Twitter allows you to address a wide audience via hashtags, links or retweets.</p> <p>The operating company of Twitter is Twitter, Inc., 1355 Market Street, Suite 900, San Francisco, CA 94103, UNITED STATES.</p> <p>With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Twitter component (Twitter button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding Twitter component of Twitter. Further information about the Twitter buttons is available under https://about.twitter.com/de/resources/buttons. During the course of this technical procedure, Twitter gains knowledge of what specific sub-page of our website was visited by the data subject. The purpose of the integration of the Twitter component is a retransmission of the contents of this website to allow our users to introduce this web page to the digital world and increase our visitor numbers.</p> <p>If the data subject is logged in at the same time on Twitter, Twitter detects with every call-up to our website by the data subject and for the entire duration of their stay on our Internet site which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Twitter component and associated with the respective Twitter account of the data subject. If the data subject clicks on one of the Twitter buttons integrated on our website, then Twitter assigns this information to the personal Twitter user account of the data subject and stores the personal data.</p> <p>Twitter receives information via the Twitter component that the data subject has visited our website, provided that the data subject is logged in on Twitter at the time of the call-up to our website. This occurs regardless of whether the person clicks on the Twitter component or not. If such a transmission of information to Twitter is not desirable for the data subject, then he or she may prevent this by logging off from their Twitter account before a call-up to our website is made.</p> <p>The applicable data protection provisions of Twitter may be accessed under https://twitter.com/privacy?lang=en.</p> <ol> <li>Data protection provisions about the application and use of YouTube</li> </ol> <p>On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal.</p> <p>The operating company of YouTube is YouTube, LLC, 901 Cherry Ave., San Bruno, CA 94066, UNITED STATES. The YouTube, LLC is a subsidiary of Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES.</p> <p>With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject.</p> <p>If the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject.</p> <p>YouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made.</p> <p>YouTube\u2019s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google.</p> <ol> <li>Legal basis for the processing</li> </ol> <p>Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR).</p> <ol> <li>The legitimate interests pursued by the controller or by a third party</li> </ol> <p>Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders.</p> <ol> <li>Period for which the personal data will be stored</li> </ol> <p>The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract.</p> <ol> <li>Provision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data</li> </ol> <p>We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact our Data Protection Officer. Our Data Protection Officer clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data.</p> <ol> <li>Existence of automated decision-making</li> </ol> <p>As a responsible company, we do not use automatic decision-making or profiling.</p> <p>This Privacy Policy has been generated by the Privacy Policy Generator of the External Data Protection Officers that was developed in cooperation with RC GmbH, which sells used notebooks and the Media Law Lawyers from WBS-LAW.</p>"},{"location":"download/","title":"Install spotRiver","text":"<pre><code>pip install spotRiver\n</code></pre>"},{"location":"examples/","title":"SPOT Examples","text":""},{"location":"examples/#simple-spotpython-run","title":"Simple spotPython run","text":"<p>import numpy as np from spotPython.fun.objectivefunctions import analytical from spotPython.spot import spot import numpy as np from math import inf</p>"},{"location":"examples/#number-of-initial-points","title":"number of initial points:","text":"<p>ni = 7</p>"},{"location":"examples/#number-of-points","title":"number of points","text":"<p>n = 10</p> <p>fun = analytical().fun_sphere lower = np.array([-1]) upper = np.array([1]) design_control={\u201cinit_size\u201d: ni}</p> <p>spot_1 = spot.Spot(fun=fun,             lower = lower,             upper= upper,             fun_evals = n,             show_progress=True,             design_control=design_control,) spot_1.run()</p>"},{"location":"hyperparameter-tuning-cookbook/","title":"Hyperparameter Tuning Cookbook","text":"<p>The following is a cookbook of hyperparameter tuning recipes. It is not meant to be exhaustive, but instead act as a place to capture a number of the common patterns used in hyperparameter tuning.</p> <p>Hyperparameter Tuning Cookbook</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>spotRiver<ul> <li>data<ul> <li>airline_passengers</li> <li>base</li> <li>bike_sharing</li> <li>generic</li> <li>opm</li> <li>river_hyper_dict</li> <li>synth<ul> <li>sea</li> </ul> </li> </ul> </li> <li>drift<ul> <li>drift_generator</li> </ul> </li> <li>evaluation<ul> <li>eval_bml</li> <li>eval_nowcast</li> <li>eval_oml</li> </ul> </li> <li>fun<ul> <li>hyperriver</li> <li>hyperriver_old</li> </ul> </li> <li>plot<ul> <li>stats</li> </ul> </li> <li>preprocess<ul> <li>impute</li> </ul> </li> <li>utils<ul> <li>data_conversion</li> <li>features</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/spotRiver/data/","title":"data","text":"<p>Datasets.</p> <p>This module contains a collection of datasets for multiple tasks: classification, regression, etc. The data corresponds to popular datasets and are conveniently wrapped to easily iterate over the data in a stream fashion. All datasets have fixed size.</p>"},{"location":"reference/spotRiver/data/#spotRiver.data.AirlinePassengers","title":"<code>AirlinePassengers</code>","text":"<p>         Bases: <code>base.FileDataset</code></p> <p>Monthly number of international airline passengers [1].</p> <p>The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data.</p> <p>Returns:</p> Type Description <code>Generator</code> <p>An iterator over the data in the file.</p> <p>Note: The code can be used as a template for creating new datasets based on CSV files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.data.airline_passengers import AirlinePassengers\n    dataset = AirlinePassengers()\n    for x, y in dataset.take(5):\n        print(x, y)\n    {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112\n    {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118\n    {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132\n    {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129\n    {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121\n</code></pre> References <p>[1]: International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/airline_passengers.py</code> <pre><code>class AirlinePassengers(base.FileDataset):\n\"\"\"Monthly number of international airline passengers [1].\n\n    The stream contains 144 items and only one single feature, which is the month. The goal is to\n    predict the number of passengers each month by capturing the trend and the seasonality of the\n    data.\n\n    Returns:\n        (Generator): An iterator over the data in the file.\n\n    Note: The code can be used as a template for creating new datasets based on CSV files.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.data.airline_passengers import AirlinePassengers\n            dataset = AirlinePassengers()\n            for x, y in dataset.take(5):\n                print(x, y)\n            {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112\n            {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118\n            {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132\n            {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129\n            {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121\n\n    References:\n        [1]: [International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;display=line)\n\n    \"\"\"\n\n    def __init__(self):\n\"\"\"Constructor method.\n\n        Returns:\n            (NoneType): None\n\n        \"\"\"\n        super().__init__(\n            filename=\"airline-passengers.csv\",\n            task=base.REG,\n            n_features=1,\n            n_samples=144,\n        )\n\n    def __iter__(self):\n\"\"\"Iterate over the data.\n            Returns:\n                (Generator): An iterator over the data in the file.\n        \"\"\"\n        return stream.iter_csv(\n            self.path,\n            target=\"passengers\",\n            converters={\"passengers\": int},\n            parse_dates={\"month\": \"%Y-%m\"},\n        )\n</code></pre>"},{"location":"reference/spotRiver/data/#spotRiver.data.airline_passengers.AirlinePassengers.__init__","title":"<code>__init__()</code>","text":"<p>Constructor method.</p> <p>Returns:</p> Type Description <code>NoneType</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/airline_passengers.py</code> <pre><code>def __init__(self):\n\"\"\"Constructor method.\n\n    Returns:\n        (NoneType): None\n\n    \"\"\"\n    super().__init__(\n        filename=\"airline-passengers.csv\",\n        task=base.REG,\n        n_features=1,\n        n_samples=144,\n    )\n</code></pre>"},{"location":"reference/spotRiver/data/#spotRiver.data.airline_passengers.AirlinePassengers.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the data.</p> <p>Returns:</p> Type Description <code>Generator</code> <p>An iterator over the data in the file.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/airline_passengers.py</code> <pre><code>def __iter__(self):\n\"\"\"Iterate over the data.\n        Returns:\n            (Generator): An iterator over the data in the file.\n    \"\"\"\n    return stream.iter_csv(\n        self.path,\n        target=\"passengers\",\n        converters={\"passengers\": int},\n        parse_dates={\"month\": \"%Y-%m\"},\n    )\n</code></pre>"},{"location":"reference/spotRiver/data/airline_passengers/","title":"airline_passengers","text":""},{"location":"reference/spotRiver/data/airline_passengers/#spotRiver.data.airline_passengers.AirlinePassengers","title":"<code>AirlinePassengers</code>","text":"<p>         Bases: <code>base.FileDataset</code></p> <p>Monthly number of international airline passengers [1].</p> <p>The stream contains 144 items and only one single feature, which is the month. The goal is to predict the number of passengers each month by capturing the trend and the seasonality of the data.</p> <p>Returns:</p> Type Description <code>Generator</code> <p>An iterator over the data in the file.</p> <p>Note: The code can be used as a template for creating new datasets based on CSV files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.data.airline_passengers import AirlinePassengers\n    dataset = AirlinePassengers()\n    for x, y in dataset.take(5):\n        print(x, y)\n    {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112\n    {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118\n    {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132\n    {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129\n    {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121\n</code></pre> References <p>[1]: International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/airline_passengers.py</code> <pre><code>class AirlinePassengers(base.FileDataset):\n\"\"\"Monthly number of international airline passengers [1].\n\n    The stream contains 144 items and only one single feature, which is the month. The goal is to\n    predict the number of passengers each month by capturing the trend and the seasonality of the\n    data.\n\n    Returns:\n        (Generator): An iterator over the data in the file.\n\n    Note: The code can be used as a template for creating new datasets based on CSV files.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.data.airline_passengers import AirlinePassengers\n            dataset = AirlinePassengers()\n            for x, y in dataset.take(5):\n                print(x, y)\n            {'month': datetime.datetime(1949, 1, 1, 0, 0)} 112\n            {'month': datetime.datetime(1949, 2, 1, 0, 0)} 118\n            {'month': datetime.datetime(1949, 3, 1, 0, 0)} 132\n            {'month': datetime.datetime(1949, 4, 1, 0, 0)} 129\n            {'month': datetime.datetime(1949, 5, 1, 0, 0)} 121\n\n    References:\n        [1]: [International airline passengers: monthly totals in thousands. Jan 49 \u2013 Dec 60](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;display=line)\n\n    \"\"\"\n\n    def __init__(self):\n\"\"\"Constructor method.\n\n        Returns:\n            (NoneType): None\n\n        \"\"\"\n        super().__init__(\n            filename=\"airline-passengers.csv\",\n            task=base.REG,\n            n_features=1,\n            n_samples=144,\n        )\n\n    def __iter__(self):\n\"\"\"Iterate over the data.\n            Returns:\n                (Generator): An iterator over the data in the file.\n        \"\"\"\n        return stream.iter_csv(\n            self.path,\n            target=\"passengers\",\n            converters={\"passengers\": int},\n            parse_dates={\"month\": \"%Y-%m\"},\n        )\n</code></pre>"},{"location":"reference/spotRiver/data/airline_passengers/#spotRiver.data.airline_passengers.AirlinePassengers.__init__","title":"<code>__init__()</code>","text":"<p>Constructor method.</p> <p>Returns:</p> Type Description <code>NoneType</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/airline_passengers.py</code> <pre><code>def __init__(self):\n\"\"\"Constructor method.\n\n    Returns:\n        (NoneType): None\n\n    \"\"\"\n    super().__init__(\n        filename=\"airline-passengers.csv\",\n        task=base.REG,\n        n_features=1,\n        n_samples=144,\n    )\n</code></pre>"},{"location":"reference/spotRiver/data/airline_passengers/#spotRiver.data.airline_passengers.AirlinePassengers.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the data.</p> <p>Returns:</p> Type Description <code>Generator</code> <p>An iterator over the data in the file.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/airline_passengers.py</code> <pre><code>def __iter__(self):\n\"\"\"Iterate over the data.\n        Returns:\n            (Generator): An iterator over the data in the file.\n    \"\"\"\n    return stream.iter_csv(\n        self.path,\n        target=\"passengers\",\n        converters={\"passengers\": int},\n        parse_dates={\"month\": \"%Y-%m\"},\n    )\n</code></pre>"},{"location":"reference/spotRiver/data/base/","title":"base","text":""},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Config","title":"<code>Config</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>Base class for all configurations.</p> <p>All configurations inherit from this class, be they stored in a file or generated on the fly.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class Config(abc.ABC):\n\"\"\"Base class for all configurations.\n\n    All configurations inherit from this class, be they stored in a file or generated on the fly.\n    \"\"\"\n\n    def __init__(\n        self,\n    ):\n        pass\n\n    @property\n    def desc(self):\n\"\"\"Return the description from the docstring.\"\"\"\n        desc = re.split(pattern=r\"\\w+\\n\\s{4}\\-{3,}\", string=self.__doc__, maxsplit=0)[0]\n        return inspect.cleandoc(desc)\n\n    @property\n    def _repr_content(self):\n\"\"\"The items that are displayed in the __repr__ method.\n\n        This property can be overridden in order to modify the output of the __repr__ method.\n\n        \"\"\"\n\n        content = {}\n        content[\"Name\"] = self.__class__.__name__\n        return content\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Config.desc","title":"<code>desc</code>  <code>property</code>","text":"<p>Return the description from the docstring.</p>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Dataset","title":"<code>Dataset</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>Base class for all datasets.</p> <p>All datasets inherit from this class, be they stored in a file or generated on the fly.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>Type of task the dataset is meant for. Should be one of: - \u201cRegression\u201d - \u201cBinary classification\u201d - \u201cMulti-class classification\u201d - \u201cMulti-output binary classification\u201d - \u201cMulti-output regression\u201d</p> required <code>n_features</code> <code>int</code> <p>Number of features in the dataset.</p> <code>None</code> <code>n_samples</code> <code>int</code> <p>Number of samples in the dataset.</p> <code>None</code> <code>n_classes</code> <code>int</code> <p>Number of classes in the dataset, only applies to classification datasets.</p> <code>None</code> <code>n_outputs</code> <code>int</code> <p>Number of outputs the target is made of, only applies to multi-output datasets.</p> <code>None</code> <code>sparse</code> <code>bool</code> <p>Whether the dataset is sparse or not.</p> <code>False</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class Dataset(abc.ABC):\n\"\"\"Base class for all datasets.\n\n    All datasets inherit from this class, be they stored in a file or generated on the fly.\n\n    Args:\n        task (str):\n            Type of task the dataset is meant for. Should be one of:\n            - \"Regression\"\n            - \"Binary classification\"\n            - \"Multi-class classification\"\n            - \"Multi-output binary classification\"\n            - \"Multi-output regression\"\n        n_features (int):\n            Number of features in the dataset.\n        n_samples (int):\n            Number of samples in the dataset.\n        n_classes (int):\n            Number of classes in the dataset, only applies to classification datasets.\n        n_outputs (int):\n            Number of outputs the target is made of, only applies to multi-output datasets.\n        sparse (bool):\n            Whether the dataset is sparse or not.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        task: str,\n        n_features: int=None,\n        n_samples=None,\n        n_classes=None,\n        n_outputs=None,\n        sparse=False,\n    ):\n        self.task = task\n        self.n_features = n_features\n        self.n_samples = n_samples\n        self.n_outputs = n_outputs\n        self.n_classes = n_classes\n        self.sparse = sparse\n\n    @abc.abstractmethod\n    def __iter__(self):\n        raise NotImplementedError\n\n    def take(self, k: int):\n\"\"\"Iterate over the k samples.\"\"\"\n        return itertools.islice(self, k)\n\n    @property\n    def desc(self):\n\"\"\"Return the description from the docstring.\"\"\"\n        desc = re.split(pattern=r\"\\w+\\n\\s{4}\\-{3,}\", string=self.__doc__, maxsplit=0)[0]\n        return inspect.cleandoc(desc)\n\n    @property\n    def _repr_content(self):\n\"\"\"The items that are displayed in the __repr__ method.\n\n        This property can be overridden in order to modify the output of the __repr__ method.\n\n        \"\"\"\n\n        content = {}\n        content[\"Name\"] = self.__class__.__name__\n        content[\"Task\"] = self.task\n        if isinstance(self, SyntheticDataset) and self.n_samples is None:\n            content[\"Samples\"] = \"\u221e\"\n        elif self.n_samples:\n            content[\"Samples\"] = f\"{self.n_samples:,}\"\n        if self.n_features:\n            content[\"Features\"] = f\"{self.n_features:,}\"\n        if self.n_outputs:\n            content[\"Outputs\"] = f\"{self.n_outputs:,}\"\n        if self.n_classes:\n            content[\"Classes\"] = f\"{self.n_classes:,}\"\n        content[\"Sparse\"] = str(self.sparse)\n\n        return content\n\n    def __repr__(self):\n        l_len = max(map(len, self._repr_content.keys()))\n        r_len = max(map(len, self._repr_content.values()))\n\n        out = f\"{self.desc}\\n\\n\" + \"\\n\".join(\n            k.rjust(l_len) + \"  \" + v.ljust(r_len) for k, v in self._repr_content.items()\n        )\n\n        if \"Parameters\\n    ----------\" in self.__doc__:\n            params = re.split(\n                r\"\\w+\\n\\s{4}\\-{3,}\",\n                re.split(\"Parameters\\n    ----------\", self.__doc__)[1],\n            )[0].rstrip()\n            out += f\"\\n\\nParameters\\n----------{params}\"\n\n        return out\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Dataset.desc","title":"<code>desc</code>  <code>property</code>","text":"<p>Return the description from the docstring.</p>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.Dataset.take","title":"<code>take(k)</code>","text":"<p>Iterate over the k samples.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>def take(self, k: int):\n\"\"\"Iterate over the k samples.\"\"\"\n    return itertools.islice(self, k)\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.FileConfig","title":"<code>FileConfig</code>","text":"<p>         Bases: <code>Config</code></p> <p>Base class for configurations that are stored in a local file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The file\u2019s name.</p> required <code>directory</code> <code>str</code> <p>The directory where the file is contained. Defaults to the location of the <code>datasets</code> module.</p> <code>None</code> <code>desc</code> <code>dict</code> <p>Extra config parameters to pass as keyword arguments.</p> <code>{}</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class FileConfig(Config):\n\"\"\"Base class for configurations that are stored in a local file.\n\n    Args:\n        filename (str):\n            The file's name.\n        directory (str):\n            The directory where the file is contained. Defaults to the location of the `datasets` module.\n        desc (dict):\n            Extra config parameters to pass as keyword arguments.\n\n    \"\"\"\n\n    def __init__(self, filename, directory=None, **desc):\n        super().__init__(**desc)\n        self.filename = filename\n        self.directory = directory\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"Path\"] = str(self.path)\n        return content\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.FileDataset","title":"<code>FileDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>Base class for datasets that are stored in a local file.</p> <p>Small datasets that are part of the spotRiver package inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The file\u2019s name.</p> required <code>directory</code> <code>str</code> <p>The directory where the file is contained. Defaults to the location of the <code>datasets</code> module.</p> <code>None</code> <code>desc</code> <code>dict</code> <p>Extra dataset parameters to pass as keyword arguments.</p> <code>{}</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class FileDataset(Dataset):\n\"\"\"Base class for datasets that are stored in a local file.\n\n    Small datasets that are part of the spotRiver package inherit from this class.\n\n    Args:\n        filename (str): The file's name.\n        directory (str):\n            The directory where the file is contained. Defaults to the location of the `datasets` module.\n        desc (dict):\n            Extra dataset parameters to pass as keyword arguments.\n\n    \"\"\"\n\n    def __init__(self, filename, directory=None, **desc):\n        super().__init__(**desc)\n        self.filename = filename\n        self.directory = directory\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"Path\"] = str(self.path)\n        return content\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.GenericFileDataset","title":"<code>GenericFileDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>Base class for datasets that are stored in a local file.</p> <p>Small datasets that are part of the spotRiver package inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The file\u2019s name.</p> required <code>directory</code> <code>str</code> <p>The directory where the file is contained. Defaults to the location of the <code>datasets</code> module.</p> <code>None</code> <code>desc</code> <code>dict</code> <p>Extra dataset parameters to pass as keyword arguments.</p> <code>{}</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class GenericFileDataset(Dataset):\n\"\"\"Base class for datasets that are stored in a local file.\n\n    Small datasets that are part of the spotRiver package inherit from this class.\n\n    Args:\n        filename (str): The file's name.\n        directory (str):\n            The directory where the file is contained. Defaults to the location of the `datasets` module.\n        desc (dict):\n            Extra dataset parameters to pass as keyword arguments.\n    \"\"\"\n\n    def __init__(self, filename, target, converters, parse_dates, directory=None, **desc):\n        super().__init__(**desc)\n        self.filename = filename\n        self.directory = directory\n        self.target = target\n        self.converters = converters\n        self.parse_dates = parse_dates\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"Path\"] = str(self.path)\n        return content\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.RemoteDataset","title":"<code>RemoteDataset</code>","text":"<p>         Bases: <code>FileDataset</code></p> <p>Base class for datasets that are stored in a remote file.</p> <p>Medium and large datasets that are not part of the river package inherit from this class.</p> Note <p>The filename doesn\u2019t have to be provided if unpack is False. Indeed in the latter case the filename will be inferred from the URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL the dataset is located at.</p> required <code>size</code> <code>int</code> <p>The expected download size.</p> required <code>unpack</code> <code>bool</code> <p>Whether to unpack the download or not.</p> <code>True</code> <code>filename</code> <code>str</code> <p>An optional name to given to the file if the file is unpacked.</p> <code>None</code> <code>desc</code> <code>dict</code> <p>Extra dataset parameters to pass as keyword arguments.</p> <code>{}</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class RemoteDataset(FileDataset):\n\"\"\"Base class for datasets that are stored in a remote file.\n\n    Medium and large datasets that are not part of the river package inherit from this class.\n\n    Note:\n        The filename doesn't have to be provided if unpack is False. Indeed in the latter case the\n        filename will be inferred from the URL.\n\n    Args:\n        url (str):\n            The URL the dataset is located at.\n        size (int):\n            The expected download size.\n        unpack (bool):\n            Whether to unpack the download or not.\n        filename (str):\n            An optional name to given to the file if the file is unpacked.\n        desc (dict):\n            Extra dataset parameters to pass as keyword arguments.\n    \"\"\"\n\n    def __init__(self, url, size, unpack=True, filename=None, **desc):\n        if filename is None:\n            filename = path.basename(url)\n\n        super().__init__(filename=filename, **desc)\n        self.url = url\n        self.size = size\n        self.unpack = unpack\n\n    @property\n    def path(self):\n        return pathlib.Path(get_data_home(), self.__class__.__name__, self.filename)\n\n    def download(self, force=False, verbose=True):\n        if not force and self.is_downloaded:\n            return\n\n        # Determine where to download the archive\n        directory = self.path.parent\n        directory.mkdir(parents=True, exist_ok=True)\n        archive_path = directory.joinpath(path.basename(self.url))\n\n        with request.urlopen(self.url) as r:\n            # Notify the user\n            if verbose:\n                meta = r.info()\n                try:\n                    n_bytes = int(meta[\"Content-Length\"])\n                    msg = f\"Downloading {self.url} ({utils.pretty.humanize_bytes(n_bytes)})\"\n                except KeyError:\n                    msg = f\"Downloading {self.url}\"\n                print(msg)\n\n            # Now dump the contents of the requests\n            with open(archive_path, \"wb\") as f:\n                shutil.copyfileobj(r, f)\n\n        if not self.unpack:\n            return\n\n        if verbose:\n            print(f\"Uncompressing into {directory}\")\n\n        if archive_path.suffix.endswith(\"zip\"):\n            with zipfile.ZipFile(archive_path, \"r\") as zf:\n                zf.extractall(directory)\n\n        elif archive_path.suffix.endswith((\"gz\", \"tar\")):\n            mode = \"r:\" if archive_path.suffix.endswith(\"tar\") else \"r:gz\"\n            tar = tarfile.open(archive_path, mode)\n            tar.extractall(directory)\n            tar.close()\n\n        else:\n            raise RuntimeError(f\"Unhandled extension type: {archive_path.suffix}\")\n\n        # Delete the archive file now that it has been uncompressed\n        archive_path.unlink()\n\n    @abc.abstractmethod\n    def _iter(self):\n        pass\n\n    @property\n    def is_downloaded(self):\n\"\"\"Indicate whether or the data has been correctly downloaded.\"\"\"\n        if self.path.exists():\n            if self.path.is_file():\n                return self.path.stat().st_size == self.size\n            return sum(f.stat().st_size for f in self.path.glob(\"**/*\") if f.is_file())\n\n        return False\n\n    def __iter__(self):\n        if not self.is_downloaded:\n            self.download(verbose=True)\n        if not self.is_downloaded:\n            raise RuntimeError(\"Something went wrong during the download\")\n        yield from self._iter()\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"URL\"] = self.url\n        content[\"Size\"] = utils.pretty.humanize_bytes(self.size)\n        content[\"Downloaded\"] = str(self.is_downloaded)\n        return content\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.RemoteDataset.is_downloaded","title":"<code>is_downloaded</code>  <code>property</code>","text":"<p>Indicate whether or the data has been correctly downloaded.</p>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.SyntheticDataset","title":"<code>SyntheticDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>A synthetic dataset.</p> <p>All synthetic datasets inherit from this class.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>class SyntheticDataset(Dataset):\n\"\"\"A synthetic dataset.\n\n    All synthetic datasets inherit from this class.\n\n    \"\"\"\n\n    def __repr__(self):\n        l_len_prop = max(map(len, self._repr_content.keys()))\n        r_len_prop = max(map(len, self._repr_content.values()))\n        params = self._get_params()\n        l_len_config = max(map(len, params.keys()))\n        r_len_config = max(map(len, map(str, params.values())))\n\n        out = (\n            \"Synthetic data generator\\n\\n\"\n            + \"\\n\".join(k.rjust(l_len_prop) + \"  \" + v.ljust(r_len_prop) for k, v in self._repr_content.items())\n            + \"\\n\\nConfiguration\\n-------------\\n\"\n            + \"\\n\".join(k.rjust(l_len_config) + \"  \" + str(v).ljust(r_len_config) for k, v in params.items())\n        )\n\n        return out\n\n    def _get_params(self) -&gt; typing.Dict[str, typing.Any]:\n\"\"\"Return the parameters that were used during initialization.\"\"\"\n        return {\n            name: getattr(self, name)\n            for name, param in inspect.signature(self.__init__).parameters.items()  # type: ignore\n            if param.kind != param.VAR_KEYWORD\n        }\n</code></pre>"},{"location":"reference/spotRiver/data/base/#spotRiver.data.base.get_data_home","title":"<code>get_data_home(data_home=None)</code>","text":"<p>Return the location where remote datasets are to be stored.     By default the data directory is set to a folder named \u2018spotriver_data\u2019 in the     user home folder. Alternatively, it can be set by the \u2018SPOTRIVER_DATA\u2019 environment     variable or programmatically by giving an explicit folder path. The \u2018~\u2019     symbol is expanded to the user home folder.     If the folder does not already exist, it is automatically created.</p> <p>Parameters:</p> Name Type Description Default <code>data_home</code> <code>str</code> <p>The path to spotriver data directory. If <code>None</code>, the default path is <code>~/spotriver_data</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>data_home</code> <code>str</code> <code>str</code> <p>The path to the spotriver data directory.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/base.py</code> <pre><code>def get_data_home(data_home=None) -&gt; str:\n\"\"\"Return the location where remote datasets are to be stored.\n        By default the data directory is set to a folder named 'spotriver_data' in the\n        user home folder. Alternatively, it can be set by the 'SPOTRIVER_DATA' environment\n        variable or programmatically by giving an explicit folder path. The '~'\n        symbol is expanded to the user home folder.\n        If the folder does not already exist, it is automatically created.\n\n    Args:\n        data_home (str):\n            The path to spotriver data directory. If `None`, the default path\n            is `~/spotriver_data`.\n\n    Returns:\n        data_home (str):\n        The path to the spotriver data directory.\n    \"\"\"\n    if data_home is None:\n        data_home = environ.get(\"SPOTRIVER_DATA\", Path.home() / \"spotriver_data\")\n    # Ensure data_home is a Path() object pointing to an absolute path\n    data_home = Path(data_home).absolute()\n    # Create data directory if it does not exists.\n    data_home.mkdir(parents=True, exist_ok=True)\n    return data_home\n</code></pre>"},{"location":"reference/spotRiver/data/bike_sharing/","title":"bike_sharing","text":""},{"location":"reference/spotRiver/data/bike_sharing/#spotRiver.data.bike_sharing.get_bike_sharing_data","title":"<code>get_bike_sharing_data(train_size=0.6)</code>","text":"<p>Fetches the Bike Sharing Demand dataset from OpenML and splits it into training and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>train_size</code> <code>float</code> <p>The proportion of the dataset to include in the training set. Default value: 0.6</p> <code>0.6</code> <p>Returns:</p> Type Description <code>tuple</code> <p>tuple containing: df (pd.DataFrame): The full dataset. train (pd.DataFrame): The training set. test (pd.DataFrame): The test set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.data.bike_sharing import get_bike_sharing_data\n&gt;&gt;&gt; df, train, test = get_bike_sharing_data(train_size=0.6)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/bike_sharing.py</code> <pre><code>def get_bike_sharing_data(train_size=0.6):\n\"\"\"\n    Fetches the Bike Sharing Demand dataset from OpenML and splits it into training and test sets.\n\n    Args:\n        train_size (float):\n            The proportion of the dataset to include in the training set. Default value: 0.6\n    Returns:\n        (tuple): tuple containing:\n            df (pd.DataFrame): The full dataset.\n            train (pd.DataFrame): The training set.\n            test (pd.DataFrame): The test set.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.data.bike_sharing import get_bike_sharing_data\n        &gt;&gt;&gt; df, train, test = get_bike_sharing_data(train_size=0.6)\n    \"\"\"\n\n    bike_sharing = fetch_openml(\"Bike_Sharing_Demand\", version=2, as_frame=True, parser=\"pandas\")\n    df = bike_sharing.frame\n    # Normalize the count column\n    df[\"count\"] = df[\"count\"] / df[\"count\"].max()\n    # Replace heavy_rain with rain in the weather column\n    df[\"weather\"].replace(to_replace=\"heavy_rain\", value=\"rain\", inplace=True)\n    n = df.shape[0]\n    # Calculate the number of rows in the training set\n    k = int(n * train_size)\n    # Split the data into training and test sets\n    train = df[0:k]\n    test = df[k:n]\n    return df, train, test\n</code></pre>"},{"location":"reference/spotRiver/data/generic/","title":"generic","text":""},{"location":"reference/spotRiver/data/generic/#spotRiver.data.generic.GenericData","title":"<code>GenericData</code>","text":"<p>         Bases: <code>base.GenericFileDataset</code></p> <p>A class for handling generic data.</p> <p>This class inherits from the base.GenericFileDataset class and provides an interface for handling generic data.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file containing the data.</p> required <code>target</code> <code>str</code> <p>The name of the target column.</p> required <code>n_features</code> <code>int</code> <p>The number of features in the dataset.</p> required <code>n_samples</code> <code>int</code> <p>The number of samples in the dataset.</p> required <code>converters</code> <code>Dict[str, callable]</code> <p>A dictionary of functions for converting column data.</p> required <code>parse_dates</code> <code>List[str]</code> <p>A list of column names to parse as dates.</p> required <code>directory</code> <code>str</code> <p>The directory where the file is located.</p> required <code>task</code> <code>str</code> <p>The type of task. Default is base.REG for regression.</p> <code>base.REG</code> <code>fraction</code> <code>float</code> <p>The fraction of the data to use. Default is 1.0 for all data.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Generator</code> <p>An iterator over the data in the file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.data.generic import GenericData\n    import importlib.resources as pkg_resources\n    import spotRiver.data as data\n    inp_file = pkg_resources.files(data)\n    csv_path = str(inp_file.resolve())\n    dataset = GenericData(filename=\"UnivariateData.csv\",\n                        directory=csv_path,\n                        target=\"Consumption\",\n                        n_features=1,\n                        n_samples=51_706,\n                        converters={\"Consumption\": float},\n                        parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n    for x, y in dataset:\n        print(x, y)\n        break\n    {'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/generic.py</code> <pre><code>class GenericData(base.GenericFileDataset):\n\"\"\"A class for handling generic data.\n\n    This class inherits from the base.GenericFileDataset class and provides an interface for handling generic data.\n\n    Args:\n        filename (str): The name of the file containing the data.\n        target (str): The name of the target column.\n        n_features (int): The number of features in the dataset.\n        n_samples (int): The number of samples in the dataset.\n        converters (Dict[str, callable]): A dictionary of functions for converting column data.\n        parse_dates (List[str]): A list of column names to parse as dates.\n        directory (str): The directory where the file is located.\n        task (str): The type of task. Default is base.REG for regression.\n        fraction (float): The fraction of the data to use. Default is 1.0 for all data.\n\n    Returns:\n        (Generator): An iterator over the data in the file.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.data.generic import GenericData\n            import importlib.resources as pkg_resources\n            import spotRiver.data as data\n            inp_file = pkg_resources.files(data)\n            csv_path = str(inp_file.resolve())\n            dataset = GenericData(filename=\"UnivariateData.csv\",\n                                directory=csv_path,\n                                target=\"Consumption\",\n                                n_features=1,\n                                n_samples=51_706,\n                                converters={\"Consumption\": float},\n                                parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n            for x, y in dataset:\n                print(x, y)\n                break\n            {'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217\n\n    \"\"\"\n    def __init__(\n        self,\n        filename: str,\n        target: str,\n        n_features: int,\n        n_samples: int,\n        converters: Dict[str, callable],\n        parse_dates: List[str],\n        directory: str,\n        task: str = base.REG,\n        fraction: float = 1.0\n    ):\n        super().__init__(\n            filename=filename,\n            n_features=n_features,\n            n_samples=n_samples,\n            task=task,\n            target=target,\n            converters=converters,\n            parse_dates=parse_dates,\n            directory=directory,\n        )\n        self.fraction = fraction\n\n    def __iter__(self) -&gt; Union[Dict[str, float], float]:\n        return stream.iter_csv(\n            self.path,\n            target=self.target,\n            converters=self.converters,\n            parse_dates=self.parse_dates,\n            fraction=self.fraction,\n            seed=123,\n        )\n</code></pre>"},{"location":"reference/spotRiver/data/opm/","title":"opm","text":"<p>Office of Policy and Management dataset</p> <p>The original database is available from CT\u2019s OPM</p> <pre><code>https://portal.ct.gov/OPM/IGPP/Publications/Real-Estate-Sales-Listing\n</code></pre> <p>The data contains 985,862 observations of up to 14 variables.</p>"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm","title":"<code>fetch_opm(*, data_home=None, download_if_missing=True, return_X_y=False, include_numeric=True, include_categorical=False)</code>","text":"<p>Fetch the OPM dataset from the Connecticut Open Data portal.</p>"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm--parameters","title":"Parameters","text":"str or pathlib.Path, default=None <p>Specify another download and cache folder for the datasets. By default all spotRiver data is stored in \u2018~/spotriver_data\u2019 subfolders.</p> bool, default=True <p>If False, raise an IOError if the data is not locally available rather than trying to download the data from the source site.</p> bool, default=False <p>If True, return <code>(X, y)</code> instead of a <code>Bunch</code> object. See <code>sklearn.utils.Bunch</code> for more information.</p> bool, default=True <p>If True, include numeric columns in the output. Numeric columns include \u2018List Year\u2019, \u2018Assessed Value\u2019, \u2018Sale Amount\u2019, \u2018Sales Ratio\u2019, \u2018lat\u2019, \u2018lon\u2019, and \u2018timestamp_rec\u2019.</p> bool, default=False <p>If True, include categorical columns in the output. Categorical columns include \u2018Town\u2019, \u2018Address\u2019, \u2018Property Type\u2019, \u2018Residential Type\u2019, \u2018Non Use Code\u2019, \u2018Assessor Remarks\u2019, and \u2018OPM remarks\u2019. Columns with fewer than 200 unique values will be treated as categorical.</p>"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm--returns","title":"Returns","text":"<p>Bunch or Tuple[pd.DataFrame, pd.Series] or pd.DataFrame     If <code>return_X_y</code> is False, return a <code>Bunch</code> object with the following     attributes:         * data : pd.DataFrame of shape (n_samples, n_features)             The feature matrix.         * target : pd.Series of shape (n_samples,)             The target vector.         * DESCR : str             A short description of the dataset.     If <code>return_X_y</code> is True, return a tuple <code>(X, y)</code> where <code>X</code> is the feature     matrix and <code>y</code> is the target vector. If only numeric or categorical     columns are included in the output, return a pd.DataFrame instead of a     Bunch.</p>"},{"location":"reference/spotRiver/data/opm/#spotRiver.data.opm.fetch_opm--examples","title":"Examples","text":"<p>from spotRiver.data import fetch_opm     # Fetch the OPM dataset and return a pandas DataFrame     opm_df = fetch_opm()     # Fetch the OPM dataset, include categorical columns, and return a Bunch object     opm_data = fetch_opm(include_numeric=False, include_categorical=True, return_X_y=False)     # Fetch the OPM dataset, include numeric and categorical columns, and return a tuple of pandas DataFrames     X, y = fetch_opm(include_categorical=True, return_X_y=True)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/opm.py</code> <pre><code>def fetch_opm(\n    *,\n    data_home: Union[str, Path] = None,\n    download_if_missing: bool = True,\n    return_X_y: bool = False,\n    include_numeric: bool = True,\n    include_categorical: bool = False,\n) -&gt; Union[Tuple[pd.DataFrame, pd.Series], pd.DataFrame, Bunch]:\n\"\"\"Fetch the OPM dataset from the Connecticut Open Data portal.\n\n    Parameters\n    ----------\n    data_home : str or pathlib.Path, default=None\n        Specify another download and cache folder for the datasets. By default\n        all spotRiver data is stored in '~/spotriver_data' subfolders.\n    download_if_missing : bool, default=True\n        If False, raise an IOError if the data is not locally available\n        rather than trying to download the data from the source site.\n    return_X_y : bool, default=False\n        If True, return `(X, y)` instead of a `Bunch` object. See\n        `sklearn.utils.Bunch` for more information.\n    include_numeric : bool, default=True\n        If True, include numeric columns in the output. Numeric columns include\n        'List Year', 'Assessed Value', 'Sale Amount', 'Sales Ratio', 'lat', 'lon',\n        and 'timestamp_rec'.\n    include_categorical : bool, default=False\n        If True, include categorical columns in the output. Categorical columns\n        include 'Town', 'Address', 'Property Type', 'Residential Type',\n        'Non Use Code', 'Assessor Remarks', and 'OPM remarks'. Columns with fewer\n        than 200 unique values will be treated as categorical.\n\n    Returns\n    -------\n    Bunch or Tuple[pd.DataFrame, pd.Series] or pd.DataFrame\n        If `return_X_y` is False, return a `Bunch` object with the following\n        attributes:\n            * data : pd.DataFrame of shape (n_samples, n_features)\n                The feature matrix.\n            * target : pd.Series of shape (n_samples,)\n                The target vector.\n            * DESCR : str\n                A short description of the dataset.\n        If `return_X_y` is True, return a tuple `(X, y)` where `X` is the feature\n        matrix and `y` is the target vector. If only numeric or categorical\n        columns are included in the output, return a pd.DataFrame instead of a\n        Bunch.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from spotRiver.data import fetch_opm\n        # Fetch the OPM dataset and return a pandas DataFrame\n        opm_df = fetch_opm()\n        # Fetch the OPM dataset, include categorical columns, and return a Bunch object\n        opm_data = fetch_opm(include_numeric=False, include_categorical=True, return_X_y=False)\n        # Fetch the OPM dataset, include numeric and categorical columns, and return a tuple of pandas DataFrames\n        X, y = fetch_opm(include_categorical=True, return_X_y=True)\n    \"\"\"\n    filename = get_data_home(data_home=data_home) / \"opm_2001-2020.csv\"\n    if not filename.is_file():\n        if not download_if_missing:\n            raise IOError(\"Data not found and `download_if_missing` is False\")\n        logger.info(f\"Downloading OPM dataset to '{filename}'.\")\n        urlretrieve(url=OPM_URL, filename=filename)\n    # FIXME: Add hash check for download.\n\n    df = pd.read_csv(filename, dtype=OPM_DTYPE, parse_dates=[\"Date Recorded\"])\n\n    # Collect rows (observations) we want to keep and subset only once.\n    #\n    # This might look kind of ugly but is much more efficient than making copy\n    # after copy of the (largish) data frame `df`.\n    idx = (\n        (df[\"Date Recorded\"] &gt;= \"2001-09-30\")\n        &amp; (df[\"Assessed Value\"] &gt;= 2000)\n        &amp; (df[\"Assessed Value\"] &lt;= 1e8)\n        &amp; (df[\"Sale Amount\"] &gt;= 2000)\n        &amp; (df[\"Sale Amount\"] &lt;= 2e8)\n    )\n    logger.debug(f\"Removing {len(idx) - idx.sum()} rows for constraint violations.\")\n\n    # Now keep only those rows which we selected with `idx`, sort the values by\n    # the date on which they were recorded and then reset the index.\n    df = df.loc[idx].sort_values(by=\"Date Recorded\").reset_index(drop=True)\n\n    cols = []\n    if include_numeric:\n        # Extract latitude and longitude from Location field.\n        # Converting to float32 looses precision.\n        df[[\"lon\", \"lat\"]] = df[\"Location\"].str.extract(r\"POINT \\((-?\\d+\\.\\d+) (-?\\d+\\.\\d+)\\)\").astype(\"float\")\n\n        # Check if points are inside the bounding box for CT.\n        # Bounding box taken from https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/\n        outside_bbox = (\n            (df[\"lon\"] &lt; -73.727775) | (df[\"lon\"] &gt; -71.786994) | (df[\"lat\"] &lt; 40.980144) | (df[\"lat\"] &gt; 42.050587)\n        )\n        df.loc[outside_bbox, [\"lon\", \"lat\"]] = np.nan\n        logger.debug(f\"Found {outside_bbox.sum()} locations outside of CT's bounding box.\")\n\n        # Convert types to smaller types to save some space.\n        df[\"List Year\"] = df[\"List Year\"].astype(\"int16\")\n\n        # Add timestamp column by converting the Date Recorded to nanoseconds since epoch\n        # and divide by 1e9 to go from nanoseconds to seconds since epoch.\n        df[\"timestamp_rec\"] = df[\"Date Recorded\"].astype(\"int64\") // 1e9\n\n        # Converting `Assessed Value` to float32 changes 159 values\n        df[\"Assessed Value\"] = df[\"Assessed Value\"].astype(\"int32\")\n\n        # Converting `Assessed Value` to int32/float32 changes 175/222 values\n        # df[\"Sale Amount\"] = df[\"Sale Amount\"].astype(\"int32\")\n\n        cols.extend([\"List Year\", \"Assessed Value\", \"Sale Amount\", \"Sales Ratio\", \"lat\", \"lon\", \"timestamp_rec\"])\n\n    # FIXME: We probably want to invest some time into deriving more meaninfgul\n    # categorical variables from some of these. Especially the remarks columns\n    # would benefit from a BoW approach and the Address column really carries very\n    # little information.\n    if include_categorical:\n        categorical_columns = [\n            \"Town\",\n            \"Address\",\n            \"Property Type\",\n            \"Residential Type\",\n            \"Non Use Code\",\n            \"Assessor Remarks\",\n            \"OPM remarks\",\n        ]\n        cols.extend(categorical_columns)\n\n        for cat_col in categorical_columns:\n            df[cat_col] = df[cat_col].fillna(\"Unknown\")\n            # If there less than 200 unique values, convert to \"category\"\n            # instead of storing as a string to save space.\n            if df[cat_col].nunique() &lt; 200:\n                df[cat_col] = df[cat_col].astype(\"category\")\n\n    if len(cols) == 0:\n        raise Exception(\"No columns selected. Did you set both `include_numeric` and `include_categorical` to False?\")\n\n    X = df[cols]\n    # y = df[\"Sale Amount\"]\n    y = X.pop(\"Sale Amount\")\n\n    if return_X_y:\n        return (X, y)\n    return Bunch(data=X, target=y)\n</code></pre>"},{"location":"reference/spotRiver/data/river_hyper_dict/","title":"river_hyper_dict","text":""},{"location":"reference/spotRiver/data/river_hyper_dict/#spotRiver.data.river_hyper_dict.RiverHyperDict","title":"<code>RiverHyperDict</code>","text":"<p>         Bases: <code>base.FileConfig</code></p> <p>River hyperparameter dictionary.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/river_hyper_dict.py</code> <pre><code>class RiverHyperDict(base.FileConfig):\n\"\"\"River hyperparameter dictionary.\"\"\"\n\n    def __init__(self):\n        super().__init__(\n            filename=\"river_hyper_dict.json\",\n        )\n\n    def load(self):\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n</code></pre>"},{"location":"reference/spotRiver/data/synth/","title":"synth","text":"<p>Synthetic datasets.</p> <p>Each synthetic dataset is a stream generator. The benefit of using a generator is that they do not store the data and each data sample is generated on the fly. Except for a couple of methods, the majority of these methods are infinite data generators.</p>"},{"location":"reference/spotRiver/data/synth/#spotRiver.data.synth.SEA","title":"<code>SEA</code>","text":"<p>         Bases: <code>datasets.base.SyntheticDataset</code></p> <p>SEA synthetic dataset.</p> <p>Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream.</p> <ul> <li> <p>Variant 0: <code>True</code> if <code>att1 + att2 &gt; 8</code></p> </li> <li> <p>Variant 1: <code>True</code> if <code>att1 + att2 &gt; 9</code></p> </li> <li> <p>Variant 2: <code>True</code> if <code>att1 + att2 &gt; 7</code></p> </li> <li> <p>Variant 3: <code>True</code> if <code>att1 + att2 &gt; 9.5</code></p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>variant</code> <code>int</code> <p>The variant of the data stream to use. Can be 0, 1, 2, or 3.</p> <code>0</code> <code>noise</code> <code>float</code> <p>The probability of generating label noise.</p> <code>0.0</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>A generator of features and labels.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.data.synth import SEA\n    dataset = synth.SEA(variant=0, seed=42)\n    for x, y in dataset.take(5):\n        print(x, y)\n</code></pre> <p>{0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False</p> References <p>[1]: A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/synth/sea.py</code> <pre><code>class SEA(datasets.base.SyntheticDataset):\n\"\"\"SEA synthetic dataset.\n\n    Implementation of the data stream with abrupt drift described in [1]. Each observation is\n    composed of 3 features. Only the first two features are relevant. The target is binary, and is\n    positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to\n    choose from. Concept drift can be introduced by switching the threshold anytime during the\n    stream.\n\n    * **Variant 0**: `True` if `att1 + att2 &gt; 8`\n\n    * **Variant 1**: `True` if `att1 + att2 &gt; 9`\n\n    * **Variant 2**: `True` if `att1 + att2 &gt; 7`\n\n    * **Variant 3**: `True` if `att1 + att2 &gt; 9.5`\n\n    Args:\n        variant (int): The variant of the data stream to use. Can be 0, 1, 2, or 3.\n        noise (float): The probability of generating label noise.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        (Generator): A generator of features and labels.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.data.synth import SEA\n            dataset = synth.SEA(variant=0, seed=42)\n            for x, y in dataset.take(5):\n                print(x, y)\n    {0: 6.39426, 1: 0.25010, 2: 2.75029} False\n    {0: 2.23210, 1: 7.36471, 2: 6.76699} True\n    {0: 8.92179, 1: 0.86938, 2: 4.21921} True\n    {0: 0.29797, 1: 2.18637, 2: 5.05355} False\n    {0: 0.26535, 1: 1.98837, 2: 6.49884} False\n\n    References:\n        [1]: [A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.482.3991&amp;rep=rep1&amp;type=pdf)\n\n    \"\"\"\n\n    def __init__(self, variant=0, noise=0.0, seed: int = None):\n        super().__init__(n_features=3, task=datasets.base.BINARY_CLF)\n\n        if variant not in (0, 1, 2, 3):\n            raise ValueError(\"Unknown variant, possible choices are: 0, 1, 2, 3\")\n\n        self.variant = variant\n        self.noise = noise\n        self.seed = seed\n        self._threshold = {0: 8, 1: 9, 2: 7, 3: 9.5}[variant]\n\n    def __iter__(self):\n        rng = random.Random(self.seed)\n\n        while True:\n            x = {i: rng.uniform(0, 10) for i in range(3)}\n            y = x[0] + x[1] &gt; self._threshold\n\n            if self.noise and rng.random() &lt; self.noise:\n                y = not y\n\n            yield x, y\n\n    @property\n    def _repr_content(self):\n        return {**super()._repr_content, \"Variant\": str(self.variant)}\n</code></pre>"},{"location":"reference/spotRiver/data/synth/sea/","title":"sea","text":""},{"location":"reference/spotRiver/data/synth/sea/#spotRiver.data.synth.sea.SEA","title":"<code>SEA</code>","text":"<p>         Bases: <code>datasets.base.SyntheticDataset</code></p> <p>SEA synthetic dataset.</p> <p>Implementation of the data stream with abrupt drift described in [1]. Each observation is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to choose from. Concept drift can be introduced by switching the threshold anytime during the stream.</p> <ul> <li> <p>Variant 0: <code>True</code> if <code>att1 + att2 &gt; 8</code></p> </li> <li> <p>Variant 1: <code>True</code> if <code>att1 + att2 &gt; 9</code></p> </li> <li> <p>Variant 2: <code>True</code> if <code>att1 + att2 &gt; 7</code></p> </li> <li> <p>Variant 3: <code>True</code> if <code>att1 + att2 &gt; 9.5</code></p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>variant</code> <code>int</code> <p>The variant of the data stream to use. Can be 0, 1, 2, or 3.</p> <code>0</code> <code>noise</code> <code>float</code> <p>The probability of generating label noise.</p> <code>0.0</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>A generator of features and labels.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.data.synth import SEA\n    dataset = synth.SEA(variant=0, seed=42)\n    for x, y in dataset.take(5):\n        print(x, y)\n</code></pre> <p>{0: 6.39426, 1: 0.25010, 2: 2.75029} False {0: 2.23210, 1: 7.36471, 2: 6.76699} True {0: 8.92179, 1: 0.86938, 2: 4.21921} True {0: 0.29797, 1: 2.18637, 2: 5.05355} False {0: 0.26535, 1: 1.98837, 2: 6.49884} False</p> References <p>[1]: A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/data/synth/sea.py</code> <pre><code>class SEA(datasets.base.SyntheticDataset):\n\"\"\"SEA synthetic dataset.\n\n    Implementation of the data stream with abrupt drift described in [1]. Each observation is\n    composed of 3 features. Only the first two features are relevant. The target is binary, and is\n    positive if the sum of the features exceeds a certain threshold. There are 4 thresholds to\n    choose from. Concept drift can be introduced by switching the threshold anytime during the\n    stream.\n\n    * **Variant 0**: `True` if `att1 + att2 &gt; 8`\n\n    * **Variant 1**: `True` if `att1 + att2 &gt; 9`\n\n    * **Variant 2**: `True` if `att1 + att2 &gt; 7`\n\n    * **Variant 3**: `True` if `att1 + att2 &gt; 9.5`\n\n    Args:\n        variant (int): The variant of the data stream to use. Can be 0, 1, 2, or 3.\n        noise (float): The probability of generating label noise.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        (Generator): A generator of features and labels.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.data.synth import SEA\n            dataset = synth.SEA(variant=0, seed=42)\n            for x, y in dataset.take(5):\n                print(x, y)\n    {0: 6.39426, 1: 0.25010, 2: 2.75029} False\n    {0: 2.23210, 1: 7.36471, 2: 6.76699} True\n    {0: 8.92179, 1: 0.86938, 2: 4.21921} True\n    {0: 0.29797, 1: 2.18637, 2: 5.05355} False\n    {0: 0.26535, 1: 1.98837, 2: 6.49884} False\n\n    References:\n        [1]: [A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.482.3991&amp;rep=rep1&amp;type=pdf)\n\n    \"\"\"\n\n    def __init__(self, variant=0, noise=0.0, seed: int = None):\n        super().__init__(n_features=3, task=datasets.base.BINARY_CLF)\n\n        if variant not in (0, 1, 2, 3):\n            raise ValueError(\"Unknown variant, possible choices are: 0, 1, 2, 3\")\n\n        self.variant = variant\n        self.noise = noise\n        self.seed = seed\n        self._threshold = {0: 8, 1: 9, 2: 7, 3: 9.5}[variant]\n\n    def __iter__(self):\n        rng = random.Random(self.seed)\n\n        while True:\n            x = {i: rng.uniform(0, 10) for i in range(3)}\n            y = x[0] + x[1] &gt; self._threshold\n\n            if self.noise and rng.random() &lt; self.noise:\n                y = not y\n\n            yield x, y\n\n    @property\n    def _repr_content(self):\n        return {**super()._repr_content, \"Variant\": str(self.variant)}\n</code></pre>"},{"location":"reference/spotRiver/drift/drift_generator/","title":"drift_generator","text":""},{"location":"reference/spotRiver/drift/drift_generator/#spotRiver.drift.drift_generator.generate_drift","title":"<code>generate_drift(data, drift_values=[1.1, 10.0, 0.1, 1.1])</code>","text":"<p>Generates a drift array based on the number of rows in the input data and the specified drift values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pd.DataFrame or np.ndarray</code> <p>The input data.</p> required <code>drift_values</code> <code>list of float</code> <p>The drift values to use.</p> <code>[1.1, 10.0, 0.1, 1.1]</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>The generated drift array.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from spotRiver.drift.drift_generator import generate_drift\n&gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; generate_drift(data, drift_values=[1.1, 10.0, 0.1, 1.1])\narray([ 1.1, 10. ,  0.1,  1.1])\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/drift/drift_generator.py</code> <pre><code>def generate_drift(data: pd.DataFrame, drift_values=[1.1, 10.0, 0.1, 1.1]) -&gt; np.ndarray:\n\"\"\"\n    Generates a drift array based on the number of rows in the input data and the specified drift values.\n\n    Args:\n        data (pd.DataFrame or np.ndarray): The input data.\n        drift_values (list of float): The drift values to use.\n\n    Returns:\n        (np.ndarray): The generated drift array.\n\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from spotRiver.drift.drift_generator import generate_drift\n        &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6]])\n        &gt;&gt;&gt; generate_drift(data, drift_values=[1.1, 10.0, 0.1, 1.1])\n        array([ 1.1, 10. ,  0.1,  1.1])\n\n    \"\"\"\n    num_rows = data.shape[0]\n    num_drift_values = len(drift_values)\n    quotient, remain = divmod(num_rows, num_drift_values)\n\n    quotient_array = [value for value in drift_values for _ in range(quotient)]\n    remain_array = np.full(remain, drift_values[-1], dtype=float)\n\n    drift = np.concatenate([quotient_array, remain_array])\n    return drift\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/","title":"eval_bml","text":""},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.ResourceMonitor","title":"<code>ResourceMonitor</code>","text":"<p>A context manager for monitoring resource usage.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>A description of the resource usage. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ResourceMonitorError</code> <p>If the resource monitor is already tracing memory usage.</p> <p>Returns:</p> Type Description <code>ResourceMonitor</code> <p>A ResourceMonitor object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import time\n&gt;&gt;&gt; from spotRiver.evaluation.eval_bml import ResourceMonitor\n&gt;&gt;&gt; with ResourceMonitor() as rm:\n...     time.sleep(1)\n...     print(rm.result())\nResource usage:\n    Time [s]: 1.000000001\n    Memory [b]: 0.0\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>class ResourceMonitor:\n\"\"\"\n    A context manager for monitoring resource usage.\n    Args:\n        name (str, optional): A description of the resource usage. Defaults to None.\n    Raises:\n        (ResourceMonitorError): If the resource monitor is already tracing memory usage.\n    Returns:\n        (ResourceMonitor): A ResourceMonitor object.\n    Examples:\n        &gt;&gt;&gt; import time\n        &gt;&gt;&gt; from spotRiver.evaluation.eval_bml import ResourceMonitor\n        &gt;&gt;&gt; with ResourceMonitor() as rm:\n        ...     time.sleep(1)\n        ...     print(rm.result())\n        Resource usage:\n            Time [s]: 1.000000001\n            Memory [b]: 0.0\n    \"\"\"\n\n    def __init__(self, name: Optional[str] = None):\n        self.name = name\n        self.r_time = None\n        self.memory = None\n        self.current_memory = None\n        self.peak_memory = None\n        self._start = None\n\n    def __enter__(self):\n        if tracemalloc.is_tracing():\n            raise ResourceMonitorError(\"Already tracing memory usage!\")\n        tracemalloc.start()\n        tracemalloc.reset_peak()\n        self._start = time.perf_counter_ns()\n\n    def __exit__(self, type, value, traceback):\n        self.r_time = (time.perf_counter_ns() - self._start) / 1.0e9\n        _, peak = tracemalloc.get_traced_memory()\n        self.memory = peak / (1024 * 1024)\n        tracemalloc.stop()\n\n    def result(self):\n\"\"\" Returns a ResourceUsage object with the results of the resource monitor.\n        Raises:\n            (ResourceMonitorError):\n                If the resource monitor has not been used yet.\n        Returns:\n            (ResourceUsage):\n                A ResourceUsage object with the results of the resource monitor.\n        Examples:\n        &gt;&gt;&gt; from time import sleep\n        &gt;&gt;&gt; from spotRiver.evaluation.eval_bml import ResourceMonitor\n        &gt;&gt;&gt; with ResourceMonitor() as rm:\n        &gt;&gt;&gt; sleep(1)\n        &gt;&gt;&gt; print(rm.result())\n        Resource usage:\n            Time [s]: 1.000000001\n            Memory [b]: 0.0\n        \"\"\"\n        if self.r_time is None or self.memory is None:\n            raise ResourceMonitorError(\"No resources monitored yet.\")\n        return ResourceUsage(name=self.name, r_time=self.r_time, memory=self.memory)\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.ResourceMonitor.result","title":"<code>result()</code>","text":"<p>Returns a ResourceUsage object with the results of the resource monitor.</p> <p>Raises:</p> Type Description <code>ResourceMonitorError</code> <p>If the resource monitor has not been used yet.</p> <p>Returns:</p> Type Description <code>ResourceUsage</code> <p>A ResourceUsage object with the results of the resource monitor.</p> <p>Examples:</p> <p>from time import sleep from spotRiver.evaluation.eval_bml import ResourceMonitor with ResourceMonitor() as rm: sleep(1) print(rm.result())</p> Resource usage <p>Time [s]: 1.000000001 Memory [b]: 0.0</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def result(self):\n\"\"\" Returns a ResourceUsage object with the results of the resource monitor.\n    Raises:\n        (ResourceMonitorError):\n            If the resource monitor has not been used yet.\n    Returns:\n        (ResourceUsage):\n            A ResourceUsage object with the results of the resource monitor.\n    Examples:\n    &gt;&gt;&gt; from time import sleep\n    &gt;&gt;&gt; from spotRiver.evaluation.eval_bml import ResourceMonitor\n    &gt;&gt;&gt; with ResourceMonitor() as rm:\n    &gt;&gt;&gt; sleep(1)\n    &gt;&gt;&gt; print(rm.result())\n    Resource usage:\n        Time [s]: 1.000000001\n        Memory [b]: 0.0\n    \"\"\"\n    if self.r_time is None or self.memory is None:\n        raise ResourceMonitorError(\"No resources monitored yet.\")\n    return ResourceUsage(name=self.name, r_time=self.r_time, memory=self.memory)\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_bml_horizon","title":"<code>eval_bml_horizon(model, train, test, target_column, horizon, include_remainder=True, metric=None)</code>","text":"<p>Evaluate a machine learning model on a rolling horizon basis.</p> <p>This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>The model to be evaluated.</p> required <code>train</code> <code>pd.DataFrame</code> <p>The training data set.</p> required <code>test</code> <code>pd.DataFrame</code> <p>The testing data set.</p> required <code>target_column</code> <code>str</code> <p>The name of the column containing the target variable.</p> required <code>horizon</code> <code>int</code> <p>The number of steps ahead to forecast.</p> required <code>include_remainder</code> <code>bool</code> <p>Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True.</p> <code>True</code> <code>metric</code> <code>object</code> <p>An evaluation metric object that has an <code>evaluate</code> method. This metric will be used to evaluate the model\u2019s performance on the test dataset.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression()\n&gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n&gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n&gt;&gt;&gt; df_eval, df_true = eval_bml_horizon(model, train, test, \"y\", horizon=1)\n&gt;&gt;&gt; print(df_eval)\n      Metric  Memory (MB)  CompTime (s)\n0  0.000000          0.0           0.0\n1  0.000000          0.0           0.0\n...        ...          ...           ...\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def eval_bml_horizon(\n    model: object,\n    train: pd.DataFrame,\n    test: pd.DataFrame,\n    target_column: str,\n    horizon: int,\n    include_remainder: bool = True,\n    metric: object = None,\n) -&gt; tuple:\n\"\"\"\n    Evaluate a machine learning model on a rolling horizon basis.\n\n    This function evaluates a machine learning model on a rolling horizon basis.\n    The model is trained on the training data and then evaluated on the test data\n    using a given evaluation metric. The evaluation results are returned as a tuple\n    of two data frames. The first one contains evaluation metrics for each window.\n    The second one contains the true and predicted values for each observation in the test set.\n\n    Args:\n        model (object): The model to be evaluated.\n        train (pd.DataFrame): The training data set.\n        test (pd.DataFrame): The testing data set.\n        target_column (str): The name of the column containing the target variable.\n        horizon (int, optional): The number of steps ahead to forecast.\n        include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True.\n        metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset.\n    Returns:\n        tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.\n    Examples:\n        &gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n        &gt;&gt;&gt; model = LinearRegression()\n        &gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n        &gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n        &gt;&gt;&gt; df_eval, df_true = eval_bml_horizon(model, train, test, \"y\", horizon=1)\n        &gt;&gt;&gt; print(df_eval)\n              Metric  Memory (MB)  CompTime (s)\n        0  0.000000          0.0           0.0\n        1  0.000000          0.0           0.0\n        ...        ...          ...           ...\n\n    \"\"\"\n    # Check if metric is None or null and raise ValueError if it is\n    if metric is None:\n        raise ValueError(\"The 'metric' parameter must not be None or null.\")\n    # Reset index of train and test dataframes\n    train = train.reset_index(drop=True)\n    test = test.reset_index(drop=True)\n    # Initialize lists for predictions and differences\n    preds_list = []\n    diffs_list = []\n    # Fit the model on the training data\n    rm = ResourceMonitor()\n    with rm:\n        model.fit(train.loc[:, train.columns != target_column], train[target_column])\n    # Evaluate the model on empty arrays to get initial resource usage\n    df_eval = pd.DataFrame.from_dict(\n        [evaluate_model(y_true=np.array([]), y_pred=np.array([]), memory=rm.memory, r_time=rm.r_time, metric=metric)]\n    )\n    # If include_remainder is False, remove remainder rows from test dataframe\n    if include_remainder is False:\n        remainder = len(test) % horizon\n        if remainder &gt; 0:\n            test = test[:-remainder]\n    # Evaluate the model on batches of size horizon from the test dataframe\n    for batch_number, batch_df in test.groupby(np.arange(len(test)) // horizon):\n        rm = ResourceMonitor()\n        with rm:\n            preds = model.predict(batch_df.loc[:, batch_df.columns != target_column])\n        diffs = batch_df[target_column].values - preds\n        df_eval.loc[batch_number + 1] = pd.Series(\n            evaluate_model(\n                y_true=batch_df[target_column],\n                y_pred=preds,\n                memory=rm.memory,\n                r_time=rm.r_time,\n                metric=metric,\n            )\n        )\n        # Append predictions and differences to their respective lists\n        preds_list.append(preds)\n        diffs_list.append(diffs)\n    # Concatenate predictions and differences lists into series\n    series_preds = pd.Series(np.concatenate(preds_list))\n    series_diffs = pd.Series(np.concatenate(diffs_list))\n    # Create a dataframe with true values and add columns for predictions and differences\n    df_true = pd.DataFrame(test[target_column])\n    df_true[\"Prediction\"] = series_preds\n    df_true[\"Difference\"] = series_diffs\n    return df_eval, df_true\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_bml_landmark","title":"<code>eval_bml_landmark(model, train, test, target_column, horizon, include_remainder=True, metric=None)</code>","text":"<p>Evaluate a machine learning model on a rolling landmark basis.</p> <p>This function evaluates a machine learning model on a rolling landmark basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>The model to be evaluated.</p> required <code>train</code> <code>pd.DataFrame</code> <p>The training data set.</p> required <code>test</code> <code>pd.DataFrame</code> <p>The testing data set.</p> required <code>target_column</code> <code>str</code> <p>The name of the column containing the target variable.</p> required <code>horizon</code> <code>int</code> <p>The number of steps ahead to forecast.</p> required <code>include_remainder</code> <code>bool</code> <p>Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True.</p> <code>True</code> <code>metric</code> <code>object</code> <p>An evaluation metric object that has an <code>evaluate</code> method. This metric will be used to evaluate the model\u2019s performance on the test dataset.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression()\n&gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n&gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n&gt;&gt;&gt; df_eval, df_true = eval_bml_landmark(model, train, test, \"y\", horizon=1)\n&gt;&gt;&gt; print(df_eval)\n        Metric  Memory (MB)  CompTime (s)\n0  0.000000          0.0           0.0\n1  0.000000          0.0           0.0\n...        ...          ...           ...\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def eval_bml_landmark(\n    model: object,\n    train: pd.DataFrame,\n    test: pd.DataFrame,\n    target_column: str,\n    horizon: int,\n    include_remainder: bool = True,\n    metric: object = None,\n) -&gt; tuple:\n\"\"\"Evaluate a machine learning model on a rolling landmark basis.\n\n    This function evaluates a machine learning model on a rolling landmark basis.\n    The model is trained on the training data and then evaluated on the test data\n    using a given evaluation metric. The evaluation results are returned as a tuple\n    of two data frames. The first one contains evaluation metrics for each window.\n    The second one contains the true and predicted values for each observation in the test set.\n\n    Args:\n        model (object): The model to be evaluated.\n        train (pd.DataFrame): The training data set.\n        test (pd.DataFrame): The testing data set.\n        target_column (str): The name of the column containing the target variable.\n        horizon (int, optional): The number of steps ahead to forecast.\n        include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True.\n        metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset.\n    Returns:\n        tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.\n    Examples:\n        &gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n        &gt;&gt;&gt; model = LinearRegression()\n        &gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n        &gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n        &gt;&gt;&gt; df_eval, df_true = eval_bml_landmark(model, train, test, \"y\", horizon=1)\n        &gt;&gt;&gt; print(df_eval)\n                Metric  Memory (MB)  CompTime (s)\n        0  0.000000          0.0           0.0\n        1  0.000000          0.0           0.0\n        ...        ...          ...           ...\n\n    \"\"\"\n    train = train.reset_index(drop=True)\n    test = test.reset_index(drop=True)\n    series_preds = pd.Series(dtype=float)\n    series_diffs = pd.Series(dtype=float)\n    rm = ResourceMonitor()\n    with rm:\n        model.fit(train.loc[:, train.columns != target_column], train[target_column])\n    df_eval = pd.DataFrame.from_dict(\n        [evaluate_model(y_true=np.array([]), y_pred=np.array([]), memory=rm.memory, r_time=rm.r_time, metric=metric)]\n    )\n    if include_remainder is False:\n        rem = len(test) % horizon\n        if rem &gt; 0:\n            test = test[:-rem]\n    # Landmark Evaluation\n    for i, new_df in enumerate(gen_sliding_window(test, horizon)):\n        train = pd.concat([train, new_df], ignore_index=True)\n        rm = ResourceMonitor()\n        with rm:\n            preds = pd.Series(model.predict(new_df.loc[:, new_df.columns != target_column]))\n            model.fit(train.loc[:, train.columns != target_column], train[target_column])\n        diffs = new_df[target_column].values - preds\n        df_eval.loc[i + 1] = pd.Series(\n            evaluate_model(\n                y_true=new_df[target_column],\n                y_pred=preds,\n                memory=rm.memory,\n                r_time=rm.r_time,\n                metric=metric,\n            )\n        )\n        series_preds = pd.concat([series_preds, preds], ignore_index=True)\n        series_diffs = pd.concat([series_diffs, diffs], ignore_index=True)\n    df_true = pd.DataFrame(test[target_column])\n    df_true[\"Prediction\"] = series_preds\n    df_true[\"Difference\"] = series_diffs\n    return df_eval, df_true\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_bml_window","title":"<code>eval_bml_window(model, train, test, target_column, horizon, include_remainder=True, metric=None)</code>","text":"<p>Evaluate a model on a rolling window basis.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>The model to be evaluated.</p> required <code>train</code> <code>pd.DataFrame</code> <p>The training data set.</p> required <code>test</code> <code>pd.DataFrame</code> <p>The testing data set.</p> required <code>target_column</code> <code>str</code> <p>The name of the column containing the target variable.</p> required <code>horizon</code> <code>int</code> <p>The number of steps ahead to forecast.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple of two data frames. The first one contains evaluation metrics for each window.</p> <code>tuple</code> <p>The second one contains the true and predicted values for each observation in the test set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression()\n&gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n&gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n&gt;&gt;&gt; df_eval, df_true = eval_bml_window(model, train, test, \"y\", horizon=1)\n&gt;&gt;&gt; print(df_eval)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def eval_bml_window(\n    model: object,\n    train: pd.DataFrame,\n    test: pd.DataFrame,\n    target_column: str,\n    horizon: int,\n    include_remainder: bool = True,\n    metric: object = None,\n) -&gt; tuple:\n\"\"\"Evaluate a model on a rolling window basis.\n\n    Args:\n        model (object): The model to be evaluated.\n        train (pd.DataFrame): The training data set.\n        test (pd.DataFrame): The testing data set.\n        target_column (str): The name of the column containing the target variable.\n        horizon (int, optional): The number of steps ahead to forecast.\n\n    Returns:\n        tuple: A tuple of two data frames. The first one contains evaluation metrics for each window.\n        The second one contains the true and predicted values for each observation in the test set.\n\n    Examples:\n        &gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n        &gt;&gt;&gt; model = LinearRegression()\n        &gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n        &gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n        &gt;&gt;&gt; df_eval, df_true = eval_bml_window(model, train, test, \"y\", horizon=1)\n        &gt;&gt;&gt; print(df_eval)\n    \"\"\"\n    train = train.reset_index(drop=True)\n    test = test.reset_index(drop=True)\n    df_all = pd.concat([train, test], ignore_index=True)\n    series_preds = pd.Series(dtype=float)\n    series_diffs = pd.Series(dtype=float)\n    rm = ResourceMonitor()\n    with rm:\n        model.fit(train.loc[:, train.columns != target_column], train[target_column])\n    df_eval = pd.DataFrame.from_dict(\n        [evaluate_model(y_true=np.array([]), y_pred=np.array([]), memory=rm.memory, r_time=rm.r_time, metric=metric)]\n    )\n    if include_remainder is False:\n        rem = len(test) % horizon\n        if rem &gt; 0:\n            test = test[:-rem]\n    for i, (w_train, w_test) in enumerate(gen_horizon_shifted_window(df_all, len(train), horizon)):\n        rm = ResourceMonitor()\n        with rm:\n            model.fit(w_train.loc[:, w_train.columns != target_column], w_train[target_column])\n            preds = pd.Series(model.predict(w_test.loc[:, w_test.columns != target_column]))\n        diffs = w_test[target_column].values - preds\n        df_eval.loc[i + 1] = pd.Series(\n            evaluate_model(\n                y_true=w_test[target_column],\n                y_pred=preds,\n                memory=rm.memory,\n                r_time=rm.r_time,\n                metric=metric,\n            )\n        )\n\n        series_preds = pd.concat([series_preds, preds], ignore_index=True)\n        series_diffs = pd.concat([series_diffs, diffs], ignore_index=True)\n\n    df_true = pd.DataFrame(test[target_column])\n    df_true[\"Prediction\"] = series_preds\n    df_true[\"Difference\"] = series_diffs\n    return df_eval, df_true\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.eval_oml_horizon","title":"<code>eval_oml_horizon(model, train, test, target_column, horizon, include_remainder=True, metric=None, oml_grace_period=None)</code>","text":"<p>Evaluate a machine learning model on a rolling horizon basis.</p> <p>This function evaluates a machine learning model on a rolling horizon basis. The model is trained on the training data and then evaluated on the test data using a given evaluation metric. The evaluation results are returned as a tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>The model to be evaluated.</p> required <code>train</code> <code>pd.DataFrame</code> <p>The training data set.</p> required <code>test</code> <code>pd.DataFrame</code> <p>The testing data set.</p> required <code>target_column</code> <code>str</code> <p>The name of the column containing the target variable.</p> required <code>horizon</code> <code>int</code> <p>The number of steps ahead to forecast.</p> required <code>include_remainder</code> <code>bool</code> <p>Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True.</p> <code>True</code> <code>metric</code> <code>object</code> <p>An evaluation metric object that has an <code>evaluate</code> method. This metric will be used to evaluate the model\u2019s performance on the test dataset.</p> <code>None</code> <code>oml_grace_period</code> <code>int</code> <p>The number of observations to use for initial training. Defaults to None, in which case the horizon is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[pd.DataFrame, pd.DataFrame]</code> <p>A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression()\n&gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n&gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n&gt;&gt;&gt; df_eval, df_true = eval_oml_horizon(model, train, test, \"y\", horizon=1)\n&gt;&gt;&gt; print(df_eval)\n        Metric  Memory (MB)  CompTime (s)\n0  0.000000          0.0           0.0\n1  0.000000          0.0           0.0\n...        ...          ...           ...\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def eval_oml_horizon(\n    model: object,\n    train: pd.DataFrame,\n    test: pd.DataFrame,\n    target_column: str,\n    horizon: int,\n    include_remainder: bool = True,\n    metric: object = None,\n    oml_grace_period: int = None,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n\"\"\"\n    Evaluate a machine learning model on a rolling horizon basis.\n\n    This function evaluates a machine learning model on a rolling horizon basis.\n    The model is trained on the training data and then evaluated on the test data\n    using a given evaluation metric. The evaluation results are returned as a tuple\n    of two data frames. The first one contains evaluation metrics for each window.\n    The second one contains the true and predicted values for each observation in the test set.\n\n    Args:\n        model (object): The model to be evaluated.\n        train (pd.DataFrame): The training data set.\n        test (pd.DataFrame): The testing data set.\n        target_column (str): The name of the column containing the target variable.\n        horizon (int, optional): The number of steps ahead to forecast.\n        include_remainder (bool): Whether to include the remainder of the test dataframe if its length is not divisible by the horizon. Defaults to True.\n        metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset.\n        oml_grace_period (int, optional): The number of observations to use for initial training. Defaults to None, in which case the horizon is used.\n    Returns:\n        tuple: A tuple of two data frames. The first one contains evaluation metrics for each window. The second one contains the true and predicted values for each observation in the test set.\n    Examples:\n        &gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n        &gt;&gt;&gt; model = LinearRegression()\n        &gt;&gt;&gt; train = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [2, 4, 6]})\n        &gt;&gt;&gt; test = pd.DataFrame({\"x\": [4, 5], \"y\": [8, 10]})\n        &gt;&gt;&gt; df_eval, df_true = eval_oml_horizon(model, train, test, \"y\", horizon=1)\n        &gt;&gt;&gt; print(df_eval)\n                Metric  Memory (MB)  CompTime (s)\n        0  0.000000          0.0           0.0\n        1  0.000000          0.0           0.0\n        ...        ...          ...           ...\n    \"\"\"\n    # Check if metric is None or null and raise ValueError if it is\n    if metric is None:\n        raise ValueError(\"The 'metric' parameter must not be None or null.\")\n    if oml_grace_period is None:\n        oml_grace_period = horizon\n    train = train.reset_index(drop=True)\n    test = test.reset_index(drop=True)\n    if include_remainder is False:\n        rem = len(test) % horizon\n        if rem &gt; 0:\n            test = test[:-rem]\n    series_preds = pd.Series(dtype=float)\n    series_diffs = pd.Series(dtype=float)\n\n    # Initial Training on Train Data\n    # For OML, this is performed on a limited subset only (oml_grace_period).\n    train_X = train.loc[:, train.columns != target_column]\n    train_y = train[target_column]\n    train_X = train_X.tail(oml_grace_period)\n    train_y = train_y.tail(oml_grace_period)\n    rm = ResourceMonitor()\n    with rm:\n        for xi, yi in river_stream.iter_pandas(train_X, train_y):\n            # The following line returns y_pred, which is not used, therefore set to \"_\":\n            _ = model.predict_one(xi)\n            # metric = metric.update(yi, y_pred)\n            model = model.learn_one(xi, yi)\n    # TODO: Add error handling\n    # Return res_dict = {\"Metric\": score, \"Memory (MB)\": memory, \"CompTime (s)\": r_time}\n    df_eval = pd.DataFrame.from_dict(\n        [evaluate_model(y_true=np.array([]), y_pred=np.array([]), memory=rm.memory, r_time=rm.r_time, metric=metric)]\n    )\n    # Test Data Evaluation\n    for i, new_df in enumerate(gen_sliding_window(test, horizon)):\n        preds = []\n        test_X = new_df.loc[:, new_df.columns != target_column]\n        test_y = new_df[target_column]\n        rm = ResourceMonitor()\n        with rm:\n            for xi, yi in river_stream.iter_pandas(test_X, test_y):\n                pred = model.predict_one(xi)\n                preds.append(pred)  # This is falsly measured with the ResourceMonitor\n                model = model.learn_one(xi, yi)\n        preds = pd.Series(preds)\n        diffs = new_df[target_column].values - preds\n        df_eval.loc[i + 1] = pd.Series(\n            evaluate_model(\n                y_true=new_df[target_column],\n                y_pred=preds,\n                memory=rm.memory,\n                r_time=rm.r_time,\n                metric=metric,\n            )\n        )\n        series_preds = pd.concat([series_preds, preds], ignore_index=True)\n        series_diffs = pd.concat([series_diffs, diffs], ignore_index=True)\n    df_true = pd.DataFrame(test[target_column])\n    df_true[\"Prediction\"] = series_preds\n    df_true[\"Difference\"] = series_diffs\n    return df_eval, df_true\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.evaluate_model","title":"<code>evaluate_model(y_true, y_pred, memory, r_time, metric)</code>","text":"<p>Evaluate a machine learning model on a test dataset.</p> <p>This function evaluates a machine learning model on a test dataset using a given evaluation metric. The evaluation results are returned as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>np.ndarray</code> <p>A numpy array containing the true values.</p> required <code>y_pred</code> <code>np.ndarray</code> <p>A numpy array containing the predicted values.</p> required <code>memory</code> <code>float</code> <p>The memory usage of the model.</p> required <code>r_time</code> <code>float</code> <p>The computation time of the model.</p> required <code>metric</code> <code>object</code> <p>An evaluation metric object that has an <code>evaluate</code> method. This metric will be used to evaluate the model\u2019s performance on the test dataset.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the evaluation results.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.metrics import accuracy_score\n&gt;&gt;&gt; y_true = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 1, 1])\n&gt;&gt;&gt; memory = 0.0\n&gt;&gt;&gt; r_time = 0.0\n&gt;&gt;&gt; metric = accuracy_score\n&gt;&gt;&gt; evaluate_model(y_true, y_pred, memory, r_time, metric)\n{'Metric': 0.75, 'Memory (MB)': 0.0, 'CompTime (s)': 0.0}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def evaluate_model(y_true: np.ndarray,\n                   y_pred: np.ndarray,\n                   memory: float,\n                   r_time: float,\n                   metric) -&gt; dict:\n\"\"\"\n    Evaluate a machine learning model on a test dataset.\n\n    This function evaluates a machine learning model on a test dataset using a given evaluation metric.\n    The evaluation results are returned as a dictionary.\n\n    Args:\n        y_true (np.ndarray): A numpy array containing the true values.\n        y_pred (np.ndarray): A numpy array containing the predicted values.\n        memory (float): The memory usage of the model.\n        r_time (float): The computation time of the model.\n        metric (object): An evaluation metric object that has an `evaluate` method.\n            This metric will be used to evaluate the model's performance on the test dataset.\n    Returns:\n        dict: A dictionary containing the evaluation results.\n    Examples:\n        &gt;&gt;&gt; from sklearn.metrics import accuracy_score\n        &gt;&gt;&gt; y_true = np.array([0, 1, 0, 1])\n        &gt;&gt;&gt; y_pred = np.array([0, 1, 1, 1])\n        &gt;&gt;&gt; memory = 0.0\n        &gt;&gt;&gt; r_time = 0.0\n        &gt;&gt;&gt; metric = accuracy_score\n        &gt;&gt;&gt; evaluate_model(y_true, y_pred, memory, r_time, metric)\n        {'Metric': 0.75, 'Memory (MB)': 0.0, 'CompTime (s)': 0.0}\n    \"\"\"\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"y_true and y_pred must have the same size\")\n    if (len(y_true) == 0) or (len(y_pred) == 0):\n        res_dict = {\n            \"Metric\": None,\n            \"Memory (MB)\": memory,\n            \"CompTime (s)\": r_time,\n        }\n        return res_dict\n    score = metric(y_true, y_pred)\n    res_dict = {\"Metric\": score, \"Memory (MB)\": memory, \"CompTime (s)\": r_time}\n    return res_dict\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.gen_sliding_window","title":"<code>gen_sliding_window(df, horizon, include_remainder=True)</code>","text":"<p>Generates sliding windows of a given size from a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>The input DataFrame.</p> required <code>horizon</code> <code>int</code> <p>The size of the sliding window.</p> required <code>include_remainder</code> <code>bool</code> <p>Whether to include the remainder of the DataFrame if its length is not divisible by the horizon. Defaults to False.</p> <code>True</code> <p>Yields:</p> Type Description <code>pd.DataFrame</code> <p>A sliding window of the input DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n&gt;&gt;&gt; for window in gen_sliding_window(df, 2):\n...     print(window)\n   A  B\n0  1  4\n1  2  5\n   A  B\n2  3  6\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def gen_sliding_window(df: pd.DataFrame,\n                       horizon: int,\n                       include_remainder: bool = True\n                       ) -&gt; Generator[pd.DataFrame, None, None]:\n\"\"\"Generates sliding windows of a given size from a DataFrame.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        horizon (int): The size of the sliding window.\n        include_remainder (bool):\n            Whether to include the remainder of the DataFrame\n            if its length is not divisible by the horizon. Defaults to False.\n\n    Yields:\n        (pd.DataFrame):\n            A sliding window of the input DataFrame.\n\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n        &gt;&gt;&gt; for window in gen_sliding_window(df, 2):\n        ...     print(window)\n           A  B\n        0  1  4\n        1  2  5\n           A  B\n        2  3  6\n    \"\"\"\n    i = 0\n    while True:\n        subset = df[i * horizon : (i + 1) * horizon]\n        if len(subset) == 0:\n            break\n        elif len(subset) &lt; horizon:\n            if include_remainder:\n                yield subset\n            break\n        i += 1\n        yield subset\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.plot_bml_oml_horizon_metrics","title":"<code>plot_bml_oml_horizon_metrics(df_eval=None, df_labels=None, log_x=False, log_y=False, cumulative=True, grid=True, figsize=None, metric=None, filename=None, **kwargs)</code>","text":"<p>Plot evaluation metrics for machine learning models.</p> <p>This function plots the evaluation metrics for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the evaluation metrics for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis.</p> <p>Parameters:</p> Name Type Description Default <code>df_eval</code> <code>list[pd.DataFrame]</code> <p>A list of pandas dataframes containing the evaluation metrics for each model. Each dataframe should have an index column with the dataset name and three columns with the label names: e.g., \u201cMetric\u201d, \u201cCompTime (s)\u201d and \u201cMemory (MB)\u201d. If None, no plot is generated. Default is None.</p> <code>None</code> <code>df_labels</code> <code>list</code> <p>A list of strings containing the labels for each model. The length of this list should match the length of df_eval. If None, numeric indices are used as labels. Default is None.</p> <code>None</code> <code>log_x</code> <code>bool</code> <p>A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False.</p> <code>False</code> <code>log_y</code> <code>bool</code> <p>A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False.</p> <code>False</code> <code>cumulative</code> <code>bool</code> <p>A flag indicating whether to plot cumulative metrics. If True, cumulative metrics are plotted. If False, non-cumulative metrics are plotted. Default is True.</p> <code>True</code> <code>grid</code> <code>bool</code> <p>A flag indicating whether to plot a grid. If True, grid is shown. Default is True.</p> <code>True</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure. Default is None.</p> <code>None</code> <code>metric</code> <code>object</code> <p>An evaluation metric object that has an <code>evaluate</code> method. This metric will be used to evaluate the model\u2019s performance on the test dataset.</p> <code>None</code> <code>filename</code> <code>str</code> <p>The name of the file to save the plot to. If None, the plot is not saved. Default is None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the plot function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NoneType</code> <p>This function does not return anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.metrics import accuracy_score\n&gt;&gt;&gt; from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics\n&gt;&gt;&gt; df_eval = pd.DataFrame({\"Metric\": [0.5, 0.75, 0.9], \"CompTime (s)\": [0.1, 0.2, 0.3], \"Memory (MB)\": [0.1, 0.2, 0.3]})\n&gt;&gt;&gt; df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"]\n&gt;&gt;&gt; plot_bml_oml_horizon_metrics(df_eval, df_labels, metric=accuracy_score)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def plot_bml_oml_horizon_metrics(\n    df_eval: list[pd.DataFrame] = None,\n    df_labels: list = None,\n    log_x=False,\n    log_y=False,\n    cumulative=True,\n    grid=True,\n    figsize=None,\n    metric=None,\n    filename=None,\n    **kwargs,\n) -&gt; None:\n\"\"\"Plot evaluation metrics for machine learning models.\n\n    This function plots the evaluation metrics for different machine learning models\n    on a given dataset. The function takes a list of pandas dataframes as input,\n    each containing the evaluation metrics for one model. The function also takes\n    an optional list of labels for each model and boolean flags to indicate whether\n    to use logarithmic scales for the x-axis and y-axis.\n\n    Args:\n        df_eval (list[pd.DataFrame], optional): A list of pandas dataframes containing the evaluation metrics for each model. Each dataframe should have an index column with the dataset name and three columns with the label names: e.g., \"Metric\", \"CompTime (s)\" and \"Memory (MB)\". If None, no plot is generated. Default is None.\n        df_labels (list, optional): A list of strings containing the labels for each model. The length of this list should match the length of df_eval. If None, numeric indices are used as labels. Default is None.\n        log_x (bool, optional): A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False.\n        log_y (bool, optional): A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False.\n        cumulative (bool, optional): A flag indicating whether to plot cumulative metrics. If True, cumulative metrics are plotted. If False, non-cumulative metrics are plotted. Default is True.\n        grid (bool, optional): A flag indicating whether to plot a grid. If True, grid is shown. Default is True.\n        figsize (tuple, optional): The size of the figure. Default is None.\n        metric (object): An evaluation metric object that has an `evaluate` method. This metric will be used to evaluate the model's performance on the test dataset.\n        filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Default is None.\n        **kwargs (Any): Additional keyword arguments to be passed to the plot function.\n\n    Returns:\n        (NoneType): This function does not return anything.\n\n    Examples:\n        &gt;&gt;&gt; from sklearn.metrics import accuracy_score\n        &gt;&gt;&gt; from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics\n        &gt;&gt;&gt; df_eval = pd.DataFrame({\"Metric\": [0.5, 0.75, 0.9], \"CompTime (s)\": [0.1, 0.2, 0.3], \"Memory (MB)\": [0.1, 0.2, 0.3]})\n        &gt;&gt;&gt; df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"]\n        &gt;&gt;&gt; plot_bml_oml_horizon_metrics(df_eval, df_labels, metric=accuracy_score)\n    \"\"\"\n    if figsize is None:\n        figsize = (10, 5)\n    # Check if metric is None or null and raise ValueError if it is\n    if metric is None:\n        raise ValueError(\"The 'metric' parameter must not be None or null.\")\n    # Check if input dataframes are provided\n    if df_eval is not None:\n        df_list = copy.deepcopy(df_eval)\n        # Convert single dataframe input to a list if needed\n        if df_list.__class__ != list:\n            df_list = [df_list]\n        # Define metric names and titles\n        metric_name = metric.__name__\n        metrics = [\"Metric\", \"CompTime (s)\", \"Memory (MB)\"]\n        titles = [metric_name, \"Computation time (s)\", \"Memory (MB)\"]\n        # Create subplots with shared x-axis\n        fig, axes = plt.subplots(3, figsize=figsize, constrained_layout=True, sharex=True)\n        # Loop over each dataframe in input list\n        for j, df in enumerate(df_list):\n            if cumulative:\n                # df.MAE = np.cumsum(df.MAE) / range(1, (1 + df.MAE.size))\n                df[\"Metric\"] = np.cumsum(df[\"Metric\"]) / range(1, (1 + df[\"Metric\"].size))\n                df[\"CompTime (s)\"] = np.cumsum(df[\"CompTime (s)\"])  # / range(1, (1 + df[\"CompTime (s)\"].size))\n                # df[\"Memory (MB)\"] = np.cumsum(df[\"Memory (MB)\"]) / range(1, (1 + df[\"Memory (MB)\"].size))\n            # Loop over each metric\n            for i in range(3):\n                # Assign label based on input or default value\n                if df_labels is None:\n                    label = f\"{j}\"\n                else:\n                    label = df_labels[j]\n                # Plot metric values against dataset names\n                axes[i].plot(df.index.values.tolist(), df[metrics[i]].values.tolist(), label=label, **kwargs)\n                # Set title and legend\n                axes[i].set_title(titles[i])\n                axes[i].legend(loc=\"upper right\")\n                axes[i].grid(grid)\n                # Set logarithmic scales if specified\n                if log_x:\n                    axes[i].set_xscale(\"log\")\n                if log_y:\n                    axes[i].set_yscale(\"log\")\n        if filename is not None:\n            plt.savefig(filename)\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_bml/#spotRiver.evaluation.eval_bml.plot_bml_oml_horizon_predictions","title":"<code>plot_bml_oml_horizon_predictions(df_true=None, df_labels=None, target_column='Actual', log_x=False, log_y=False, skip_first_n=0, grid=True, figsize=None, filename=None, **kwargs)</code>","text":"<p>Plot actual vs predicted values for machine learning models.</p> <p>This function plots the actual vs predicted values for different machine learning models on a given dataset. The function takes a list of pandas dataframes as input, each containing the actual and predicted values for one model. The function also takes an optional list of labels for each model and boolean flags to indicate whether to use logarithmic scales for the x-axis and y-axis.</p> <p>Parameters:</p> Name Type Description Default <code>df_true</code> <code>list[pd.DataFrame]</code> <p>A list of pandas dataframes containing the actual and predicted values for each model. Each dataframe should have an index column with the dataset name and two columns with the label names: e.g., \u201cActual\u201d and \u201cPrediction\u201d. If None, no plot is generated. Default is None.</p> <code>None</code> <code>df_labels</code> <code>list</code> <p>A list of strings containing the labels for each model. The length of this list should match the length of df_true. If None, numeric indices are used as labels. Default is None.</p> <code>None</code> <code>target_column</code> <code>str</code> <p>The name of the column containing the target variable. Default is \u201cActual\u201d.</p> <code>'Actual'</code> <code>log_x</code> <code>bool</code> <p>A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False.</p> <code>False</code> <code>log_y</code> <code>bool</code> <p>A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False.</p> <code>False</code> <code>skip_first_n</code> <code>int</code> <p>The number of rows to skip from the beginning of the dataframes. Default is 0.</p> <code>0</code> <code>grid</code> <code>bool</code> <p>A flag indicating whether to plot a grid. If True, grid is shown. Default is True.</p> <code>True</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure. Default is None.</p> <code>None</code> <code>filename</code> <code>str</code> <p>The name of the file to save the plot to. If None, the plot is not saved. Default is None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the plot function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NoneType</code> <p>This function does not return anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.metrics import accuracy_score\n&gt;&gt;&gt; from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions\n&gt;&gt;&gt; df_true = pd.DataFrame({\"Actual\": [0.5, 0.75, 0.9], \"Prediction\": [0.1, 0.2, 0.3]})\n&gt;&gt;&gt; df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"]\n&gt;&gt;&gt; plot_bml_oml_horizon_predictions(df_true, df_labels, target_column=\"Actual\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_bml.py</code> <pre><code>def plot_bml_oml_horizon_predictions(\n    df_true: list[pd.DataFrame] = None,\n    df_labels: list = None,\n    target_column: str = \"Actual\",\n    log_x=False,\n    log_y=False,\n    skip_first_n=0,\n    grid=True,\n    figsize: tuple = None,\n    filename=None,\n    **kwargs,\n) -&gt; None:\n\"\"\" Plot actual vs predicted values for machine learning models.\n\n    This function plots the actual vs predicted values for different machine learning models\n    on a given dataset. The function takes a list of pandas dataframes as input,\n    each containing the actual and predicted values for one model. The function also takes\n    an optional list of labels for each model and boolean flags to indicate whether\n    to use logarithmic scales for the x-axis and y-axis.\n\n    Args:\n        df_true (list[pd.DataFrame], optional): A list of pandas dataframes containing the actual and predicted values for each model. Each dataframe should have an index column with the dataset name and two columns with the label names: e.g., \"Actual\" and \"Prediction\". If None, no plot is generated. Default is None.\n        df_labels (list, optional): A list of strings containing the labels for each model. The length of this list should match the length of df_true. If None, numeric indices are used as labels. Default is None.\n        target_column (str, optional): The name of the column containing the target variable. Default is \"Actual\".\n        log_x (bool, optional): A flag indicating whether to use logarithmic scale for the x-axis. If True, log scale is used. If False, linear scale is used. Default is False.\n        log_y (bool, optional): A flag indicating whether to use logarithmic scale for the y-axis. If True, log scale is used. If False, linear scale is used. Default is False.\n        skip_first_n (int, optional): The number of rows to skip from the beginning of the dataframes. Default is 0.\n        grid (bool, optional): A flag indicating whether to plot a grid. If True, grid is shown. Default is True.\n        figsize (tuple, optional): The size of the figure. Default is None.\n        filename (str, optional): The name of the file to save the plot to. If None, the plot is not saved. Default is None.\n        **kwargs (Any): Additional keyword arguments to be passed to the plot function.\n\n    Returns:\n        (NoneType): This function does not return anything.\n\n    Examples:\n        &gt;&gt;&gt; from sklearn.metrics import accuracy_score\n        &gt;&gt;&gt; from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions\n        &gt;&gt;&gt; df_true = pd.DataFrame({\"Actual\": [0.5, 0.75, 0.9], \"Prediction\": [0.1, 0.2, 0.3]})\n        &gt;&gt;&gt; df_labels = [\"Model 1\", \"Model 2\", \"Model 3\"]\n        &gt;&gt;&gt; plot_bml_oml_horizon_predictions(df_true, df_labels, target_column=\"Actual\")\n\n    \"\"\"\n    if figsize is None:\n        figsize = (10, 5)\n    if df_true is not None:\n        df_plot = copy.deepcopy(df_true)\n        if df_plot.__class__ != list:\n            df_plot = [df_plot]\n        plt.figure(figsize=figsize)\n        for j, df in enumerate(df_plot):\n            if df_labels is None:\n                label = f\"{j}\"\n            else:\n                label = df_labels[j]\n            df.loc[: skip_first_n - 1, \"Prediction\"] = np.nan\n            plt.plot(df.index, df[\"Prediction\"], label=label, **kwargs)\n        plt.plot(df_plot[0].index, df_plot[0][target_column], label=\"Actual\", color=\"black\", **kwargs)\n        plt.title(\"Actual vs Prediction\")\n        if log_x:\n            plt.xscale(\"log\")\n        if log_y:\n            plt.yscale(\"log\")\n        plt.grid(grid)\n        plt.legend()\n        if filename is not None:\n            plt.savefig(filename)\n    plt.show()\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_nowcast/","title":"eval_nowcast","text":""},{"location":"reference/spotRiver/evaluation/eval_nowcast/#spotRiver.evaluation.eval_nowcast.eval_nowcast_model","title":"<code>eval_nowcast_model(model, dataset, time_interval='month', window_size=12)</code>","text":"<p>Evaluates a time series model using a rolling mean absolute error metric.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>river.time_series</code> <p>A predictor object (river.time_series) that implements the forecast and learn_one methods.</p> required <code>dataset</code> <code>object</code> <p>A dataset object that contains the time series data.</p> required <code>time_interval</code> <code>str</code> <p>The name of the attribute that contains the date information in the dataset.</p> <code>'month'</code> <code>window_size</code> <code>int</code> <p>The number of observations to use for calculating the rolling metric.</p> <code>12</code> <p>Returns:</p> Type Description <code>Tuple[List, utils.Rolling, List, List]</code> <p>Tuple[List, utils.Rolling, List, List]: A tuple of four lists: - dates: The dates corresponding to each observation in the dataset. - metric: A rolling metric object that contains the mean absolute error values. - y_trues: The true values of the target variable in the dataset. - y_preds: The predicted values of the target variable by the model.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from river import compose\n    from river import linear_model\n    from river import preprocessing, datasets, utils, metrics\n    import matplotlib.pyplot as plt\n    from spotRiver.utils.features import get_ordinal_date\n    from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n</code></pre> <pre><code>model = compose.Pipeline(\n    ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n    ('scale', preprocessing.StandardScaler()),\n    ('lin_reg', linear_model.LinearRegression())\n)\ndataset = datasets.AirlinePassengers()\ndates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset)\nplot_nowcast_model(dates, metric, y_trues, y_preds)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_nowcast.py</code> <pre><code>def eval_nowcast_model(model, dataset, time_interval: str = \"month\", window_size: int = 12) -&gt; Tuple[List, utils.Rolling, List, List]:\n\"\"\"\n    Evaluates a time series model using a rolling mean absolute error metric.\n\n    Args:\n        model (river.time_series): A predictor object (river.time_series) that implements the forecast and learn_one methods.\n        dataset (object): A dataset object that contains the time series data.\n        time_interval (str): The name of the attribute that contains the date information in the dataset.\n        window_size (int): The number of observations to use for calculating the rolling metric.\n\n    Returns:\n        Tuple[List, utils.Rolling, List, List]: A tuple of four lists:\n            - dates: The dates corresponding to each observation in the dataset.\n            - metric: A rolling metric object that contains the mean absolute error values.\n            - y_trues: The true values of the target variable in the dataset.\n            - y_preds: The predicted values of the target variable by the model.\n\n    Examples:\n        &gt;&gt;&gt; from river import compose\n            from river import linear_model\n            from river import preprocessing, datasets, utils, metrics\n            import matplotlib.pyplot as plt\n            from spotRiver.utils.features import get_ordinal_date\n            from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n\n            model = compose.Pipeline(\n                ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n                ('scale', preprocessing.StandardScaler()),\n                ('lin_reg', linear_model.LinearRegression())\n            )\n            dataset = datasets.AirlinePassengers()\n            dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset)\n            plot_nowcast_model(dates, metric, y_trues, y_preds)\n    \"\"\"\n    metric = utils.Rolling(obj=metrics.MAE(), window_size=window_size)\n    dates = []\n    y_trues = []\n    y_preds = []\n    for x, y in dataset:\n        # Obtain the prior prediction and update the model in one go\n        y_pred = model.predict_one(x)\n        model.learn_one(x, y)\n        # Update the error metric\n        metric.update(y, y_pred)\n        # Store the true value and the prediction\n        dates.append(x[time_interval])\n        y_trues.append(y)\n        y_preds.append(y_pred)\n    return dates, metric, y_trues, y_preds\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_nowcast/#spotRiver.evaluation.eval_nowcast.plot_nowcast_model","title":"<code>plot_nowcast_model(dates, metric, y_trues, y_preds, range=None)</code>","text":"<p>Plots the true values and the predictions of a nowcast model along with a rolling metric.</p> <p>Parameters:</p> Name Type Description Default <code>dates</code> <code>List[str]</code> <p>A list of strings that contains the dates corresponding to each observation.</p> required <code>metric</code> <code>utils.Rolling</code> <p>A rolling metric object that contains the mean absolute error values.</p> required <code>y_trues</code> <code>List[float]</code> <p>A list of floats that contains the true values of the target variable.</p> required <code>y_preds</code> <code>List[float]</code> <p>A list of floats that contains the predicted values of the target variable.</p> required <code>range</code> <code>List[int]</code> <p>A list of 2 int that specify the subset.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None. Displays a matplotlib figure with two lines and a title.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_nowcast.py</code> <pre><code>def plot_nowcast_model(\n    dates: List[str], metric: utils.Rolling, y_trues: List[float], y_preds: List[float], range: List[int] = None\n) -&gt; None:\n\"\"\"\n    Plots the true values and the predictions of a nowcast model along with a rolling metric.\n\n    Parameters:\n        dates: A list of strings that contains the dates corresponding to each observation.\n        metric: A rolling metric object that contains the mean absolute error values.\n        y_trues: A list of floats that contains the true values of the target variable.\n        y_preds: A list of floats that contains the predicted values of the target variable.\n        range: A list of 2 int that specify the subset.\n\n    Returns:\n        None. Displays a matplotlib figure with two lines and a title.\n    \"\"\"\n    # Create a figure and an axis object\n    fig, ax = plt.subplots(figsize=(10, 6))\n    # Add grid lines to the plot\n    ax.grid(alpha=0.75)\n    if range is not None:\n        dates = dates[range[0] : range[1]]\n        y_preds = y_preds[range[0] : range[1]]\n        y_trues = y_trues[range[0] : range[1]]\n    # Plot the true values and the predictions with different colors and labels\n    ax.plot(dates, y_trues, lw=3, color=\"#2ecc71\", alpha=0.8, label=\"Ground truth\")\n    ax.plot(dates, y_preds, lw=3, color=\"#e74c3c\", alpha=0.8, label=\"Prediction\")\n    # Add a legend to show the labels\n    ax.legend()\n    # Set the title of the plot to be the rolling metric\n    ax.set_title(metric)\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_oml/","title":"eval_oml","text":""},{"location":"reference/spotRiver/evaluation/eval_oml/#spotRiver.evaluation.eval_oml.eval_oml_iter_progressive","title":"<code>eval_oml_iter_progressive(dataset, metric, models, step=100, weight_coeff=0.0, log_level=50)</code>","text":"<p>Evaluate OML Models on Streaming Data</p> <p>This function evaluates one or more OML models on a streaming dataset. The evaluation is done iteratively, and the models are tested every <code>step</code> iterations. The results are returned as a dictionary of metrics and their values.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>list or river.Stream</code> <p>A list of river.Stream objects containing the streaming data to be evaluated. If a single river.Stream object is provided, it is automatically converted to a list.</p> required <code>metric</code> <code>river.metrics.base.MultiClassMetric or river.metrics.base.RegressionMetric</code> <p>The metric to be used for evaluation.</p> required <code>models</code> <code>dict</code> <p>A dictionary of OML models to be evaluated. The keys are the names of the models, and the values are the model objects.</p> required <code>step</code> <code>int</code> <p>Iteration number at which to yield results. This only takes into account the predictions, and not the training steps. Defaults to 100.</p> <code>100</code> <code>weight_coeff</code> <code>float</code> <p>Results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff &gt; 1. If weight_coeff == 0, then results are multiplied by 1 and every result has an equal weight. Defaults to 0.0.</p> <code>0.0</code> <code>log_level</code> <code>int</code> <p>The level of logging to use. 0 = no logging, 50 = print only important information. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the evaluation results. The keys are the names of the models, and the values are dictionaries with the following keys: - \u201cstep\u201d: A list of iteration numbers at which the model was evaluated. - \u201cerror\u201d: A list of the weighted errors for each iteration. - \u201cr_time\u201d: A list of the weighted running times for each iteration. - \u201cmemory\u201d: A list of the weighted memory usages for each iteration. - \u201cmetric_name\u201d: The name of the metric used for evaluation.</p> Reference <p>https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from river import compose\n    from river import linear_model\n    from river import preprocessing, datasets, utils, metrics\n    import matplotlib.pyplot as plt\n    from spotRiver.utils.features import get_ordinal_date\n    from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n    model = compose.Pipeline(\n        ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n        ('scale', preprocessing.StandardScaler()),\n        ('lin_reg', linear_model.LinearRegression())\n    )\n    dataset = datasets.AirlinePassengers()\n    dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset)\n    plot_nowcast_model(dates, metric, y_trues, y_preds)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_oml.py</code> <pre><code>def eval_oml_iter_progressive(dataset, metric, models, step=100, weight_coeff=0.0, log_level=50):\n\"\"\"Evaluate OML Models on Streaming Data\n\n    This function evaluates one or more OML models on a streaming dataset. The evaluation\n    is done iteratively, and the models are tested every `step` iterations. The results\n    are returned as a dictionary of metrics and their values.\n\n    Args:\n        dataset (list or river.Stream): A list of river.Stream objects containing the\n            streaming data to be evaluated. If a single river.Stream object is provided,\n            it is automatically converted to a list.\n        metric (river.metrics.base.MultiClassMetric or river.metrics.base.RegressionMetric):\n            The metric to be used for evaluation.\n        models (dict): A dictionary of OML models to be evaluated. The keys are the names\n            of the models, and the values are the model objects.\n        step (int): Iteration number at which to yield results. This only takes into account\n            the predictions, and not the training steps. Defaults to 100.\n        weight_coeff (float): Results are multiplied by (step/n_steps)**weight_coeff,\n            where n_steps is the total number of iterations. Results from the beginning have\n            a lower weight than results from the end if weight_coeff &gt; 1. If weight_coeff == 0,\n            then results are multiplied by 1 and every result has an equal weight. Defaults to 0.0.\n        log_level (int): The level of logging to use. 0 = no logging, 50 = print only important\n            information. Defaults to 50.\n\n    Returns:\n        (dict): A dictionary containing the evaluation results. The keys are the names of the\n            models, and the values are dictionaries with the following keys:\n            - \"step\": A list of iteration numbers at which the model was evaluated.\n            - \"error\": A list of the weighted errors for each iteration.\n            - \"r_time\": A list of the weighted running times for each iteration.\n            - \"memory\": A list of the weighted memory usages for each iteration.\n            - \"metric_name\": The name of the metric used for evaluation.\n\n    Reference:\n        https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/\n\n    Examples:\n        &gt;&gt;&gt; from river import compose\n            from river import linear_model\n            from river import preprocessing, datasets, utils, metrics\n            import matplotlib.pyplot as plt\n            from spotRiver.utils.features import get_ordinal_date\n            from spotRiver.evaluation.eval_nowcast import eval_nowcast_model, plot_nowcast_model\n            model = compose.Pipeline(\n                ('ordinal_date', compose.FuncTransformer(get_ordinal_date)),\n                ('scale', preprocessing.StandardScaler()),\n                ('lin_reg', linear_model.LinearRegression())\n            )\n            dataset = datasets.AirlinePassengers()\n            dates, metric, y_trues, y_preds = eval_nowcast_model(model, dataset=dataset)\n            plot_nowcast_model(dates, metric, y_trues, y_preds)\n\n    \"\"\"\n    metric_name = metric.__class__.__name__\n    # Convert dataset to a list if needed\n    if dataset.__class__ != list:\n        dataset = [dataset]\n    n_steps = len(dataset)\n    result = {}\n    for model_name, model in models.items():\n        result_i = {\"step\": [], \"error\": [], \"r_time\": [], \"memory\": []}\n        for checkpoint in iter_progressive_val_score(\n            dataset, model, metric, measure_time=True, measure_memory=True, step=step\n        ):\n            if log_level &lt;= 20:\n                progress_bar(checkpoint[\"Step\"] / n_steps, message=\"Eval iter_prog_val_score:\")\n            w = (checkpoint[\"Step\"] / n_steps) ** weight_coeff\n            result_i[\"step\"].append(checkpoint[\"Step\"])\n            result_i[\"error\"].append(w * checkpoint[metric_name].get())\n            # Convert timedelta object into seconds\n            result_i[\"r_time\"].append(w * checkpoint[\"Time\"].total_seconds())\n            # Make sure the memory measurements are in MB\n            raw_memory = checkpoint[\"Memory\"]\n            result_i[\"memory\"].append(w * raw_memory * 2**-20)\n        result_i[\"metric_name\"] = metric_name\n        result[model_name] = result_i\n    return result\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_oml/#spotRiver.evaluation.eval_oml.fun_eval_oml_iter_progressive","title":"<code>fun_eval_oml_iter_progressive(result, metric=None, weights=None)</code>","text":"<p>Wrapper function for eval_oml_iter_progressive, returning a single function value.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>dict</code> <p>A dictionary of evaluation results, as returned by eval_oml_iter_progressive.</p> required <code>metric</code> <code>function</code> <p>The metric function to use for computing the function value. Defaults to None, in which case the mean function is used.</p> <code>None</code> <code>weights</code> <code>numpy.array</code> <p>An array of weights for error, r_time, and memory. If None, the weights are set to [1, 0, 0], which considers only the error. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>numpy.array</code> <p>An array of function values, one for each model in the evaluation results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the weights array is not of length 3.</p> Reference <p>https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive\n</code></pre> <pre><code>&gt;&gt;&gt; result = {\n...     \"model1\": {\n...         \"step\": [1, 2, 3],\n...         \"error\": [0.1, 0.2, 0.3],\n...         \"r_time\": [0.1, 0.2, 0.3],\n...         \"memory\": [0.1, 0.2, 0.3],\n...         \"metric_name\": \"MAE\"\n...     },\n...     \"model2\": {\n...         \"step\": [1, 2, 3],\n...         \"error\": [0.2, 0.3, 0.4],\n...         \"r_time\": [0.2, 0.3, 0.4],\n...         \"memory\": [0.2, 0.3, 0.4],\n...         \"metric_name\": \"MAE\"\n...     }\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; fun_eval_oml_iter_progressive(result)\narray([0.1, 0.2])\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_oml.py</code> <pre><code>def fun_eval_oml_iter_progressive(result, metric=None, weights=None):\n\"\"\"Wrapper function for eval_oml_iter_progressive, returning a single function value.\n\n    Args:\n        result (dict): A dictionary of evaluation results, as returned by eval_oml_iter_progressive.\n        metric (function, optional): The metric function to use for computing the function value.\n            Defaults to None, in which case the mean function is used.\n        weights (numpy.array, optional): An array of weights for error, r_time, and memory.\n            If None, the weights are set to [1, 0, 0], which considers only the error.\n            Defaults to None.\n\n    Returns:\n        (numpy.array): An array of function values, one for each model in the evaluation results.\n\n    Raises:\n        ValueError: If the weights array is not of length 3.\n\n    Reference:\n        https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.evaluation.eval_oml import fun_eval_oml_iter_progressive\n\n        &gt;&gt;&gt; result = {\n        ...     \"model1\": {\n        ...         \"step\": [1, 2, 3],\n        ...         \"error\": [0.1, 0.2, 0.3],\n        ...         \"r_time\": [0.1, 0.2, 0.3],\n        ...         \"memory\": [0.1, 0.2, 0.3],\n        ...         \"metric_name\": \"MAE\"\n        ...     },\n        ...     \"model2\": {\n        ...         \"step\": [1, 2, 3],\n        ...         \"error\": [0.2, 0.3, 0.4],\n        ...         \"r_time\": [0.2, 0.3, 0.4],\n        ...         \"memory\": [0.2, 0.3, 0.4],\n        ...         \"metric_name\": \"MAE\"\n        ...     }\n        ... }\n\n        &gt;&gt;&gt; fun_eval_oml_iter_progressive(result)\n        array([0.1, 0.2])\n\n    \"\"\"\n    if metric is None:\n        metric = mean\n    if weights is None:\n        weights = array([1, 0, 0])\n    if len(weights) != 3:\n        raise ValueError(\"The weights array must be of length 3.\")\n    model_names = list(result.keys())\n    n = len(model_names)\n    y = zeros([n])\n    for i in range(n):\n        y[i] = (\n            weights[0] * metric(result[model_names[i]][\"error\"])\n            + weights[1] * metric(result[model_names[i]][\"r_time\"])\n            + weights[2] * metric(result[model_names[i]][\"memory\"])\n        )\n    return y\n</code></pre>"},{"location":"reference/spotRiver/evaluation/eval_oml/#spotRiver.evaluation.eval_oml.plot_oml_iter_progressive","title":"<code>plot_oml_iter_progressive(result, log_x=False, log_y=False, figsize=None, filename=None)</code>","text":"<p>Plot evaluation of OML models.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>dict</code> <p>A dictionary of evaluation results, as returned by eval_oml_iter_progressive.</p> required <code>log_x</code> <code>bool</code> <p>If True, the x-axis is set to log scale. Defaults to False.</p> <code>False</code> <code>log_y</code> <code>bool</code> <p>If True, the y-axis is set to log scale. Defaults to False.</p> <code>False</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure. Defaults to None, in which case the default figure size <code>(10, 5)</code> is used.</p> <code>None</code> <code>filename</code> <code>str</code> <p>The name of the file to save the plot to. If None, the plot is not saved. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>matplotlib.figure.Figure</code> <p>The figure object.</p> Reference <p>https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive\n</code></pre> <pre><code>&gt;&gt;&gt; result = {\n...     \"model1\": {\n...         \"step\": [1, 2, 3],\n...         \"error\": [0.1, 0.2, 0.3],\n...         \"r_time\": [0.1, 0.2, 0.3],\n...         \"memory\": [0.1, 0.2, 0.3],\n...         \"metric_name\": \"MAE\"\n...     },\n...     \"model2\": {\n...         \"step\": [1, 2, 3],\n...         \"error\": [0.2, 0.3, 0.4],\n...         \"r_time\": [0.2, 0.3, 0.4],\n...         \"memory\": [0.2, 0.3, 0.4],\n...         \"metric_name\": \"MAE\"\n...     }\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; plot_oml_iter_progressive(result)\n&lt;Figure size 1000x500 with 3 Axes&gt;\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/evaluation/eval_oml.py</code> <pre><code>def plot_oml_iter_progressive(result, log_x=False, log_y=False, figsize=None, filename=None):\n\"\"\"Plot evaluation of OML models.\n\n    Args:\n        result (dict): A dictionary of evaluation results, as returned by eval_oml_iter_progressive.\n        log_x (bool, optional): If True, the x-axis is set to log scale. Defaults to False.\n        log_y (bool, optional): If True, the y-axis is set to log scale. Defaults to False.\n        figsize (tuple, optional): The size of the figure. Defaults to None, in which case\n            the default figure size `(10, 5)` is used.\n        filename (str, optional): The name of the file to save the plot to. If None, the plot\n            is not saved. Defaults to None.\n\n    Returns:\n        (matplotlib.figure.Figure): The figure object.\n\n    Reference:\n        https://riverml.xyz/0.15.0/recipes/on-hoeffding-trees/\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.evaluation.eval_oml import plot_oml_iter_progressive\n\n        &gt;&gt;&gt; result = {\n        ...     \"model1\": {\n        ...         \"step\": [1, 2, 3],\n        ...         \"error\": [0.1, 0.2, 0.3],\n        ...         \"r_time\": [0.1, 0.2, 0.3],\n        ...         \"memory\": [0.1, 0.2, 0.3],\n        ...         \"metric_name\": \"MAE\"\n        ...     },\n        ...     \"model2\": {\n        ...         \"step\": [1, 2, 3],\n        ...         \"error\": [0.2, 0.3, 0.4],\n        ...         \"r_time\": [0.2, 0.3, 0.4],\n        ...         \"memory\": [0.2, 0.3, 0.4],\n        ...         \"metric_name\": \"MAE\"\n        ...     }\n        ... }\n\n        &gt;&gt;&gt; plot_oml_iter_progressive(result)\n        &lt;Figure size 1000x500 with 3 Axes&gt;\n\n    \"\"\"\n    if figsize is None:\n        figsize = (10, 5)\n    fig, ax = plt.subplots(figsize=figsize, nrows=3, dpi=300)\n    for model_name, model in result.items():\n        ax[0].plot(model[\"step\"], model[\"error\"], label=model_name)\n        ax[1].plot(model[\"step\"], model[\"r_time\"], label=model_name)\n        ax[2].plot(model[\"step\"], model[\"memory\"], label=model_name)\n\n    ax[0].set_ylabel(model[\"metric_name\"])\n    ax[1].set_ylabel(\"Time (seconds)\")\n    ax[2].set_ylabel(\"Memory (MB)\")\n    ax[2].set_xlabel(\"Instances\")\n\n    ax[0].grid(True)\n    ax[1].grid(True)\n    ax[2].grid(True)\n    if log_y:\n        ax[0].set_yscale(\"log\")\n        ax[1].set_yscale(\"log\")\n        ax[2].set_yscale(\"log\")\n\n    ax[0].legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.25), ncol=3, fancybox=True, shadow=True)\n    plt.tight_layout()\n    plt.close()\n    if filename is not None:\n        fig.savefig(filename, dpi=300)\n    return fig\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/","title":"hyperriver","text":""},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver","title":"<code>HyperRiver</code>","text":"<p>Hyperparameter Tuning for River.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>class HyperRiver:\n\"\"\"\n    Hyperparameter Tuning for River.\n\n    Args:\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n\n    \"\"\"\n\n    def __init__(self, seed=126, log_level=50):\n\"\"\"Initialize the class.\n        Args:\n            seed (int): seed.\n                See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n            log_level (int): The level of logging to use. 0 = no logging, 50 = print only important\n                            information. Defaults to 50.\n        Returns:\n            (NoneType): None\n        \"\"\"\n        self.seed = seed\n        self.rng = default_rng(seed=self.seed)\n        self.fun_control = {\n            \"seed\": None,\n            \"data\": None,\n            \"step\": 10_000,\n            \"horizon\": None,\n            \"grace_period\": None,\n            \"metric_river\": None,\n            \"metric_sklearn\": mean_absolute_error,\n            \"weights\": array([1, 0, 0]),\n            \"weight_coeff\": 0.0,\n            \"log_level\": log_level,\n            \"var_name\": [],\n            \"var_type\": [],\n            \"prep_model\": None,\n        }\n        self.log_level = self.fun_control[\"log_level\"]\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n    def compute_y(self, df_eval):\n\"\"\"Compute the objective function value.\n        Args:\n            df_eval (pd.DataFrame): DataFrame with the evaluation results.\n        Returns:\n            (float): objective function value. Mean of the MAEs of the predicted values.\n        Examples:\n            &gt;&gt;&gt; df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)'])\n            &gt;&gt;&gt; weights = [1, 1, 1]\n            &gt;&gt;&gt; compute_y(df_eval, weights)\n            4.0\n        \"\"\"\n        # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values\n        df_eval = df_eval.dropna()\n        y_error = df_eval[\"Metric\"].mean()\n        logger.debug(\"y_error from eval_oml_horizon: %s\", y_error)\n        y_r_time = df_eval[\"CompTime (s)\"].mean()\n        logger.debug(\"y_r_time from eval_oml_horizon: %s\", y_r_time)\n        y_memory = df_eval[\"Memory (MB)\"].mean()\n        logger.debug(\"y_memory from eval_oml_horizon: %s\", y_memory)\n        weights = self.fun_control[\"weights\"]\n        logger.debug(\"weights from eval_oml_horizon: %s\", weights)\n        y = weights[0] * y_error + weights[1] * y_r_time + weights[2] * y_memory\n        logger.debug(\"weighted res from eval_oml_horizon: %s\", y)\n        return y\n\n    def check_X_shape(self, X):\n\"\"\"\n        Check the shape of X.\n        Args:\n            X (np.ndarray): The input data.\n        Returns:\n            (NoneType): None\n        Examples:\n            &gt;&gt;&gt; X = np.array([[1, 2, 3], [4, 5, 6]])\n            &gt;&gt;&gt; check_X_shape(X)\n            &gt;&gt;&gt; X = np.array([1, 2, 3])\n            &gt;&gt;&gt; check_X_shape(X)\n            Traceback (most recent call last):\n            ...\n            Exception\n\n        \"\"\"\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != len(self.fun_control[\"var_name\"]):\n            raise Exception\n\n    def evaluate_model(self, model: object, fun_control: dict) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n\"\"\"\n        Evaluates a model using the eval_oml_horizon function.\n\n        Args:\n            model (object): The model to be evaluated.\n            fun_control (dict): A dictionary containing the following keys:\n                - train (pd.DataFrame): The training data.\n                - test (pd.DataFrame): The testing data.\n                - target_column (str): The name of the target column.\n                - horizon (int): The horizon value.\n                - oml_grace_period (int): The oml_grace_period value.\n                - metric_sklearn (str): The metric to be used for evaluation.\n\n        Returns:\n            (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes:\n                - df_eval: The evaluation dataframe.\n                - df_preds: The predictions dataframe.\n\n        Example:\n            &gt;&gt;&gt; model = SomeModel()\n            &gt;&gt;&gt; fun_control = {\n            ...     \"train\": train_data,\n            ...     \"test\": test_data,\n            ...     \"target_column\": \"target\",\n            ...     \"horizon\": 5,\n            ...     \"oml_grace_period\": 10,\n            ...     \"metric_sklearn\": \"accuracy\"\n            ... }\n            &gt;&gt;&gt; df_eval, df_preds = evaluate_model(model, fun_control)\n        \"\"\"\n        try:\n            df_eval, df_preds = eval_oml_horizon(\n                model=model,\n                train=fun_control[\"train\"],\n                test=fun_control[\"test\"],\n                target_column=fun_control[\"target_column\"],\n                horizon=fun_control[\"horizon\"],\n                oml_grace_period=fun_control[\"oml_grace_period\"],\n                metric=fun_control[\"metric_sklearn\"],\n            )\n        except Exception as err:\n            print(f\"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. {err=}, {type(err)=}\")\n        return df_eval, df_preds\n\n    def get_river_df_eval_preds(self, model):\n\"\"\"Get the evaluation and prediction dataframes for a river model.\n        Args:\n            model (object): The model to be evaluated.\n        Returns:\n            (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes:\n                - df_eval: The evaluation dataframe.\n                - df_preds: The predictions dataframe.\n        Examples:\n            &gt;&gt;&gt; model = SomeModel()\n            &gt;&gt;&gt; df_eval, df_preds = get_river_df_eval_preds(model)\n        \"\"\"\n        try:\n            df_eval, df_preds = self.evaluate_model(model, self.fun_control)\n        except Exception as err:\n            print(f\"Error in get_river_df_eval_preds(). Call to evaluate_model failed. {err=}, {type(err)=}\")\n            print(\"Setting df_eval and df.preds to np.nan\")\n            df_eval = np.nan\n            df_preds = np.nan\n        return df_eval, df_preds\n\n    def fun_oml_horizon(self, X: np.ndarray, fun_control: Optional[Dict[str, Any]] = None) -&gt; np.ndarray:\n\"\"\"\n        The objective function for hyperparameter tuning.\n\n        This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning.\n\n        Args:\n            X (np.ndarray): The input data.\n            fun_control (dict, optional): A dictionary containing the following keys:\n                - train (pd.DataFrame): The training data.\n                - test (pd.DataFrame): The testing data.\n                - target_column (str): The name of the target column.\n                - horizon (int): The horizon value.\n                - oml_grace_period (int): The oml_grace_period value.\n                - metric_sklearn (str): The metric to be used for evaluation.\n\n        Returns:\n            (np.ndarray): The objective function values.\n\n        Example:\n            &gt;&gt;&gt; fun_oml_horizon(X, fun_control={'train': train_data, 'test': test_data, 'target_column': 'y', 'horizon': 5, 'oml_grace_period': 10, 'metric_sklearn': 'accuracy'})\n            array([0.8, 0.85, 0.9])\n        \"\"\"\n        z_res = []\n        self.fun_control.update(fun_control)\n        self.check_X_shape(X)\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        for config in generate_one_config_from_var_dict(var_dict, self.fun_control):\n            config_id = generate_config_id(config)\n            if self.fun_control[\"prep_model\"] is not None:\n                model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n            else:\n                model = self.fun_control[\"core_model\"](**config)\n            try:\n                df_eval, _ = self.evaluate_model(model, self.fun_control)\n                y = self.compute_y(df_eval)\n            except Exception as err:\n                y = np.nan\n                print(f\"Error in fun(). Call to evaluate or compute_y failed. {err=}, {type(err)=}\")\n                print(\"Setting y to np.nan.\")\n            z_res.append(y / self.fun_control[\"n_samples\"])\n        return np.array(z_res)\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.__init__","title":"<code>__init__(seed=126, log_level=50)</code>","text":"<p>Initialize the class.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> <code>log_level</code> <code>int</code> <p>The level of logging to use. 0 = no logging, 50 = print only important             information. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>NoneType</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>def __init__(self, seed=126, log_level=50):\n\"\"\"Initialize the class.\n    Args:\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n        log_level (int): The level of logging to use. 0 = no logging, 50 = print only important\n                        information. Defaults to 50.\n    Returns:\n        (NoneType): None\n    \"\"\"\n    self.seed = seed\n    self.rng = default_rng(seed=self.seed)\n    self.fun_control = {\n        \"seed\": None,\n        \"data\": None,\n        \"step\": 10_000,\n        \"horizon\": None,\n        \"grace_period\": None,\n        \"metric_river\": None,\n        \"metric_sklearn\": mean_absolute_error,\n        \"weights\": array([1, 0, 0]),\n        \"weight_coeff\": 0.0,\n        \"log_level\": log_level,\n        \"var_name\": [],\n        \"var_type\": [],\n        \"prep_model\": None,\n    }\n    self.log_level = self.fun_control[\"log_level\"]\n    logger.setLevel(self.log_level)\n    logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.check_X_shape","title":"<code>check_X_shape(X)</code>","text":"<p>Check the shape of X.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>np.ndarray</code> <p>The input data.</p> required <p>Returns:</p> Type Description <code>NoneType</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; check_X_shape(X)\n&gt;&gt;&gt; X = np.array([1, 2, 3])\n&gt;&gt;&gt; check_X_shape(X)\nTraceback (most recent call last):\n...\nException\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>def check_X_shape(self, X):\n\"\"\"\n    Check the shape of X.\n    Args:\n        X (np.ndarray): The input data.\n    Returns:\n        (NoneType): None\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2, 3], [4, 5, 6]])\n        &gt;&gt;&gt; check_X_shape(X)\n        &gt;&gt;&gt; X = np.array([1, 2, 3])\n        &gt;&gt;&gt; check_X_shape(X)\n        Traceback (most recent call last):\n        ...\n        Exception\n\n    \"\"\"\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array([X])\n    if X.shape[1] != len(self.fun_control[\"var_name\"]):\n        raise Exception\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.compute_y","title":"<code>compute_y(df_eval)</code>","text":"<p>Compute the objective function value.</p> <p>Parameters:</p> Name Type Description Default <code>df_eval</code> <code>pd.DataFrame</code> <p>DataFrame with the evaluation results.</p> required <p>Returns:</p> Type Description <code>float</code> <p>objective function value. Mean of the MAEs of the predicted values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)'])\n&gt;&gt;&gt; weights = [1, 1, 1]\n&gt;&gt;&gt; compute_y(df_eval, weights)\n4.0\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>def compute_y(self, df_eval):\n\"\"\"Compute the objective function value.\n    Args:\n        df_eval (pd.DataFrame): DataFrame with the evaluation results.\n    Returns:\n        (float): objective function value. Mean of the MAEs of the predicted values.\n    Examples:\n        &gt;&gt;&gt; df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)'])\n        &gt;&gt;&gt; weights = [1, 1, 1]\n        &gt;&gt;&gt; compute_y(df_eval, weights)\n        4.0\n    \"\"\"\n    # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values\n    df_eval = df_eval.dropna()\n    y_error = df_eval[\"Metric\"].mean()\n    logger.debug(\"y_error from eval_oml_horizon: %s\", y_error)\n    y_r_time = df_eval[\"CompTime (s)\"].mean()\n    logger.debug(\"y_r_time from eval_oml_horizon: %s\", y_r_time)\n    y_memory = df_eval[\"Memory (MB)\"].mean()\n    logger.debug(\"y_memory from eval_oml_horizon: %s\", y_memory)\n    weights = self.fun_control[\"weights\"]\n    logger.debug(\"weights from eval_oml_horizon: %s\", weights)\n    y = weights[0] * y_error + weights[1] * y_r_time + weights[2] * y_memory\n    logger.debug(\"weighted res from eval_oml_horizon: %s\", y)\n    return y\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.evaluate_model","title":"<code>evaluate_model(model, fun_control)</code>","text":"<p>Evaluates a model using the eval_oml_horizon function.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>The model to be evaluated.</p> required <code>fun_control</code> <code>dict</code> <p>A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation.</p> required <p>Returns:</p> Type Description <code>Tuple[pd.DataFrame, pd.DataFrame]</code> <p>A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe.</p> Example <p>model = SomeModel() fun_control = { \u2026     \u201ctrain\u201d: train_data, \u2026     \u201ctest\u201d: test_data, \u2026     \u201ctarget_column\u201d: \u201ctarget\u201d, \u2026     \u201chorizon\u201d: 5, \u2026     \u201coml_grace_period\u201d: 10, \u2026     \u201cmetric_sklearn\u201d: \u201caccuracy\u201d \u2026 } df_eval, df_preds = evaluate_model(model, fun_control)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>def evaluate_model(self, model: object, fun_control: dict) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n\"\"\"\n    Evaluates a model using the eval_oml_horizon function.\n\n    Args:\n        model (object): The model to be evaluated.\n        fun_control (dict): A dictionary containing the following keys:\n            - train (pd.DataFrame): The training data.\n            - test (pd.DataFrame): The testing data.\n            - target_column (str): The name of the target column.\n            - horizon (int): The horizon value.\n            - oml_grace_period (int): The oml_grace_period value.\n            - metric_sklearn (str): The metric to be used for evaluation.\n\n    Returns:\n        (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes:\n            - df_eval: The evaluation dataframe.\n            - df_preds: The predictions dataframe.\n\n    Example:\n        &gt;&gt;&gt; model = SomeModel()\n        &gt;&gt;&gt; fun_control = {\n        ...     \"train\": train_data,\n        ...     \"test\": test_data,\n        ...     \"target_column\": \"target\",\n        ...     \"horizon\": 5,\n        ...     \"oml_grace_period\": 10,\n        ...     \"metric_sklearn\": \"accuracy\"\n        ... }\n        &gt;&gt;&gt; df_eval, df_preds = evaluate_model(model, fun_control)\n    \"\"\"\n    try:\n        df_eval, df_preds = eval_oml_horizon(\n            model=model,\n            train=fun_control[\"train\"],\n            test=fun_control[\"test\"],\n            target_column=fun_control[\"target_column\"],\n            horizon=fun_control[\"horizon\"],\n            oml_grace_period=fun_control[\"oml_grace_period\"],\n            metric=fun_control[\"metric_sklearn\"],\n        )\n    except Exception as err:\n        print(f\"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. {err=}, {type(err)=}\")\n    return df_eval, df_preds\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.fun_oml_horizon","title":"<code>fun_oml_horizon(X, fun_control=None)</code>","text":"<p>The objective function for hyperparameter tuning.</p> <p>This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>np.ndarray</code> <p>The input data.</p> required <code>fun_control</code> <code>dict</code> <p>A dictionary containing the following keys: - train (pd.DataFrame): The training data. - test (pd.DataFrame): The testing data. - target_column (str): The name of the target column. - horizon (int): The horizon value. - oml_grace_period (int): The oml_grace_period value. - metric_sklearn (str): The metric to be used for evaluation.</p> <code>None</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>The objective function values.</p> Example <p>fun_oml_horizon(X, fun_control={\u2018train\u2019: train_data, \u2018test\u2019: test_data, \u2018target_column\u2019: \u2018y\u2019, \u2018horizon\u2019: 5, \u2018oml_grace_period\u2019: 10, \u2018metric_sklearn\u2019: \u2018accuracy\u2019}) array([0.8, 0.85, 0.9])</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>def fun_oml_horizon(self, X: np.ndarray, fun_control: Optional[Dict[str, Any]] = None) -&gt; np.ndarray:\n\"\"\"\n    The objective function for hyperparameter tuning.\n\n    This function takes in input data and a dictionary of control parameters to compute the objective function values for hyperparameter tuning.\n\n    Args:\n        X (np.ndarray): The input data.\n        fun_control (dict, optional): A dictionary containing the following keys:\n            - train (pd.DataFrame): The training data.\n            - test (pd.DataFrame): The testing data.\n            - target_column (str): The name of the target column.\n            - horizon (int): The horizon value.\n            - oml_grace_period (int): The oml_grace_period value.\n            - metric_sklearn (str): The metric to be used for evaluation.\n\n    Returns:\n        (np.ndarray): The objective function values.\n\n    Example:\n        &gt;&gt;&gt; fun_oml_horizon(X, fun_control={'train': train_data, 'test': test_data, 'target_column': 'y', 'horizon': 5, 'oml_grace_period': 10, 'metric_sklearn': 'accuracy'})\n        array([0.8, 0.85, 0.9])\n    \"\"\"\n    z_res = []\n    self.fun_control.update(fun_control)\n    self.check_X_shape(X)\n    var_dict = assign_values(X, self.fun_control[\"var_name\"])\n    for config in generate_one_config_from_var_dict(var_dict, self.fun_control):\n        config_id = generate_config_id(config)\n        if self.fun_control[\"prep_model\"] is not None:\n            model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n        else:\n            model = self.fun_control[\"core_model\"](**config)\n        try:\n            df_eval, _ = self.evaluate_model(model, self.fun_control)\n            y = self.compute_y(df_eval)\n        except Exception as err:\n            y = np.nan\n            print(f\"Error in fun(). Call to evaluate or compute_y failed. {err=}, {type(err)=}\")\n            print(\"Setting y to np.nan.\")\n        z_res.append(y / self.fun_control[\"n_samples\"])\n    return np.array(z_res)\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver/#spotRiver.fun.hyperriver.HyperRiver.get_river_df_eval_preds","title":"<code>get_river_df_eval_preds(model)</code>","text":"<p>Get the evaluation and prediction dataframes for a river model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>The model to be evaluated.</p> required <p>Returns:</p> Type Description <code>Tuple[pd.DataFrame, pd.DataFrame]</code> <p>A tuple containing two dataframes: - df_eval: The evaluation dataframe. - df_preds: The predictions dataframe.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; model = SomeModel()\n&gt;&gt;&gt; df_eval, df_preds = get_river_df_eval_preds(model)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver.py</code> <pre><code>def get_river_df_eval_preds(self, model):\n\"\"\"Get the evaluation and prediction dataframes for a river model.\n    Args:\n        model (object): The model to be evaluated.\n    Returns:\n        (Tuple[pd.DataFrame, pd.DataFrame]): A tuple containing two dataframes:\n            - df_eval: The evaluation dataframe.\n            - df_preds: The predictions dataframe.\n    Examples:\n        &gt;&gt;&gt; model = SomeModel()\n        &gt;&gt;&gt; df_eval, df_preds = get_river_df_eval_preds(model)\n    \"\"\"\n    try:\n        df_eval, df_preds = self.evaluate_model(model, self.fun_control)\n    except Exception as err:\n        print(f\"Error in get_river_df_eval_preds(). Call to evaluate_model failed. {err=}, {type(err)=}\")\n        print(\"Setting df_eval and df.preds to np.nan\")\n        df_eval = np.nan\n        df_preds = np.nan\n    return df_eval, df_preds\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/","title":"hyperriver_old","text":""},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver","title":"<code>HyperRiver</code>","text":"<p>Hyperparameter Tuning for River.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>class HyperRiver:\n\"\"\"\n    Hyperparameter Tuning for River.\n\n    Args:\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n\n    \"\"\"\n\n    def __init__(self, seed=126, log_level=50):\n        self.seed = seed\n        self.rng = default_rng(seed=self.seed)\n        self.fun_control = {\n            \"seed\": None,\n            \"data\": None,\n            \"step\": 10_000,\n            \"horizon\": None,\n            \"grace_period\": None,\n            \"metric\": metrics.MAE(),\n            \"metric_sklearn\": mean_absolute_error,\n            \"weights\": array([1, 0, 0]),\n            \"weight_coeff\": 0.0,\n            \"log_level\": log_level,\n            \"var_name\": [],\n            \"var_type\": [],\n            \"prep_model\": None,\n        }\n        self.log_level = self.fun_control[\"log_level\"]\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n    # def get_month_distances(x):\n    #     return {\n    #         calendar.month_name[month]: math.exp(-(x['month'].month - month) ** 2)\n    #         for month in range(1, 13)\n    #     }\n\n    # def get_ordinal_date(x):\n    #     return {'ordinal_date': x['month'].toordinal()}\n    def fun_nowcasting(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of the nowcasting model.\n\n        Returns:\n            (float): objective function value. Mean of the MAEs of the predicted values.\n        \"\"\"\n        self.fun_control.update(fun_control)\n\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != 5:\n            raise Exception\n        lr = X[:, 0]\n        intercept_lr = X[:, 1]\n        hour = X[:, 2]\n        weekday = X[:, 3]\n        month = X[:, 4]\n\n        z_res = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            h_i = int(hour[i])\n            w_i = int(weekday[i])\n            m_i = int(month[i])\n            # baseline:\n            extract_features = compose.TransformerUnion(get_ordinal_date)\n            if h_i:\n                extract_features = compose.TransformerUnion(get_ordinal_date, get_hour_distances)\n            if w_i:\n                extract_features = compose.TransformerUnion(extract_features, get_weekday_distances)\n            if m_i:\n                extract_features = compose.TransformerUnion(extract_features, get_month_distances)\n            model = compose.Pipeline(\n                (\"features\", extract_features),\n                (\"scale\", preprocessing.StandardScaler()),\n                (\n                    \"lin_reg\",\n                    linear_model.LinearRegression(\n                        intercept_init=0, optimizer=optim.SGD(float(lr[i])), intercept_lr=float(intercept_lr[i])\n                    ),\n                ),\n            )\n            # eval:\n            dates, metric, y_trues, y_preds = eval_nowcast_model(\n                model, dataset=self.fun_control[\"data\"], time_interval=\"Time\"\n            )\n            z = metric.get()\n            z_res = np.append(z_res, z)\n        return z_res\n\n    def fun_snarimax(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of the SNARIMAX model.\n            SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with\n            e(X)ogenous inputs model.\n        This model generalizes many established time series models in a single interface that can be\n        trained online. It assumes that the provided training data is ordered in time and is uniformly spaced.\n        It is made up of the following components:\n        - S (Seasonal)\n        - N (Non-linear): Any online regression model can be used, not necessarily a linear regression\n            as is done in textbooks.\n        - AR (Autoregressive): Lags of the target variable are used as features.\n        - I (Integrated): The model can be fitted on a differenced version of a time series. In this\n            context, integration is the reverse of differencing.\n        - MA (Moving average): Lags of the errors are used as features.\n        - X (Exogenous): Users can provide additional features. Care has to be taken to include\n            features that will be available both at training and prediction time.\n\n        Each of these components can be switched on and off by specifying the appropriate parameters.\n        Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special\n        parametrizations of the SNARIMAX model.\n\n        This model is tailored for time series that are homoskedastic. In other words, it might not\n        work well if the variance of the time series varies widely along time.\n\n        Parameters of the hyperparameter vector:\n\n            `p`: Order of the autoregressive part. This is the number of past target values that will be\n                included as features.\n            `d`: Differencing order.\n            `q`: Order of the moving average part. This is the number of past error terms that will be included\n                as features.\n            `m`: Season length used for extracting seasonal features. If you believe your data has a seasonal\n                pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality,\n                and that your data is spaced by month, then you should set this to `12`.\n                Note that for this parameter to have any impact you should also set at least\n                one of the `p`, `d`, and `q` parameters.\n            `sp`:  Seasonal order of the autoregressive part. This is the number of past target values that will\n                be included as features.\n            `sd`: Seasonal differencing order.\n            `sq`: Seasonal order of the moving average part. This is the number of past error terms that will be\n                included as features.\n            `lr` (float):\n                learn rate of the linear regression model. A river `preprocessing.StandardScaler`\n                piped with a river `linear_model.LinearRegression` will be used.\n            `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler`\n                piped with a river `linear_model.LinearRegression` will be used.\n            `hour` (bool): If `True`, an hourly component is added.\n            `weekdy` (bool): If `True`, an weekday component is added.\n            `month` (bool): If `True`, an monthly component is added.\n\n        Args:\n            X (array):\n                Seven hyperparameters to be optimized. Here:\n\n                `p` (int):\n                    Order of the autoregressive part.\n                    This is the number of past target values that will be included as features.\n\n                `d` (int):\n                    Differencing order.\n\n                `q` (int):\n                    Order of the moving average part.\n                    This is the number of past error terms that will be included as features.\n\n                `m` (int):\n                    Season length used for extracting seasonal features.\n                    If you believe your data has a seasonal pattern, then set this accordingly.\n                    For instance, if the data seems to exhibit a yearly seasonality,\n                    and that your data is spaced by month, then you should set this to `12`.\n                    Note that for this parameter to have any impact you should also set\n                    at least one of the `p`, `d`, and `q` parameters.\n\n                `sp` (int):\n                    Seasonal order of the autoregressive part.\n                    This is the number of past target values that will be included as features.\n\n                `sd` (int):\n                    Seasonal differencing order.\n\n                `sq`(int):\n                    Seasonal order of the moving average part.\n                    This is the number of past error terms that will be included as features.\n\n                `lr` (float):\n                    learn rate of the linear regression model. A river `preprocessing.StandardScaler`\n                    piped with a river `linear_model.LinearRegression` will be used.\n\n                `intercept_lr` (float): intercept of the the linear regression model.\n                    A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression`\n                    will be used.\n\n                `hour` (bool): If `True`, an hourly component is added.\n\n                `weekday` (bool): If `True`, an weekday component is added.\n\n                `month` (bool): If `True`, an monthly component is added.\n\n            fun_control (dict):\n                parameter that are not optimized, e.g., `horizon`. Commonly\n                referred to as \"design of experiments\" parameters:\n\n                1. `horizon`: (int)\n\n                2. `grace_period`: (int) Initial period during which the metric is not updated.\n                    This is to fairly evaluate models which need a warming up period to start\n                    producing meaningful forecasts.\n                    The value of this parameter is equal to the `horizon` by default.\n\n                3. `data`: dataset. Default `AirlinePassengers`.\n\n        Returns:\n            (float): objective function value. Mean of the MAEs of the predicted values.\n        \"\"\"\n        self.fun_control.update(fun_control)\n\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != 12:\n            raise Exception\n        p = X[:, 0]\n        d = X[:, 1]\n        q = X[:, 2]\n        m = X[:, 3]\n        sp = X[:, 4]\n        sd = X[:, 5]\n        sq = X[:, 6]\n        lr = X[:, 7]\n        intercept_lr = X[:, 8]\n        hour = X[:, 9]\n        weekday = X[:, 10]\n        month = X[:, 11]\n\n        # TODO:\n        # horizon = fun_control[\"horizon\"]\n        # future = [\n        #   {\"month\": dt.date(year=1961, month=m, day=1)} for m in range(1, horizon + 1)\n        # ]\n        z_res = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            h_i = int(hour[i])\n            w_i = int(weekday[i])\n            m_i = int(month[i])\n            # baseline:\n            extract_features = compose.TransformerUnion(get_ordinal_date)\n            if h_i:\n                extract_features = compose.TransformerUnion(get_ordinal_date, get_hour_distances)\n            if w_i:\n                extract_features = compose.TransformerUnion(extract_features, get_weekday_distances)\n            if m_i:\n                extract_features = compose.TransformerUnion(extract_features, get_month_distances)\n            model = compose.Pipeline(\n                extract_features,\n                time_series.SNARIMAX(\n                    p=int(p[i]),\n                    d=int(d[i]),\n                    q=int(q[i]),\n                    m=int(m[i]),\n                    sp=int(sp[i]),\n                    sd=int(sd[i]),\n                    sq=int(sq[i]),\n                    regressor=compose.Pipeline(\n                        preprocessing.StandardScaler(),\n                        linear_model.LinearRegression(\n                            intercept_init=0,\n                            optimizer=optim.SGD(float(lr[i])),\n                            intercept_lr=float(intercept_lr[i]),\n                        ),\n                    ),\n                ),\n            )\n            # eval:\n            res = time_series.evaluate(\n                self.fun_control[\"data\"],\n                model,\n                metric=self.fun_control[\"metric\"],\n                horizon=self.fun_control[\"horizon\"],\n                agg_func=statistics.mean,\n            )\n            z = res.get()\n            z_res = np.append(z_res, z)\n        return z_res\n\n    def fun_hw(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of the HoltWinters model.\n\n            Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method.\n            Certain parameterizations result in special cases, such as simple exponential smoothing.\n\n        Args:\n            X (array): five hyperparameters. The parameters of the hyperparameter vector are:\n\n                1. `alpha`: Smoothing parameter for the level.\n                2. `beta`: Smoothing parameter for the trend.\n                3. `gamma`: Smoothing parameter for the seasonality.\n                4. `seasonality`: The number of periods in a season.\n                    For instance, this should be 4 for quarterly data, and 12 for yearly data.\n                5. `multiplicative`: Whether or not to use a multiplicative formulation.\n\n            fun_control (dict): Parameters that are are not tuned:\n\n                1. `horizon`: (int)\n                2. `grace_period`: (int) Initial period during which the metric is not updated.\n                    This is to fairly evaluate models which need a warming up period to start\n                    producing meaningful forecasts.\n                    The value of this parameter is equal to the `horizon` by default.\n                2. `data`: dataset. Default `AirlinePassengers`.\n\n        Returns:\n            (float): objective function value. Mean of the MAEs of the predicted values.\n        \"\"\"\n        self.fun_control.update(fun_control)\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != 5:\n            raise Exception\n\n        alpha = X[:, 0]\n        beta = X[:, 1]\n        gamma = X[:, 2]\n        seasonality = X[:, 3]\n        multiplicative = X[:, 4]\n        z_res = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            model = time_series.HoltWinters(\n                alpha=alpha[i],\n                beta=beta[i],\n                gamma=gamma[i],\n                seasonality=int(seasonality[i]),\n                multiplicative=int(multiplicative[i]),\n            )\n            res = time_series.evaluate(\n                self.fun_control[\"data\"],\n                model,\n                metric=self.fun_control[\"metric\"],\n                horizon=self.fun_control[\"horizon\"],\n                grace_period=self.fun_control[\"grace_period\"],\n                agg_func=statistics.mean,\n            )\n            z = res.get()\n            z_res = np.append(z_res, z)\n        return z_res\n\n    # def fun_HTR_iter_progressive(self, X, fun_control=None):\n    #     \"\"\"Hyperparameter Tuning of HTR model.\n    #     See: https://riverml.xyz/0.15.0/api/tree/HoeffdingTreeRegressor/\n    #     Parameters\n    #     ----------\n    #     grace_period\n    #         Number of instances a leaf should observe between split attempts.\n    #     max_depth\n    #         The maximum depth a tree can reach. If `None`, the tree will grow indefinitely.\n    #     delta\n    #         Significance level to calculate the Hoeffding bound. The significance level is given by\n    #         `1 - delta`. Values closer to zero imply longer split decision delays.\n    #     tau\n    #         Threshold below which a split will be forced to break ties.\n    #     leaf_prediction\n    #         Prediction mechanism used at leafs. NOTE: order differs from the order in river!&lt;/br&gt;\n    #         - 'mean' - Target mean&lt;/br&gt;\n    #         - 'adaptive' - Chooses between 'mean' and 'model' dynamically&lt;/br&gt;\n    #         - 'model' - Uses the model defined in `leaf_model`&lt;/br&gt;\n    #     NOT IMPLEMENTED: leaf_model\n    #         The regression model used to provide responses if `leaf_prediction='model'`. If not\n    #         provided an instance of `river.linear_model.LinearRegression` with the default\n    #         hyperparameters is used.\n    #     model_selector_decay\n    #         The exponential decaying factor applied to the learning models' squared errors, that\n    #         are monitored if `leaf_prediction='adaptive'`. Must be between `0` and `1`. The closer\n    #         to `1`, the more importance is going to be given to past observations. On the other hand,\n    #         if its value approaches `0`, the recent observed errors are going to have more influence\n    #         on the final decision.\n    #     nominal_attributes\n    #         List of Nominal attributes identifiers. If empty, then assume that all numeric attributes\n    #         should be treated as continuous.\n    #     splitter\n    #         The Splitter or Attribute Observer (AO) used to monitor the class statistics of numeric\n    #         features and perform splits. Splitters are available in the `tree.splitter` module.\n    #         Different splitters are available for classification and regression tasks. Classification\n    #         and regression splitters can be distinguished by their property `is_target_class`.\n    #         This is an advanced option. Special care must be taken when choosing different splitters.\n    #         By default, `tree.splitter.TEBSTSplitter` is used if `splitter` is `None`.\n    #     min_samples_split\n    #         The minimum number of samples every branch resulting from a split candidate must have\n    #         to be considered valid.\n    #     binary_split\n    #         If True, only allow binary splits.\n    #     max_size\n    #         The max size of the tree, in Megabytes (MB).\n    #     memory_estimate_period\n    #         Interval (number of processed instances) between memory consumption checks.\n    #     stop_mem_management\n    #         If True, stop growing as soon as memory limit is hit.\n    #     remove_poor_attrs\n    #         If True, disable poor attributes to reduce memory usage.\n    #     merit_preprune\n    #         If True, enable merit-based tree pre-pruning.\n\n    #     fun_control\n    #         Parameters that are are not tuned:\n    #             1. `horizon`: (int)\n    #             2. `grace_period`: (int) Initial period during which the metric is not updated.\n    #                     This is to fairly evaluate models which need a warming up period to start\n    #                     producing meaningful forecasts.\n    #                     The value of this parameter is equal to the `horizon` by default.\n    #             3. `data`: dataset. Default `AirlinePassengers`.\n\n    #     Returns\n    #     -------\n    #     (float): objective function value. Mean of the MAEs of the predicted values.\n    #     \"\"\"\n    #     self.fun_control.update(fun_control)\n    #     try:\n    #         X.shape[1]\n    #     except ValueError:\n    #         X = np.array([X])\n    #     if X.shape[1] != 11:\n    #         raise Exception\n    #     grace_period = X[:, 0]\n    #     max_depth = X[:, 1]\n    #     delta = X[:, 2]\n    #     tau = X[:, 3]\n    #     leaf_prediction = X[:, 4]\n    #     leaf_model = X[:, 5]\n    #     model_selector_decay = X[:, 6]\n    #     splitter = X[:, 7]\n    #     min_samples_split = X[:, 8]\n    #     binary_split = X[:, 9]\n    #     max_size = X[:, 10]\n    #     z_res = np.array([], dtype=float)\n    #     dataset_list = self.fun_control[\"data\"]\n    #     for i in range(X.shape[0]):\n    #         num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler()\n    #         cat = compose.SelectType(str) | preprocessing.FeatureHasher(n_features=1000, seed=1)\n    #         try:\n    #             res = eval_oml_iter_progressive(\n    #                 dataset=dataset_list,\n    #                 step=self.fun_control[\"step\"],\n    #                 log_level=self.fun_control[\"log_level\"],\n    #                 metric=fun_control[\"metric\"],\n    #                 weight_coeff=fun_control[\"weight_coeff\"],\n    #                 models={\n    #                     \"HTR\": (\n    #                         (num + cat)\n    #                         | tree.HoeffdingTreeRegressor(\n    #                             grace_period=int(grace_period[i]),\n    #                             max_depth=transform_power_10(int(max_depth[i])),\n    #                             delta=float(delta[i]),\n    #                             tau=float(tau[i]),\n    #                             leaf_prediction=select_leaf_prediction(int(leaf_prediction[i])),\n    #                             leaf_model=select_leaf_model(int(leaf_model[i])),\n    #                             model_selector_decay=float(model_selector_decay[i]),\n    #                             splitter=select_splitter(int(splitter[i])),\n    #                             min_samples_split=int(min_samples_split[i]),\n    #                             binary_split=int(binary_split[i]),\n    #                             max_size=float(max_size[i]),\n    #                         )\n    #                     ),\n    #                 },\n    #             )\n    #             logger.debug(\"res from eval_oml_iter_progressive: %s\", res)\n    #             y = fun_eval_oml_iter_progressive(res, metric=None, weights=self.fun_control[\"weights\"])\n    #         except Exception as err:\n    #             y = np.nan\n    #             print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\")\n    #             print(f\"Setting y to {y:.2f}.\")\n    #         z_res = np.append(z_res, y / self.fun_control[\"n_samples\"])\n    #     return z_res\n\n    def fun_oml_iter_progressive(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of an arbitrary model.\n        Returns\n        -------\n        (float): objective function value. Mean of the MAEs of the predicted values.\n        \"\"\"\n        self.fun_control.update(fun_control)\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != len(self.fun_control[\"var_name\"]):\n            raise Exception\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        z_res = np.array([], dtype=float)\n        dataset_list = self.fun_control[\"data\"]\n        for values in iterate_dict_values(var_dict):\n            values = convert_keys(values, self.fun_control[\"var_type\"])\n            print(values)\n            values = get_dict_with_levels_and_types(fun_control=self.fun_control, v=values)\n            values = transform_hyper_parameter_values(fun_control=self.fun_control, hyper_parameter_values=values)\n            print(values)\n            model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**values))\n            try:\n                res = eval_oml_iter_progressive(\n                    dataset=dataset_list,\n                    step=self.fun_control[\"step\"],\n                    log_level=self.fun_control[\"log_level\"],\n                    metric=fun_control[\"metric\"],\n                    weight_coeff=fun_control[\"weight_coeff\"],\n                    models={\n                        self.fun_control[\"model_name\"]: (model),\n                    },\n                )\n                logger.debug(\"res from eval_oml_iter_progressive: %s\", res)\n                y = fun_eval_oml_iter_progressive(res, metric=None, weights=self.fun_control[\"weights\"])\n            except Exception as err:\n                y = np.nan\n                print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\")\n                print(f\"Setting y to {y:.2f}.\")\n            z_res = np.append(z_res, y / self.fun_control[\"n_samples\"])\n        return z_res\n\n    def compute_y(self, df_eval):\n\"\"\"Compute the objective function value.\n        Args:\n            df_eval (pd.DataFrame): DataFrame with the evaluation results.\n        Returns:\n            (float): objective function value. Mean of the MAEs of the predicted values.\n        Examples:\n            &gt;&gt;&gt; df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)'])\n            &gt;&gt;&gt; weights = [1, 1, 1]\n            &gt;&gt;&gt; compute_y(df_eval, weights)\n            4.0\n        \"\"\"\n        # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values\n        df_eval = df_eval.dropna()\n        y_error = df_eval[\"Metric\"].mean()\n        logger.debug(\"y_error from eval_oml_horizon: %s\", y_error)\n        y_r_time = df_eval[\"CompTime (s)\"].mean()\n        logger.debug(\"y_r_time from eval_oml_horizon: %s\", y_r_time)\n        y_memory = df_eval[\"Memory (MB)\"].mean()\n        logger.debug(\"y_memory from eval_oml_horizon: %s\", y_memory)\n        weights = self.fun_control[\"weights\"]\n        logger.debug(\"weights from eval_oml_horizon: %s\", weights)\n        y = weights[0] * y_error + weights[1] * y_r_time + weights[2] * y_memory\n        logger.debug(\"weighted res from eval_oml_horizon: %s\", y)\n        return y\n\n    # def fun_oml_horizon_old(self, X, fun_control=None, return_model=False, return_df=False):\n    #     \"\"\"Hyperparameter Tuning of an arbitrary model.\n    #     Returns\n    #     -------\n    #     (float): objective function value. Mean of the MAEs of the predicted values.\n    #     \"\"\"\n    #     self.fun_control.update(fun_control)\n    #     weights = self.fun_control[\"weights\"]\n    #     if len(weights) != 3:\n    #         raise ValueError(\"The weights array must be of length 3.\")\n    #     try:\n    #         X.shape[1]\n    #     except ValueError:\n    #         X = np.array([X])\n    #     if X.shape[1] != len(self.fun_control[\"var_name\"]):\n    #         raise Exception\n    #     var_dict = assign_values(X, self.fun_control[\"var_name\"])\n    #     z_res = np.array([], dtype=float)\n    #     for values in iterate_dict_values(var_dict):\n    #         values = convert_keys(values, self.fun_control[\"var_type\"])\n    #         values = get_dict_with_levels_and_types(fun_control=self.fun_control, v=values)\n    #         values = transform_hyper_parameter_values(fun_control=self.fun_control, hyper_parameter_values=values)\n    #         model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**values))\n    #         if return_model:\n    #             return model\n    #         try:\n    #             df_eval, df_preds = eval_oml_horizon(\n    #                 model=model,\n    #                 train=self.fun_control[\"train\"],\n    #                 test=self.fun_control[\"test\"],\n    #                 target_column=self.fun_control[\"target_column\"],\n    #                 horizon=self.fun_control[\"horizon\"],\n    #                 oml_grace_period=self.fun_control[\"oml_grace_period\"],\n    #                 metric=self.fun_control[\"metric_sklearn\"],\n    #             )\n    #         except Exception as err:\n    #             print(f\"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. {err=}, {type(err)=}\")\n    #         if return_df:\n    #             return df_eval, df_preds\n    #         try:\n    #             y = self.compute_y(df_eval, weights)\n    #         except Exception as err:\n    #             y = np.nan\n    #             print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\")\n    #             print(f\"Setting y to {y:.2f}.\")\n    #         z_res = np.append(z_res, y / self.fun_control[\"n_samples\"])\n    #     return z_res\n\n    def check_weights(self):\n        if len(self.fun_control[\"weights\"]) != 3:\n            raise ValueError(\"The weights array must be of length 3.\")\n\n    def check_X_shape(self, X):\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != len(self.fun_control[\"var_name\"]):\n            raise Exception\n\n    def evaluate_model(self, model, fun_control):\n        try:\n            df_eval, df_preds = eval_oml_horizon(\n                model=model,\n                train=fun_control[\"train\"],\n                test=fun_control[\"test\"],\n                target_column=fun_control[\"target_column\"],\n                horizon=fun_control[\"horizon\"],\n                oml_grace_period=fun_control[\"oml_grace_period\"],\n                metric=fun_control[\"metric_sklearn\"],\n            )\n        except Exception as err:\n            print(f\"Error in fun_oml_horizon(). Call to eval_oml_horizon failed. {err=}, {type(err)=}\")\n        return df_eval, df_preds\n\n    def get_river_df_eval_preds(self, model):\n        try:\n            df_eval, df_preds = self.evaluate_model(model, self.fun_control)\n        except Exception as err:\n            print(f\"Error in get_river_df_eval_preds(). Call to evaluate_model failed. {err=}, {type(err)=}\")\n            print(\"Setting df_eval and df.preds to np.nan\")\n            df_eval = np.nan\n            df_preds = np.nan\n        return df_eval, df_preds\n\n    def fun_oml_horizon_old(self, X, fun_control=None):\n        z_res = np.array([], dtype=float)\n        self.fun_control.update(fun_control)\n        self.check_weights()\n        self.check_X_shape(X)\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        for config in get_one_config_from_var_dict(var_dict, self.fun_control):\n            if self.fun_control[\"prep_model\"] is not None:\n                model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n            else:\n                model = self.fun_control[\"core_model\"](**config)\n            try:\n                df_eval, _ = self.evaluate_model(model, self.fun_control)\n            except Exception as err:\n                df_eval = np.nan\n                print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\")\n                print(\"Setting df_eval to np.nan.\")\n            try:\n                y = self.compute_y(df_eval)\n            except Exception as err:\n                y = np.nan\n                print(f\"Error in fun(). Call to compute_y failed. {err=}, {type(err)=}\")\n                print(\"Setting y to np.nan.\")\n            z_res = np.append(z_res, y / self.fun_control[\"n_samples\"])\n        return z_res\n\n    def fun_oml_horizon(self, X, fun_control=None):\n\"\"\"\n        This function calculates the horizon for a given set of data X and control parameters.\n\n        :param X: numpy array of data\n        :param fun_control: dictionary of control parameters\n        :return: numpy array of horizon values\n        \"\"\"\n        self.fun_control.update(fun_control)\n        self.check_weights()\n        self.check_X_shape(X)\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        z_res = []\n        for config in get_one_config_from_var_dict(var_dict, self.fun_control):\n            if self.fun_control[\"prep_model\"] is not None:\n                model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n            else:\n                model = self.fun_control[\"core_model\"](**config)\n            try:\n                df_eval, _ = self.evaluate_model(model, self.fun_control)\n                y = self.compute_y(df_eval)\n            except Exception as err:\n                y = np.nan\n                print(f\"Error in fun(). Call to evaluate or compute_y failed. {err=}, {type(err)=}\")\n                print(\"Setting y to np.nan.\")\n            z_res.append(y / self.fun_control[\"n_samples\"])\n        return np.array(z_res)\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.compute_y","title":"<code>compute_y(df_eval)</code>","text":"<p>Compute the objective function value.</p> <p>Parameters:</p> Name Type Description Default <code>df_eval</code> <code>pd.DataFrame</code> <p>DataFrame with the evaluation results.</p> required <p>Returns:</p> Type Description <code>float</code> <p>objective function value. Mean of the MAEs of the predicted values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)'])\n&gt;&gt;&gt; weights = [1, 1, 1]\n&gt;&gt;&gt; compute_y(df_eval, weights)\n4.0\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>def compute_y(self, df_eval):\n\"\"\"Compute the objective function value.\n    Args:\n        df_eval (pd.DataFrame): DataFrame with the evaluation results.\n    Returns:\n        (float): objective function value. Mean of the MAEs of the predicted values.\n    Examples:\n        &gt;&gt;&gt; df_eval = pd.DataFrame( [[1, 2, 3], [4, 5, 6]], columns=['Metric', 'CompTime (s)', 'Memory (MB)'])\n        &gt;&gt;&gt; weights = [1, 1, 1]\n        &gt;&gt;&gt; compute_y(df_eval, weights)\n        4.0\n    \"\"\"\n    # take the mean of the MAEs/ACCs of the predicted values and ignore the NaN values\n    df_eval = df_eval.dropna()\n    y_error = df_eval[\"Metric\"].mean()\n    logger.debug(\"y_error from eval_oml_horizon: %s\", y_error)\n    y_r_time = df_eval[\"CompTime (s)\"].mean()\n    logger.debug(\"y_r_time from eval_oml_horizon: %s\", y_r_time)\n    y_memory = df_eval[\"Memory (MB)\"].mean()\n    logger.debug(\"y_memory from eval_oml_horizon: %s\", y_memory)\n    weights = self.fun_control[\"weights\"]\n    logger.debug(\"weights from eval_oml_horizon: %s\", weights)\n    y = weights[0] * y_error + weights[1] * y_r_time + weights[2] * y_memory\n    logger.debug(\"weighted res from eval_oml_horizon: %s\", y)\n    return y\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_hw","title":"<code>fun_hw(X, fun_control=None)</code>","text":"<p>Hyperparameter Tuning of the HoltWinters model.</p> <pre><code>Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method.\nCertain parameterizations result in special cases, such as simple exponential smoothing.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>five hyperparameters. The parameters of the hyperparameter vector are:</p> <ol> <li><code>alpha</code>: Smoothing parameter for the level.</li> <li><code>beta</code>: Smoothing parameter for the trend.</li> <li><code>gamma</code>: Smoothing parameter for the seasonality.</li> <li><code>seasonality</code>: The number of periods in a season.     For instance, this should be 4 for quarterly data, and 12 for yearly data.</li> <li><code>multiplicative</code>: Whether or not to use a multiplicative formulation.</li> </ol> required <code>fun_control</code> <code>dict</code> <p>Parameters that are are not tuned:</p> <ol> <li><code>horizon</code>: (int)</li> <li><code>grace_period</code>: (int) Initial period during which the metric is not updated.     This is to fairly evaluate models which need a warming up period to start     producing meaningful forecasts.     The value of this parameter is equal to the <code>horizon</code> by default.</li> <li><code>data</code>: dataset. Default <code>AirlinePassengers</code>.</li> </ol> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>objective function value. Mean of the MAEs of the predicted values.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>def fun_hw(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of the HoltWinters model.\n\n        Holt-Winters forecaster. This is a standard implementation of the Holt-Winters forecasting method.\n        Certain parameterizations result in special cases, such as simple exponential smoothing.\n\n    Args:\n        X (array): five hyperparameters. The parameters of the hyperparameter vector are:\n\n            1. `alpha`: Smoothing parameter for the level.\n            2. `beta`: Smoothing parameter for the trend.\n            3. `gamma`: Smoothing parameter for the seasonality.\n            4. `seasonality`: The number of periods in a season.\n                For instance, this should be 4 for quarterly data, and 12 for yearly data.\n            5. `multiplicative`: Whether or not to use a multiplicative formulation.\n\n        fun_control (dict): Parameters that are are not tuned:\n\n            1. `horizon`: (int)\n            2. `grace_period`: (int) Initial period during which the metric is not updated.\n                This is to fairly evaluate models which need a warming up period to start\n                producing meaningful forecasts.\n                The value of this parameter is equal to the `horizon` by default.\n            2. `data`: dataset. Default `AirlinePassengers`.\n\n    Returns:\n        (float): objective function value. Mean of the MAEs of the predicted values.\n    \"\"\"\n    self.fun_control.update(fun_control)\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array([X])\n    if X.shape[1] != 5:\n        raise Exception\n\n    alpha = X[:, 0]\n    beta = X[:, 1]\n    gamma = X[:, 2]\n    seasonality = X[:, 3]\n    multiplicative = X[:, 4]\n    z_res = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        model = time_series.HoltWinters(\n            alpha=alpha[i],\n            beta=beta[i],\n            gamma=gamma[i],\n            seasonality=int(seasonality[i]),\n            multiplicative=int(multiplicative[i]),\n        )\n        res = time_series.evaluate(\n            self.fun_control[\"data\"],\n            model,\n            metric=self.fun_control[\"metric\"],\n            horizon=self.fun_control[\"horizon\"],\n            grace_period=self.fun_control[\"grace_period\"],\n            agg_func=statistics.mean,\n        )\n        z = res.get()\n        z_res = np.append(z_res, z)\n    return z_res\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_nowcasting","title":"<code>fun_nowcasting(X, fun_control=None)</code>","text":"<p>Hyperparameter Tuning of the nowcasting model.</p> <p>Returns:</p> Type Description <code>float</code> <p>objective function value. Mean of the MAEs of the predicted values.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>def fun_nowcasting(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of the nowcasting model.\n\n    Returns:\n        (float): objective function value. Mean of the MAEs of the predicted values.\n    \"\"\"\n    self.fun_control.update(fun_control)\n\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array([X])\n    if X.shape[1] != 5:\n        raise Exception\n    lr = X[:, 0]\n    intercept_lr = X[:, 1]\n    hour = X[:, 2]\n    weekday = X[:, 3]\n    month = X[:, 4]\n\n    z_res = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        h_i = int(hour[i])\n        w_i = int(weekday[i])\n        m_i = int(month[i])\n        # baseline:\n        extract_features = compose.TransformerUnion(get_ordinal_date)\n        if h_i:\n            extract_features = compose.TransformerUnion(get_ordinal_date, get_hour_distances)\n        if w_i:\n            extract_features = compose.TransformerUnion(extract_features, get_weekday_distances)\n        if m_i:\n            extract_features = compose.TransformerUnion(extract_features, get_month_distances)\n        model = compose.Pipeline(\n            (\"features\", extract_features),\n            (\"scale\", preprocessing.StandardScaler()),\n            (\n                \"lin_reg\",\n                linear_model.LinearRegression(\n                    intercept_init=0, optimizer=optim.SGD(float(lr[i])), intercept_lr=float(intercept_lr[i])\n                ),\n            ),\n        )\n        # eval:\n        dates, metric, y_trues, y_preds = eval_nowcast_model(\n            model, dataset=self.fun_control[\"data\"], time_interval=\"Time\"\n        )\n        z = metric.get()\n        z_res = np.append(z_res, z)\n    return z_res\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_oml_horizon","title":"<code>fun_oml_horizon(X, fun_control=None)</code>","text":"<p>This function calculates the horizon for a given set of data X and control parameters.</p> <p>:param X: numpy array of data :param fun_control: dictionary of control parameters :return: numpy array of horizon values</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>def fun_oml_horizon(self, X, fun_control=None):\n\"\"\"\n    This function calculates the horizon for a given set of data X and control parameters.\n\n    :param X: numpy array of data\n    :param fun_control: dictionary of control parameters\n    :return: numpy array of horizon values\n    \"\"\"\n    self.fun_control.update(fun_control)\n    self.check_weights()\n    self.check_X_shape(X)\n    var_dict = assign_values(X, self.fun_control[\"var_name\"])\n    z_res = []\n    for config in get_one_config_from_var_dict(var_dict, self.fun_control):\n        if self.fun_control[\"prep_model\"] is not None:\n            model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n        else:\n            model = self.fun_control[\"core_model\"](**config)\n        try:\n            df_eval, _ = self.evaluate_model(model, self.fun_control)\n            y = self.compute_y(df_eval)\n        except Exception as err:\n            y = np.nan\n            print(f\"Error in fun(). Call to evaluate or compute_y failed. {err=}, {type(err)=}\")\n            print(\"Setting y to np.nan.\")\n        z_res.append(y / self.fun_control[\"n_samples\"])\n    return np.array(z_res)\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_oml_iter_progressive","title":"<code>fun_oml_iter_progressive(X, fun_control=None)</code>","text":"<p>Hyperparameter Tuning of an arbitrary model. Returns</p> <p>(float): objective function value. Mean of the MAEs of the predicted values.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>def fun_oml_iter_progressive(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of an arbitrary model.\n    Returns\n    -------\n    (float): objective function value. Mean of the MAEs of the predicted values.\n    \"\"\"\n    self.fun_control.update(fun_control)\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array([X])\n    if X.shape[1] != len(self.fun_control[\"var_name\"]):\n        raise Exception\n    var_dict = assign_values(X, self.fun_control[\"var_name\"])\n    z_res = np.array([], dtype=float)\n    dataset_list = self.fun_control[\"data\"]\n    for values in iterate_dict_values(var_dict):\n        values = convert_keys(values, self.fun_control[\"var_type\"])\n        print(values)\n        values = get_dict_with_levels_and_types(fun_control=self.fun_control, v=values)\n        values = transform_hyper_parameter_values(fun_control=self.fun_control, hyper_parameter_values=values)\n        print(values)\n        model = compose.Pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**values))\n        try:\n            res = eval_oml_iter_progressive(\n                dataset=dataset_list,\n                step=self.fun_control[\"step\"],\n                log_level=self.fun_control[\"log_level\"],\n                metric=fun_control[\"metric\"],\n                weight_coeff=fun_control[\"weight_coeff\"],\n                models={\n                    self.fun_control[\"model_name\"]: (model),\n                },\n            )\n            logger.debug(\"res from eval_oml_iter_progressive: %s\", res)\n            y = fun_eval_oml_iter_progressive(res, metric=None, weights=self.fun_control[\"weights\"])\n        except Exception as err:\n            y = np.nan\n            print(f\"Error in fun(). Call to evaluate failed. {err=}, {type(err)=}\")\n            print(f\"Setting y to {y:.2f}.\")\n        z_res = np.append(z_res, y / self.fun_control[\"n_samples\"])\n    return z_res\n</code></pre>"},{"location":"reference/spotRiver/fun/hyperriver_old/#spotRiver.fun.hyperriver_old.HyperRiver.fun_snarimax","title":"<code>fun_snarimax(X, fun_control=None)</code>","text":"<p>Hyperparameter Tuning of the SNARIMAX model.     SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with     e(X)ogenous inputs model. This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced. It is made up of the following components: - S (Seasonal) - N (Non-linear): Any online regression model can be used, not necessarily a linear regression     as is done in textbooks. - AR (Autoregressive): Lags of the target variable are used as features. - I (Integrated): The model can be fitted on a differenced version of a time series. In this     context, integration is the reverse of differencing. - MA (Moving average): Lags of the errors are used as features. - X (Exogenous): Users can provide additional features. Care has to be taken to include     features that will be available both at training and prediction time.</p> <p>Each of these components can be switched on and off by specifying the appropriate parameters. Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special parametrizations of the SNARIMAX model.</p> <p>This model is tailored for time series that are homoskedastic. In other words, it might not work well if the variance of the time series varies widely along time.</p> Parameters of the hyperparameter vector <p><code>p</code>: Order of the autoregressive part. This is the number of past target values that will be     included as features. <code>d</code>: Differencing order. <code>q</code>: Order of the moving average part. This is the number of past error terms that will be included     as features. <code>m</code>: Season length used for extracting seasonal features. If you believe your data has a seasonal     pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality,     and that your data is spaced by month, then you should set this to <code>12</code>.     Note that for this parameter to have any impact you should also set at least     one of the <code>p</code>, <code>d</code>, and <code>q</code> parameters. <code>sp</code>:  Seasonal order of the autoregressive part. This is the number of past target values that will     be included as features. <code>sd</code>: Seasonal differencing order. <code>sq</code>: Seasonal order of the moving average part. This is the number of past error terms that will be     included as features. <code>lr</code> (float):     learn rate of the linear regression model. A river <code>preprocessing.StandardScaler</code>     piped with a river <code>linear_model.LinearRegression</code> will be used. <code>intercept_lr</code> (float): intercept of the the linear regression model. A river <code>preprocessing.StandardScaler</code>     piped with a river <code>linear_model.LinearRegression</code> will be used. <code>hour</code> (bool): If <code>True</code>, an hourly component is added. <code>weekdy</code> (bool): If <code>True</code>, an weekday component is added. <code>month</code> (bool): If <code>True</code>, an monthly component is added.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Seven hyperparameters to be optimized. Here:</p> <p><code>p</code> (int):     Order of the autoregressive part.     This is the number of past target values that will be included as features.</p> <p><code>d</code> (int):     Differencing order.</p> <p><code>q</code> (int):     Order of the moving average part.     This is the number of past error terms that will be included as features.</p> <p><code>m</code> (int):     Season length used for extracting seasonal features.     If you believe your data has a seasonal pattern, then set this accordingly.     For instance, if the data seems to exhibit a yearly seasonality,     and that your data is spaced by month, then you should set this to <code>12</code>.     Note that for this parameter to have any impact you should also set     at least one of the <code>p</code>, <code>d</code>, and <code>q</code> parameters.</p> <p><code>sp</code> (int):     Seasonal order of the autoregressive part.     This is the number of past target values that will be included as features.</p> <p><code>sd</code> (int):     Seasonal differencing order.</p> <p><code>sq</code>(int):     Seasonal order of the moving average part.     This is the number of past error terms that will be included as features.</p> <p><code>lr</code> (float):     learn rate of the linear regression model. A river <code>preprocessing.StandardScaler</code>     piped with a river <code>linear_model.LinearRegression</code> will be used.</p> <p><code>intercept_lr</code> (float): intercept of the the linear regression model.     A river <code>preprocessing.StandardScaler</code> piped with a river <code>linear_model.LinearRegression</code>     will be used.</p> <p><code>hour</code> (bool): If <code>True</code>, an hourly component is added.</p> <p><code>weekday</code> (bool): If <code>True</code>, an weekday component is added.</p> <p><code>month</code> (bool): If <code>True</code>, an monthly component is added.</p> required <code>fun_control</code> <code>dict</code> <p>parameter that are not optimized, e.g., <code>horizon</code>. Commonly referred to as \u201cdesign of experiments\u201d parameters:</p> <ol> <li> <p><code>horizon</code>: (int)</p> </li> <li> <p><code>grace_period</code>: (int) Initial period during which the metric is not updated.     This is to fairly evaluate models which need a warming up period to start     producing meaningful forecasts.     The value of this parameter is equal to the <code>horizon</code> by default.</p> </li> <li> <p><code>data</code>: dataset. Default <code>AirlinePassengers</code>.</p> </li> </ol> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>objective function value. Mean of the MAEs of the predicted values.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/fun/hyperriver_old.py</code> <pre><code>def fun_snarimax(self, X, fun_control=None):\n\"\"\"Hyperparameter Tuning of the SNARIMAX model.\n        SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with\n        e(X)ogenous inputs model.\n    This model generalizes many established time series models in a single interface that can be\n    trained online. It assumes that the provided training data is ordered in time and is uniformly spaced.\n    It is made up of the following components:\n    - S (Seasonal)\n    - N (Non-linear): Any online regression model can be used, not necessarily a linear regression\n        as is done in textbooks.\n    - AR (Autoregressive): Lags of the target variable are used as features.\n    - I (Integrated): The model can be fitted on a differenced version of a time series. In this\n        context, integration is the reverse of differencing.\n    - MA (Moving average): Lags of the errors are used as features.\n    - X (Exogenous): Users can provide additional features. Care has to be taken to include\n        features that will be available both at training and prediction time.\n\n    Each of these components can be switched on and off by specifying the appropriate parameters.\n    Classical time series models such as AR, MA, ARMA, and ARIMA can thus be seen as special\n    parametrizations of the SNARIMAX model.\n\n    This model is tailored for time series that are homoskedastic. In other words, it might not\n    work well if the variance of the time series varies widely along time.\n\n    Parameters of the hyperparameter vector:\n\n        `p`: Order of the autoregressive part. This is the number of past target values that will be\n            included as features.\n        `d`: Differencing order.\n        `q`: Order of the moving average part. This is the number of past error terms that will be included\n            as features.\n        `m`: Season length used for extracting seasonal features. If you believe your data has a seasonal\n            pattern, then set this accordingly. For instance, if the data seems to exhibit a yearly seasonality,\n            and that your data is spaced by month, then you should set this to `12`.\n            Note that for this parameter to have any impact you should also set at least\n            one of the `p`, `d`, and `q` parameters.\n        `sp`:  Seasonal order of the autoregressive part. This is the number of past target values that will\n            be included as features.\n        `sd`: Seasonal differencing order.\n        `sq`: Seasonal order of the moving average part. This is the number of past error terms that will be\n            included as features.\n        `lr` (float):\n            learn rate of the linear regression model. A river `preprocessing.StandardScaler`\n            piped with a river `linear_model.LinearRegression` will be used.\n        `intercept_lr` (float): intercept of the the linear regression model. A river `preprocessing.StandardScaler`\n            piped with a river `linear_model.LinearRegression` will be used.\n        `hour` (bool): If `True`, an hourly component is added.\n        `weekdy` (bool): If `True`, an weekday component is added.\n        `month` (bool): If `True`, an monthly component is added.\n\n    Args:\n        X (array):\n            Seven hyperparameters to be optimized. Here:\n\n            `p` (int):\n                Order of the autoregressive part.\n                This is the number of past target values that will be included as features.\n\n            `d` (int):\n                Differencing order.\n\n            `q` (int):\n                Order of the moving average part.\n                This is the number of past error terms that will be included as features.\n\n            `m` (int):\n                Season length used for extracting seasonal features.\n                If you believe your data has a seasonal pattern, then set this accordingly.\n                For instance, if the data seems to exhibit a yearly seasonality,\n                and that your data is spaced by month, then you should set this to `12`.\n                Note that for this parameter to have any impact you should also set\n                at least one of the `p`, `d`, and `q` parameters.\n\n            `sp` (int):\n                Seasonal order of the autoregressive part.\n                This is the number of past target values that will be included as features.\n\n            `sd` (int):\n                Seasonal differencing order.\n\n            `sq`(int):\n                Seasonal order of the moving average part.\n                This is the number of past error terms that will be included as features.\n\n            `lr` (float):\n                learn rate of the linear regression model. A river `preprocessing.StandardScaler`\n                piped with a river `linear_model.LinearRegression` will be used.\n\n            `intercept_lr` (float): intercept of the the linear regression model.\n                A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression`\n                will be used.\n\n            `hour` (bool): If `True`, an hourly component is added.\n\n            `weekday` (bool): If `True`, an weekday component is added.\n\n            `month` (bool): If `True`, an monthly component is added.\n\n        fun_control (dict):\n            parameter that are not optimized, e.g., `horizon`. Commonly\n            referred to as \"design of experiments\" parameters:\n\n            1. `horizon`: (int)\n\n            2. `grace_period`: (int) Initial period during which the metric is not updated.\n                This is to fairly evaluate models which need a warming up period to start\n                producing meaningful forecasts.\n                The value of this parameter is equal to the `horizon` by default.\n\n            3. `data`: dataset. Default `AirlinePassengers`.\n\n    Returns:\n        (float): objective function value. Mean of the MAEs of the predicted values.\n    \"\"\"\n    self.fun_control.update(fun_control)\n\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array([X])\n    if X.shape[1] != 12:\n        raise Exception\n    p = X[:, 0]\n    d = X[:, 1]\n    q = X[:, 2]\n    m = X[:, 3]\n    sp = X[:, 4]\n    sd = X[:, 5]\n    sq = X[:, 6]\n    lr = X[:, 7]\n    intercept_lr = X[:, 8]\n    hour = X[:, 9]\n    weekday = X[:, 10]\n    month = X[:, 11]\n\n    # TODO:\n    # horizon = fun_control[\"horizon\"]\n    # future = [\n    #   {\"month\": dt.date(year=1961, month=m, day=1)} for m in range(1, horizon + 1)\n    # ]\n    z_res = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        h_i = int(hour[i])\n        w_i = int(weekday[i])\n        m_i = int(month[i])\n        # baseline:\n        extract_features = compose.TransformerUnion(get_ordinal_date)\n        if h_i:\n            extract_features = compose.TransformerUnion(get_ordinal_date, get_hour_distances)\n        if w_i:\n            extract_features = compose.TransformerUnion(extract_features, get_weekday_distances)\n        if m_i:\n            extract_features = compose.TransformerUnion(extract_features, get_month_distances)\n        model = compose.Pipeline(\n            extract_features,\n            time_series.SNARIMAX(\n                p=int(p[i]),\n                d=int(d[i]),\n                q=int(q[i]),\n                m=int(m[i]),\n                sp=int(sp[i]),\n                sd=int(sd[i]),\n                sq=int(sq[i]),\n                regressor=compose.Pipeline(\n                    preprocessing.StandardScaler(),\n                    linear_model.LinearRegression(\n                        intercept_init=0,\n                        optimizer=optim.SGD(float(lr[i])),\n                        intercept_lr=float(intercept_lr[i]),\n                    ),\n                ),\n            ),\n        )\n        # eval:\n        res = time_series.evaluate(\n            self.fun_control[\"data\"],\n            model,\n            metric=self.fun_control[\"metric\"],\n            horizon=self.fun_control[\"horizon\"],\n            agg_func=statistics.mean,\n        )\n        z = res.get()\n        z_res = np.append(z_res, z)\n    return z_res\n</code></pre>"},{"location":"reference/spotRiver/plot/stats/","title":"stats","text":""},{"location":"reference/spotRiver/plot/stats/#spotRiver.plot.stats.corrplot","title":"<code>corrplot(df, numeric_only=True)</code>","text":"<p>Function plots a graphical correlation matrix for each pair of columns in the dataframe.     The function takes a DataFrame df as input and generates a graphical correlation matrix     for each pair of columns in the dataframe.     The upper triangle of the correlation matrix is masked out and set to NaN values.     The resulting matrix is then styled and returned as a heatmap with colors     ranging from blue (for negative correlations) to red (for positive correlations).</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Data to plot.</p> required <code>numeric_only</code> <code>bool, default True</code> <p>Include only float, int or boolean data.</p> <code>True</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A styled correlation matrix heatmap.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.plot.stats import corrplot\n    import pandas as pd\n    X = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n    corrplot(X)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/plot/stats.py</code> <pre><code>def corrplot(df: pd.DataFrame, numeric_only=True) -&gt; None:\n\"\"\"Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n        The function takes a DataFrame df as input and generates a graphical correlation matrix\n        for each pair of columns in the dataframe.\n        The upper triangle of the correlation matrix is masked out and set to NaN values.\n        The resulting matrix is then styled and returned as a heatmap with colors\n        ranging from blue (for negative correlations) to red (for positive correlations).\n\n    Args:\n        df (pd.DataFrame): Data to plot.\n        numeric_only (bool, default True):\n            Include only float, int or boolean data.\n    Returns:\n        (pd.DataFrame): A styled correlation matrix heatmap.\n\n    Examples:\n        &gt;&gt;&gt; from spotRiver.plot.stats import corrplot\n            import pandas as pd\n            X = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n            corrplot(X)\n\n    \"\"\"\n\n    # Compute the correlation matrix\n    corr = df.corr(numeric_only=numeric_only)\n\n    # Generate a mask for the upper triangle\n    mask = np.zeros_like(corr, dtype=bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Set values in the upper triangle to NaN\n    corr[mask] = np.nan\n\n    # Apply styling to the correlation matrix and return it as a heatmap\n    return corr.style.background_gradient(cmap=\"coolwarm\", axis=None, vmin=-1, vmax=1).highlight_null(color=\"#f1f1f1\")\n</code></pre>"},{"location":"reference/spotRiver/preprocess/impute/","title":"impute","text":""},{"location":"reference/spotRiver/preprocess/impute/#spotRiver.preprocess.impute.impute_opm","title":"<code>impute_opm(include_categorical=False, data_home='data', strategy='most_frequent', columns=['lat', 'lon'], archive_name='opm_cat.csv', path_or_buf='opm_cat.zip', write_csv=True, return_df=False)</code>","text":"<p>Impute missing values in OPM dataset.</p> <p>Parameters:</p> Name Type Description Default <code>include_categorical</code> <code>bool</code> <p>Whether to include categorical features. Default is False.</p> <code>False</code> <code>data_home</code> <code>str</code> <p>The directory to use as a data store. Default is \u201cdata\u201d.</p> <code>'data'</code> <code>strategy</code> <code>str</code> <p>The imputation strategy to use. Can be one of \u201cmean\u201d, \u201cmedian\u201d, \u201cmost_frequent\u201d, or \u201cconstant\u201d. Default is \u201cmost_frequent\u201d.</p> <code>'most_frequent'</code> <code>columns</code> <code>list[str]</code> <p>A list of column names to impute. If None, impute all columns. Default is [\u201clat\u201d, \u201clon\u201d].</p> <code>['lat', 'lon']</code> <code>archive_name</code> <code>str</code> <p>The name of the archive file to write. Default is \u201copm_cat.csv\u201d.</p> <code>'opm_cat.csv'</code> <code>path_or_buf</code> <code>str</code> <p>The file path or buffer to write. Default is \u201copm_cat.zip\u201d.</p> <code>'opm_cat.zip'</code> <code>write_csv</code> <code>bool</code> <p>Whether to write the imputed data to a CSV file. Default is True.</p> <code>True</code> <code>return_df</code> <code>bool</code> <p>Whether to return the imputed data as a DataFrame. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>If <code>return_df</code> is True, returns a pandas DataFrame containing the imputed data.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/preprocess/impute.py</code> <pre><code>def impute_opm(\n    include_categorical: bool = False,\n    data_home: str = \"data\",\n    strategy: str = \"most_frequent\",\n    columns: list[str] = [\"lat\", \"lon\"],\n    archive_name: str = \"opm_cat.csv\",\n    path_or_buf: str = \"opm_cat.zip\",\n    write_csv: bool = True,\n    return_df: bool = False,\n) -&gt; pd.DataFrame:\n\"\"\"Impute missing values in OPM dataset.\n\n    Args:\n        include_categorical: Whether to include categorical features. Default is False.\n        data_home: The directory to use as a data store. Default is \"data\".\n        strategy: The imputation strategy to use. Can be one of \"mean\", \"median\", \"most_frequent\", or \"constant\". Default is \"most_frequent\".\n        columns: A list of column names to impute. If None, impute all columns. Default is [\"lat\", \"lon\"].\n        archive_name: The name of the archive file to write. Default is \"opm_cat.csv\".\n        path_or_buf: The file path or buffer to write. Default is \"opm_cat.zip\".\n        write_csv: Whether to write the imputed data to a CSV file. Default is True.\n        return_df: Whether to return the imputed data as a DataFrame. Default is False.\n\n    Returns:\n        If `return_df` is True, returns a pandas DataFrame containing the imputed data.\n    \"\"\"\n    # Validate input parameters\n    valid_strategies = [\"mean\", \"median\", \"most_frequent\", \"constant\"]\n    if strategy not in valid_strategies:\n        raise ValueError(f\"Invalid strategy: {strategy}. Must be one of {valid_strategies}.\")\n    # Fetch and concatenate data\n    X, y = fetch_opm(include_categorical=include_categorical, data_home=data_home, return_X_y=True)\n    df = pd.concat([X, y], axis=1)\n    # Impute missing values\n    imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n    if columns is None:\n        # Impute all columns\n        df[:] = imp.fit_transform(df)\n    else:\n        # Impute only specified columns\n        for col in columns:\n            if col not in df.columns:\n                raise ValueError(f\"Invalid column: {col}. Not in dataframe.\")\n            df[col] = imp.fit_transform(np.array(df[col]).reshape(-1, 1))\n    # Write csv file if requested\n    if write_csv:\n        compression_opts = dict(method=\"zip\", archive_name=archive_name)\n        df.to_csv(path_or_buf, index=False, compression=compression_opts)\n    # Return dataframe if requested\n    if return_df:\n        return df\n</code></pre>"},{"location":"reference/spotRiver/utils/data_conversion/","title":"data_conversion","text":""},{"location":"reference/spotRiver/utils/data_conversion/#spotRiver.utils.data_conversion.compare_two_tree_models","title":"<code>compare_two_tree_models(model1, model2, headers=['Parameter', 'Default', 'Spot'])</code>","text":"<p>Compares two tree models and returns a table of the differences.</p> <p>Parameters:</p> Name Type Description Default <code>model1</code> <code>Pipeline</code> <p>A river model pipeline.</p> required <code>model2</code> <code>Pipeline</code> <p>A river model pipeline.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A table of the differences between the two models.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/utils/data_conversion.py</code> <pre><code>def compare_two_tree_models(model1, model2, headers=[\"Parameter\", \"Default\", \"Spot\"]):\n\"\"\"Compares two tree models and returns a table of the differences.\n    Args:\n        model1 (Pipeline): A river model pipeline.\n        model2 (Pipeline): A river model pipeline.\n    Returns:\n        (str): A table of the differences between the two models.\n    \"\"\"\n    keys = model1[1].summary.keys()\n    values1 = model1[1].summary.values()\n    values2 = model2[1].summary.values()\n    tbl = []\n    for key, value1, value2 in zip(keys, values1, values2):\n        tbl.append([key, value1, value2])\n    return tabulate(tbl, headers=headers, numalign=\"right\", tablefmt=\"github\")\n</code></pre>"},{"location":"reference/spotRiver/utils/data_conversion/#spotRiver.utils.data_conversion.convert_to_df","title":"<code>convert_to_df(dataset, target_column, n_total=None)</code>","text":"<p>Converts a river dataset into a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>datasets.base.Dataset</code> <p>The river dataset to be converted.</p> required <code>target_column</code> <code>str</code> <p>The name of the target column in the resulting DataFrame.</p> required <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A pandas DataFrame representation of the given dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = datasets.TrumpApproval()\n    target_column = \"Approval\"\n    df = convert_to_df(dataset, target_column)\n    df.rename(columns={\n        'date': 'ordinal_date',\n        'Gallup': 'gallup',\n        'Ipsos': 'ipsos',\n        'Morning Consult': 'morning_consult',\n        'Rasmussen': 'rasmussen',\n        'YouGov': 'you_gov'},\n        inplace=True)\n    # Split the data into train and test sets\n    train = df[:500]\n    test = df[500:]\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/utils/data_conversion.py</code> <pre><code>def convert_to_df(dataset: datasets.base.Dataset, target_column: str, n_total=None) -&gt; pd.DataFrame:\n\"\"\"Converts a river dataset into a pandas DataFrame.\n\n    Args:\n        dataset (datasets.base.Dataset): The river dataset to be converted.\n        target_column (str): The name of the target column in the resulting DataFrame.\n\n    Returns:\n        (pd.DataFrame): A pandas DataFrame representation of the given dataset.\n\n    Examples:\n        &gt;&gt;&gt; dataset = datasets.TrumpApproval()\n            target_column = \"Approval\"\n            df = convert_to_df(dataset, target_column)\n            df.rename(columns={\n                'date': 'ordinal_date',\n                'Gallup': 'gallup',\n                'Ipsos': 'ipsos',\n                'Morning Consult': 'morning_consult',\n                'Rasmussen': 'rasmussen',\n                'YouGov': 'you_gov'},\n                inplace=True)\n            # Split the data into train and test sets\n            train = df[:500]\n            test = df[500:]\n    \"\"\"\n    data_dict = {key: [] for key in list(dataset.take(1))[0][0].keys()}\n    data_dict[target_column] = []\n    if n_total is None:\n        for x in dataset:\n            for key, value in x[0].items():\n                data_dict[key].append(value)\n            data_dict[target_column].append(x[1])\n    else:\n        for x in dataset.take(n_total):\n            for key, value in x[0].items():\n                data_dict[key].append(value)\n            data_dict[target_column].append(x[1])\n    df = pd.DataFrame(data_dict)\n    return df\n</code></pre>"},{"location":"reference/spotRiver/utils/features/","title":"features","text":""},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_hour_distances","title":"<code>get_hour_distances(x)</code>","text":"<p>This function takes in a dictionary with a single key-value pair where the key is a string and the value     is a datetime object.     It returns a new dictionary where the keys are the names of the hours of the day and the values are     the result of applying a Gaussian function to the difference between the hour of the input datetime     object and each hour of the day.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict[str, datetime]</code> <p>A dictionary with a single key-value pair where the key is a string and the value is a datetime object.</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary where the keys are the names of the hours of the day and the values are the result of applying a Gaussian function to the difference between the hour of the input datetime object and each hour of the day.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.utils.features import get_hour_distances\n&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; get_hour_distances({\"date\": datetime(2020, 1, 1)})\n{'0': 0.6065306597126334, '1': 0.36787944117144233, '2': 0.1353352832366127, '3': 0.01831563888873418,\n'4': 0.00033546262790251185, '5': 3.354626279025118e-06, '6': 2.0611536224385582e-08, '7': 8.315287191035679e-11,\n'8': 2.0611536224385582e-13, '9': 3.354626279025118e-16, '10': 3.354626279025118e-19,\n'11': 2.0611536224385582e-22, '12': 8.315287191035679e-26, '13': 2.0611536224385582e-29,\n'14': 3.354626279025118e-33, '15': 3.354626279025118e-37, '16': 2.0611536224385582e-41,\n'17': 8.315287191035679e-46, '18': 2.0611536224385582e-50, '19': 3.354626279025118e-55,\n'20': 3.354626279025118e-60, '21': 2.0611536224385582e-65, '22': 8.315287191035679e-71, '23': 2.0611536224385582e-76}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/utils/features.py</code> <pre><code>def get_hour_distances(x):\n\"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value\n        is a datetime object.\n        It returns a new dictionary where the keys are the names of the hours of the day and the values are\n        the result of applying a Gaussian function to the difference between the hour of the input datetime\n        object and each hour of the day.\n    Args:\n        x (Dict[str, datetime]):\n            A dictionary with a single key-value pair where the key is a string and the value is a datetime object.\n    Returns:\n        (Dict[str, float]):\n            A dictionary where the keys are the names of the hours of the day and the values are\n            the result of applying a Gaussian function to the difference between the hour of the\n            input datetime object and each hour of the day.\n    Examples:\n        &gt;&gt;&gt; from spotRiver.utils.features import get_hour_distances\n        &gt;&gt;&gt; from datetime import datetime\n        &gt;&gt;&gt; get_hour_distances({\"date\": datetime(2020, 1, 1)})\n        {'0': 0.6065306597126334, '1': 0.36787944117144233, '2': 0.1353352832366127, '3': 0.01831563888873418,\n        '4': 0.00033546262790251185, '5': 3.354626279025118e-06, '6': 2.0611536224385582e-08, '7': 8.315287191035679e-11,\n        '8': 2.0611536224385582e-13, '9': 3.354626279025118e-16, '10': 3.354626279025118e-19,\n        '11': 2.0611536224385582e-22, '12': 8.315287191035679e-26, '13': 2.0611536224385582e-29,\n        '14': 3.354626279025118e-33, '15': 3.354626279025118e-37, '16': 2.0611536224385582e-41,\n        '17': 8.315287191035679e-46, '18': 2.0611536224385582e-50, '19': 3.354626279025118e-55,\n        '20': 3.354626279025118e-60, '21': 2.0611536224385582e-65, '22': 8.315287191035679e-71, '23': 2.0611536224385582e-76}\n    \"\"\"\n    k = list(x.keys())[0]\n    return {str(hour): math.exp(-((x[k].hour - hour) ** 2)) for hour in range(0, 24)}\n</code></pre>"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_month_distances","title":"<code>get_month_distances(x)</code>","text":"<p>This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object. It returns a new dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict[str, datetime]</code> <p>A dictionary with a single key-value pair where the key is a string and the value is a datetime object.</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary where the keys are the names of the months and the values are the result of applying a Gaussian function to the difference between the month of the input datetime object and each month.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.utils.features import get_month_distances\n&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; get_month_distances({\"date\": datetime(2020, 1, 1)})\n{'January': 0.6065306597126334, 'February': 0.36787944117144233,\n'March': 0.1353352832366127, 'April': 0.01831563888873418, 'May': 0.00033546262790251185,\n'June': 3.354626279025118e-06, 'July': 2.0611536224385582e-08,\n'August': 8.315287191035679e-11,\n'September': 2.0611536224385582e-13, 'October': 3.354626279025118e-16,\n'November': 3.354626279025118e-19, 'December': 2.0611536224385582e-22}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/utils/features.py</code> <pre><code>def get_month_distances(x: Dict[str, datetime]) -&gt; Dict[str, float]:\n\"\"\"\n    This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object.\n    It returns a new dictionary where the keys are the names of the months and the values are the result of applying a Gaussian\n    function to the difference between the month of the input datetime object and each month.\n\n    Args:\n        x (Dict[str, datetime]):\n            A dictionary with a single key-value pair where the key is a string and the value is a datetime object.\n\n    Returns:\n        (Dict[str, float]):\n            A dictionary where the keys are the names of the months and the values are the result of\n            applying a Gaussian function to the difference between the month of the input datetime object and each month.\n    Examples:\n        &gt;&gt;&gt; from spotRiver.utils.features import get_month_distances\n        &gt;&gt;&gt; from datetime import datetime\n        &gt;&gt;&gt; get_month_distances({\"date\": datetime(2020, 1, 1)})\n        {'January': 0.6065306597126334, 'February': 0.36787944117144233,\n        'March': 0.1353352832366127, 'April': 0.01831563888873418, 'May': 0.00033546262790251185,\n        'June': 3.354626279025118e-06, 'July': 2.0611536224385582e-08,\n        'August': 8.315287191035679e-11,\n        'September': 2.0611536224385582e-13, 'October': 3.354626279025118e-16,\n        'November': 3.354626279025118e-19, 'December': 2.0611536224385582e-22}\n    \"\"\"\n    k = list(x.keys())[0]\n    return {calendar.month_name[month]: math.exp(-((x[k].month - month) ** 2)) for month in range(1, 13)}\n</code></pre>"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_ordinal_date","title":"<code>get_ordinal_date(x)</code>","text":"<p>This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object.     It returns a new dictionary where the keys are the string \u201cordinal_date\u201d and the value is the ordinal date of the input datetime object.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict[str, datetime]</code> <p>A dictionary with a single key-value pair where the key is a string and the value is a datetime object.</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary where the keys are the string \u201cordinal_date\u201d and the value is the ordinal date of the input datetime object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; from spotRiver.utils.features import get_ordinal_date\n&gt;&gt;&gt; get_ordinal_date({\"date\": datetime(2020, 1, 1)})\n{'ordinal_date': 737424}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/utils/features.py</code> <pre><code>def get_ordinal_date(x):\n\"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is a datetime object.\n        It returns a new dictionary where the keys are the string \"ordinal_date\" and the value is the ordinal date of the input datetime object.\n    Args:\n        x (Dict[str, datetime]): A dictionary with a single key-value pair where the key is a string and the value is a datetime object.\n    Returns:\n        (Dict[str, float]):\n            A dictionary where the keys are the string \"ordinal_date\" and the value is the ordinal date of the input datetime object.\n    Examples:\n        &gt;&gt;&gt; from datetime import datetime\n        &gt;&gt;&gt; from spotRiver.utils.features import get_ordinal_date\n        &gt;&gt;&gt; get_ordinal_date({\"date\": datetime(2020, 1, 1)})\n        {'ordinal_date': 737424}\n    \"\"\"\n    k = list(x.keys())[0]\n    return {\"ordinal_date\": x[k].toordinal()}\n</code></pre>"},{"location":"reference/spotRiver/utils/features/#spotRiver.utils.features.get_weekday_distances","title":"<code>get_weekday_distances(x)</code>","text":"<p>This function takes in a dictionary with a single key-value pair where the key is a string and the value is     a datetime object.     It returns a new dictionary where the keys are the names of the days of the week and the values are the     result of applying a Gaussian function to the difference between the weekday of the input datetime object     and each day of the week.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict[str, datetime]</code> <p>A dictionary with a single key-value pair where the key is a string and the value is a datetime object.</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary where the keys are the names of the days of the week and the values are the result of applying a Gaussian function to the difference between the weekday of the input datetime object and each day of the week.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotRiver.utils.features import get_weekday_distances\n&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; get_weekday_distances({\"date\": datetime(2020, 1, 1)})\n{'Monday': 0.6065306597126334, 'Tuesday': 0.36787944117144233, 'Wednesday': 0.1353352832366127,\n'Thursday': 0.01831563888873418, 'Friday': 0.00033546262790251185, 'Saturday': 3.354626279025118e-06,\n'Sunday': 2.0611536224385582e-08}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotRiver/utils/features.py</code> <pre><code>def get_weekday_distances(x):\n\"\"\"This function takes in a dictionary with a single key-value pair where the key is a string and the value is\n        a datetime object.\n        It returns a new dictionary where the keys are the names of the days of the week and the values are the\n        result of applying a Gaussian function to the difference between the weekday of the input datetime object\n        and each day of the week.\n    Args:\n        x (Dict[str, datetime]):\n            A dictionary with a single key-value pair where the key is a string and the value is a datetime object.\n    Returns:\n        (Dict[str, float]):\n            A dictionary where the keys are the names of the days of the week and the values\n            are the result of applying a Gaussian function to the difference between the weekday of the input\n            datetime object and each day of the week.\n    Examples:\n        &gt;&gt;&gt; from spotRiver.utils.features import get_weekday_distances\n        &gt;&gt;&gt; from datetime import datetime\n        &gt;&gt;&gt; get_weekday_distances({\"date\": datetime(2020, 1, 1)})\n        {'Monday': 0.6065306597126334, 'Tuesday': 0.36787944117144233, 'Wednesday': 0.1353352832366127,\n        'Thursday': 0.01831563888873418, 'Friday': 0.00033546262790251185, 'Saturday': 3.354626279025118e-06,\n        'Sunday': 2.0611536224385582e-08}\n    \"\"\"\n    # Monday is the first day, i.e., 0:\n    k = list(x.keys())[0]\n    return {calendar.day_name[weekday]: math.exp(-((x[k].weekday() - weekday) ** 2)) for weekday in range(0, 7)}\n</code></pre>"}]}